{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding\n",
    "\n",
    "Obwohl der Korpus lediglich 11000 Texte enthält, wird im Folgenden versucht die Klassifikation auf Basis von Word Embeddings (Kapitel ???) durchzuführen. Dabei kommen verschiedene Klassifikatoren zum Einsatz um zu sehen wie gut diese mit den gegebenen Bedingungen zurecht kommen. Die Wahl fällt auf LSTM, CNNs und deren Kombination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Dependencies\" data-toc-modified-id=\"Dependencies-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Dependencies</a></span></li><li><span><a href=\"#Get-data\" data-toc-modified-id=\"Get-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Get data</a></span></li><li><span><a href=\"#Prepare-data\" data-toc-modified-id=\"Prepare-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Prepare data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tokenize-+-Padding\" data-toc-modified-id=\"Tokenize-+-Padding-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Tokenize + Padding</a></span></li><li><span><a href=\"#One-hot-encoding-of-words-or-characters\" data-toc-modified-id=\"One-hot-encoding-of-words-or-characters-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>One-hot encoding of words or characters</a></span></li></ul></li><li><span><a href=\"#Define-model\" data-toc-modified-id=\"Define-model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Define model</a></span></li><li><span><a href=\"#Create-dense-model\" data-toc-modified-id=\"Create-dense-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Create dense model</a></span></li><li><span><a href=\"#Create-dense-on-embedded-data\" data-toc-modified-id=\"Create-dense-on-embedded-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Create dense on embedded data</a></span></li><li><span><a href=\"#Create-lstm-model\" data-toc-modified-id=\"Create-lstm-model-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Create lstm model</a></span></li><li><span><a href=\"#CNN\" data-toc-modified-id=\"CNN-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>CNN</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.externals.joblib import Memory\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import FEATURE_SELECTOR_v4\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, BatchNormalization, Flatten, Conv1D, MaxPooling1D, GlobalMaxPooling1D, RepeatVector, Bidirectional\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, LearningRateScheduler\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(location='./tmp', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "Diese Methode dient dazu die Texte in die gewünschte Form zu bringen, sodass diese anschließend in ein Modell mit einem führenden Embedding-Layer übergeben werden können. Hierfür wird jeder Texte in ein Array mit Integern überführt, wobei jeder Integer-Wert für ein ganz bestimmtes Wort steht. \n",
    "Für die weiteren Schritte müssen die Längen der Arrays angeglichen werden. Hierfür wird eine gewünschte Länge vorgegeben. Texte die eine geringere Länge aufweisen werden mittels Padding ergänzt, wobei das Array entweder zu Beginn oder am Ende mit 0-Werten ergänzt werden. Texte, die hingegen zu lang waren, werden gekürzt, indem Wörter weggelassen werden. Als Ergebnis erhält man einen Integermatrix mit m Zeilen und n Spalten, wobei m der Anzahl der Texte und n der festgelegten Länge.\n",
    "\n",
    "Anschließend wird das Datenset in Trainings- und Testdaten unterteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(serie_texts, labels, max_len=1000, test_size=0.33, random_state=42, max_words=10000):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        serie_texts: pd.Series with documents, \n",
    "        labels: pd.Series with labels,\n",
    "        max_len: Length of the array per text after padding,\n",
    "        test_size: Size of the test set,\n",
    "        random_state: Random_state\n",
    "        random_state: random_state\n",
    "        max_words\n",
    "    Output: Test and train data\n",
    "    Method: Tokenizing, Indexing, Padding and splitting into test and train data\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Train Tokenizer\n",
    "    tok = Tokenizer(num_words=max_words)\n",
    "    tok.fit_on_texts(serie_texts)\n",
    "    #Tokenizing and Indexing\n",
    "    sequences = tok.texts_to_sequences(serie_texts)\n",
    "    #Padding\n",
    "    sequences_matrix = sequence.pad_sequences(sequences, maxlen=max_len)\n",
    "    # Size\n",
    "    print(\"Anzahl Dokument m:\",sequences_matrix.shape[0])\n",
    "    print(\"Anzahl Token n:\",sequences_matrix.shape[1])\n",
    "    # Split the dataset into test and training data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(sequences_matrix, labels, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergebnisse darstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.subplot(211)\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    acc_values = acc\n",
    "    val_acc_values = val_acc\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'g', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Daten werden geladen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11039"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the data\n",
    "path_data='.//datasets//constructed_1.csv'\n",
    "\n",
    "# Load the data\n",
    "df_texts=pd.read_csv(path_data,sep=',',header=0, index_col=0)\n",
    "\n",
    "# Documents\n",
    "serie_texts=df_texts.text\n",
    "serie_texts.size\n",
    "\n",
    "# Labels\n",
    "labels=df_texts.label\n",
    "labels.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing + Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length for padding\n",
    "max_len=1000\n",
    "# Size of the test set\n",
    "test_size=0.33\n",
    "# The most n frequent words\n",
    "max_words=10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Dokument m: 11039\n",
      "Anzahl Token n: 1000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(serie_texts=serie_texts,max_len=max_len, labels=df_texts.label,test_size=test_size,max_words=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model\n",
    "\n",
    "In diesem befinden sich die Methoden um die Modell zu definieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_model(data, dense_units1=128, dense_units2=64, dropout=0.2):\n",
    "    inputs = Input(name='inputs',shape=[data.shape[1]])\n",
    "    layer=Dense(dense_units1, activation='relu')(inputs)\n",
    "    layer = Dropout(dropout)(layer)\n",
    "    layer=Dense(dense_units2, activation='relu')(layer)\n",
    "    layer = Dropout(dropout)(layer)\n",
    "    layer=Dense(1, activation='sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_flatten_model(data, max_words,embedding_units,dense_units1=128,dense_units2=64, dropout=0.2,kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, embeddings_regularizer=None):\n",
    "    inputs = Input(name='inputs',shape=[data.shape[1]])\n",
    "    layer = Embedding(max_words,embedding_units,input_length=max_len, embeddings_regularizer=embeddings_regularizer, activity_regularizer=activity_regularizer)(inputs)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(dense_units1, activation='relu',kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer, activity_regularizer=activity_regularizer)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Dropout(dropout)(layer)\n",
    "    layer = Dense(dense_units2, activation='relu')(layer)\n",
    "    layer = Dropout(dropout)(layer)\n",
    "    layer = Dense(1, activation='sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_lstm_model(data, max_words,embedding_units=32 ,lstm_units=32, dropout=0.2, recurrent_dropout=0.2):\n",
    "    inputs = Input(name='inputs',shape=[data.shape[1]])\n",
    "    layer = Embedding(max_words,embedding_units,input_length=max_len)(inputs)\n",
    "    layer = LSTM(lstm_units,recurrent_dropout=recurrent_dropout, dropout=dropout)(layer)\n",
    "    layer = Dense(1,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(data, max_words,embedding_units=32 ,lstm_units=32, dense_units=256, dropout=0.2, recurrent_dropout=0.2,embeddings_regularizer=None, activity_regularizer=None,kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None):\n",
    "    inputs = Input(name='inputs',shape=[data.shape[1]])\n",
    "    layer = Embedding(max_words,embedding_units,input_length=max_len,embeddings_regularizer=embeddings_regularizer,activity_regularizer=activity_regularizer)(inputs)\n",
    "    layer = LSTM(lstm_units,recurrent_dropout=recurrent_dropout, dropout=dropout,activity_regularizer=activity_regularizer,kernel_regularizer=kernel_regularizer, recurrent_regularizer=recurrent_regularizer, bias_regularizer=bias_regularizer)(layer)\n",
    "    layer = Dense(dense_units,name='FC1',kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer, activity_regularizer=activity_regularizer)(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(dropout)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_lstm_model(data, max_words,embedding_units=32 ,lstm_units=32, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None):\n",
    "    inputs = Input(name='inputs',shape=[data.shape[1]])\n",
    "    layer = Embedding(max_words,embedding_units,input_length=max_len)(inputs)\n",
    "    layer = Bidirectional(LSTM(lstm_units,recurrent_dropout=recurrent_dropout, dropout=dropout,kernel_regularizer=kernel_regularizer, recurrent_regularizer=recurrent_regularizer, bias_regularizer=bias_regularizer, activity_regularizer=activity_regularizer))(layer)\n",
    "    layer = Dense(1,name='FC1',kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer, activity_regularizer=activity_regularizer)(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(data, max_words, embedding_units,conv_1_filter=32,conv_1_length=7, pooling_length= 5,conv_2_filter=32,conv_2_length=7, dropout=0.5):\n",
    "    inputs = Input(name='inputs',shape=[data.shape[1]])\n",
    "    layer = Embedding(max_words,embedding_units,input_length=max_len)(inputs)\n",
    "    layer=Conv1D(conv_1_filter, conv_1_length, activation='relu')(layer)\n",
    "    layer=Dropout(dropout)(layer)\n",
    "    layer=MaxPooling1D(pooling_length)(layer)\n",
    "    layer=Conv1D(conv_2_filter, conv_2_length, activation='relu')(layer)\n",
    "    layer=Dropout(dropout)(layer)\n",
    "    layer=GlobalMaxPooling1D()(layer)\n",
    "    layer=Dense(1)(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm_model(data, max_words, embedding_units,conv_1_filter=32,conv_1_length=7, pooling_length= 5,lstm_units=32,conv_2_filter=32,conv_2_length=7, dropout=0.2,recurrent_dropout=0.2):\n",
    "    inputs = Input(name='inputs',shape=[data.shape[1]])\n",
    "    layer = Embedding(max_words,embedding_units,input_length=max_len)(inputs)\n",
    "    layer=Conv1D(conv_1_filter, conv_1_length, activation='relu')(layer)\n",
    "    layer=Dropout(dropout)(layer)\n",
    "    layer=MaxPooling1D(pooling_length)(layer)\n",
    "    layer=Conv1D(conv_2_filter, conv_2_length, activation='relu')(layer)\n",
    "    layer=Dropout(dropout)(layer)\n",
    "    layer = LSTM(lstm_units,recurrent_dropout=recurrent_dropout, dropout=dropout)(layer)\n",
    "    layer = Dense(1,name='FC1')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                64064     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 65,121\n",
      "Trainable params: 65,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7396 samples, validate on 3643 samples\n",
      "Epoch 1/500\n",
      "7396/7396 [==============================] - 4s 524us/step - loss: 7.7130 - acc: 0.5195 - val_loss: 8.1497 - val_acc: 0.4944\n",
      "Epoch 2/500\n",
      "7396/7396 [==============================] - 2s 273us/step - loss: 8.0008 - acc: 0.5032 - val_loss: 8.1497 - val_acc: 0.4944\n",
      "Epoch 3/500\n",
      "7396/7396 [==============================] - 1s 175us/step - loss: 8.0133 - acc: 0.5026 - val_loss: 8.1497 - val_acc: 0.4944\n",
      "Epoch 4/500\n",
      "7396/7396 [==============================] - 1s 158us/step - loss: 8.0113 - acc: 0.5028 - val_loss: 8.1406 - val_acc: 0.4949\n",
      "Epoch 5/500\n",
      "7396/7396 [==============================] - 1s 127us/step - loss: 7.3756 - acc: 0.5411 - val_loss: 8.1556 - val_acc: 0.4938\n",
      "Epoch 6/500\n",
      "7396/7396 [==============================] - 1s 120us/step - loss: 6.8033 - acc: 0.5746 - val_loss: 5.3692 - val_acc: 0.6635\n",
      "Epoch 7/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.5191 - acc: 0.6539 - val_loss: 5.1795 - val_acc: 0.6758\n",
      "Epoch 8/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 5.3193 - acc: 0.6673 - val_loss: 5.1233 - val_acc: 0.6794\n",
      "Epoch 9/500\n",
      "7396/7396 [==============================] - 1s 93us/step - loss: 5.6428 - acc: 0.6468 - val_loss: 5.4826 - val_acc: 0.6563\n",
      "Epoch 10/500\n",
      "7396/7396 [==============================] - 1s 131us/step - loss: 5.2983 - acc: 0.6686 - val_loss: 5.3522 - val_acc: 0.6662\n",
      "Epoch 11/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 5.4607 - acc: 0.6590 - val_loss: 5.1476 - val_acc: 0.6786\n",
      "Epoch 12/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 5.4503 - acc: 0.6594 - val_loss: 5.1565 - val_acc: 0.6775\n",
      "Epoch 13/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.5127 - acc: 0.6556 - val_loss: 5.0837 - val_acc: 0.6821\n",
      "Epoch 14/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 5.3704 - acc: 0.6636 - val_loss: 5.2438 - val_acc: 0.6717\n",
      "Epoch 15/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 5.2681 - acc: 0.6705 - val_loss: 5.1071 - val_acc: 0.6802\n",
      "Epoch 16/500\n",
      "7396/7396 [==============================] - 1s 125us/step - loss: 5.1561 - acc: 0.6773 - val_loss: 5.1620 - val_acc: 0.6766\n",
      "Epoch 17/500\n",
      "7396/7396 [==============================] - 1s 129us/step - loss: 5.3780 - acc: 0.6635 - val_loss: 5.2550 - val_acc: 0.6706\n",
      "Epoch 18/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.1842 - acc: 0.6754 - val_loss: 5.2707 - val_acc: 0.6698\n",
      "Epoch 19/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 5.1990 - acc: 0.6746 - val_loss: 5.1058 - val_acc: 0.6808\n",
      "Epoch 20/500\n",
      "7396/7396 [==============================] - 1s 127us/step - loss: 5.1696 - acc: 0.6764 - val_loss: 5.1371 - val_acc: 0.6786\n",
      "Epoch 21/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.1313 - acc: 0.6790 - val_loss: 5.1960 - val_acc: 0.6747\n",
      "Epoch 22/500\n",
      "7396/7396 [==============================] - 1s 127us/step - loss: 5.2608 - acc: 0.6706 - val_loss: 5.1499 - val_acc: 0.6777\n",
      "Epoch 23/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 5.0346 - acc: 0.6852 - val_loss: 5.1792 - val_acc: 0.6766\n",
      "Epoch 24/500\n",
      "7396/7396 [==============================] - 1s 133us/step - loss: 5.0798 - acc: 0.6827 - val_loss: 5.0861 - val_acc: 0.6821\n",
      "Epoch 25/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.0745 - acc: 0.6829 - val_loss: 5.1270 - val_acc: 0.6791\n",
      "Epoch 26/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.0863 - acc: 0.6816 - val_loss: 5.2000 - val_acc: 0.6744\n",
      "Epoch 27/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 5.3382 - acc: 0.6655 - val_loss: 5.2000 - val_acc: 0.6742\n",
      "Epoch 28/500\n",
      "7396/7396 [==============================] - 1s 125us/step - loss: 5.2766 - acc: 0.6694 - val_loss: 5.1929 - val_acc: 0.6747\n",
      "Epoch 29/500\n",
      "7396/7396 [==============================] - 1s 139us/step - loss: 5.2637 - acc: 0.6705 - val_loss: 5.1953 - val_acc: 0.6747\n",
      "Epoch 30/500\n",
      "7396/7396 [==============================] - 1s 127us/step - loss: 5.2112 - acc: 0.6739 - val_loss: 5.1976 - val_acc: 0.6744\n",
      "Epoch 31/500\n",
      "7396/7396 [==============================] - 1s 125us/step - loss: 5.1806 - acc: 0.6758 - val_loss: 5.1782 - val_acc: 0.6758\n",
      "Epoch 32/500\n",
      "7396/7396 [==============================] - 1s 152us/step - loss: 5.2624 - acc: 0.6704 - val_loss: 5.1837 - val_acc: 0.6755\n",
      "Epoch 33/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.2232 - acc: 0.6729 - val_loss: 5.1806 - val_acc: 0.6755\n",
      "Epoch 34/500\n",
      "7396/7396 [==============================] - 1s 137us/step - loss: 5.1163 - acc: 0.6798 - val_loss: 5.0762 - val_acc: 0.6824\n",
      "Epoch 35/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.1575 - acc: 0.6775 - val_loss: 5.0918 - val_acc: 0.6816\n",
      "Epoch 36/500\n",
      "7396/7396 [==============================] - 1s 131us/step - loss: 5.1163 - acc: 0.6800 - val_loss: 5.0433 - val_acc: 0.6849\n",
      "Epoch 37/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.1086 - acc: 0.6808 - val_loss: 5.0402 - val_acc: 0.6851\n",
      "Epoch 38/500\n",
      "7396/7396 [==============================] - 1s 125us/step - loss: 5.0080 - acc: 0.6871 - val_loss: 5.1369 - val_acc: 0.6791\n",
      "Epoch 39/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.1134 - acc: 0.6812 - val_loss: 5.1626 - val_acc: 0.6777\n",
      "Epoch 40/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.1699 - acc: 0.6778 - val_loss: 5.2595 - val_acc: 0.6720\n",
      "Epoch 41/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.1604 - acc: 0.6781 - val_loss: 5.1429 - val_acc: 0.6786\n",
      "Epoch 42/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 5.1180 - acc: 0.6806 - val_loss: 5.1481 - val_acc: 0.6786\n",
      "Epoch 43/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 5.0125 - acc: 0.6874 - val_loss: 5.2465 - val_acc: 0.6725\n",
      "Epoch 44/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 5.1289 - acc: 0.6801 - val_loss: 5.2132 - val_acc: 0.6747\n",
      "Epoch 45/500\n",
      "7396/7396 [==============================] - 1s 116us/step - loss: 5.0430 - acc: 0.6850 - val_loss: 5.1196 - val_acc: 0.6802\n",
      "Epoch 46/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.0558 - acc: 0.6843 - val_loss: 5.0134 - val_acc: 0.6868\n",
      "Epoch 47/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 5.1429 - acc: 0.6790 - val_loss: 5.1170 - val_acc: 0.6805\n",
      "Epoch 48/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.1582 - acc: 0.6783 - val_loss: 5.2174 - val_acc: 0.6744\n",
      "Epoch 49/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.1788 - acc: 0.6771 - val_loss: 5.1476 - val_acc: 0.6786\n",
      "Epoch 50/500\n",
      "7396/7396 [==============================] - 1s 123us/step - loss: 5.0656 - acc: 0.6839 - val_loss: 5.0890 - val_acc: 0.6821\n",
      "Epoch 51/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 5.0412 - acc: 0.6854 - val_loss: 5.0890 - val_acc: 0.6821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 5.0722 - acc: 0.6828 - val_loss: 5.0730 - val_acc: 0.6827\n",
      "Epoch 53/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.1731 - acc: 0.6762 - val_loss: 5.1724 - val_acc: 0.6758\n",
      "Epoch 54/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 5.1657 - acc: 0.6764 - val_loss: 5.2052 - val_acc: 0.6742\n",
      "Epoch 55/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.1182 - acc: 0.6794 - val_loss: 5.0849 - val_acc: 0.6819\n",
      "Epoch 56/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.1768 - acc: 0.6759 - val_loss: 5.1885 - val_acc: 0.6753\n",
      "Epoch 57/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 5.0640 - acc: 0.6831 - val_loss: 5.1064 - val_acc: 0.6805\n",
      "Epoch 58/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.1226 - acc: 0.6794 - val_loss: 5.0982 - val_acc: 0.6813\n",
      "Epoch 59/500\n",
      "7396/7396 [==============================] - 1s 119us/step - loss: 5.0216 - acc: 0.6860 - val_loss: 5.0860 - val_acc: 0.6821\n",
      "Epoch 60/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.0512 - acc: 0.6843 - val_loss: 5.0831 - val_acc: 0.6821\n",
      "Epoch 61/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.0407 - acc: 0.6850 - val_loss: 5.1044 - val_acc: 0.6808\n",
      "Epoch 62/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.0509 - acc: 0.6843 - val_loss: 5.0757 - val_acc: 0.6827\n",
      "Epoch 63/500\n",
      "7396/7396 [==============================] - 1s 109us/step - loss: 5.0036 - acc: 0.6871 - val_loss: 5.1117 - val_acc: 0.6808\n",
      "Epoch 64/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.2752 - acc: 0.6710 - val_loss: 5.2571 - val_acc: 0.6720\n",
      "Epoch 65/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.3358 - acc: 0.6673 - val_loss: 5.1369 - val_acc: 0.6791\n",
      "Epoch 66/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.1681 - acc: 0.6771 - val_loss: 5.1524 - val_acc: 0.6783\n",
      "Epoch 67/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.1482 - acc: 0.6786 - val_loss: 5.1798 - val_acc: 0.6766\n",
      "Epoch 68/500\n",
      "7396/7396 [==============================] - 1s 116us/step - loss: 5.1139 - acc: 0.6809 - val_loss: 5.0669 - val_acc: 0.6835\n",
      "Epoch 69/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 5.1319 - acc: 0.6794 - val_loss: 5.0395 - val_acc: 0.6849\n",
      "Epoch 70/500\n",
      "7396/7396 [==============================] - 1s 120us/step - loss: 5.1350 - acc: 0.6794 - val_loss: 5.0943 - val_acc: 0.6816\n",
      "Epoch 71/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 5.1368 - acc: 0.6790 - val_loss: 5.0912 - val_acc: 0.6816\n",
      "Epoch 72/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.0661 - acc: 0.6833 - val_loss: 5.1074 - val_acc: 0.6808\n",
      "Epoch 73/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 5.0505 - acc: 0.6844 - val_loss: 5.1107 - val_acc: 0.6805\n",
      "Epoch 74/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.0505 - acc: 0.6844 - val_loss: 5.0669 - val_acc: 0.6832\n",
      "Epoch 75/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 5.1061 - acc: 0.6808 - val_loss: 5.1022 - val_acc: 0.6808\n",
      "Epoch 76/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.1443 - acc: 0.6781 - val_loss: 5.0264 - val_acc: 0.6857\n",
      "Epoch 77/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.0612 - acc: 0.6836 - val_loss: 5.0538 - val_acc: 0.6841\n",
      "Epoch 78/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 5.1571 - acc: 0.6777 - val_loss: 5.0529 - val_acc: 0.6841\n",
      "Epoch 79/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.1628 - acc: 0.6773 - val_loss: 5.0384 - val_acc: 0.6851\n",
      "Epoch 80/500\n",
      "7396/7396 [==============================] - 1s 116us/step - loss: 5.0738 - acc: 0.6828 - val_loss: 5.0648 - val_acc: 0.6835\n",
      "Epoch 81/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0439 - acc: 0.6848 - val_loss: 5.0417 - val_acc: 0.6846\n",
      "Epoch 82/500\n",
      "7396/7396 [==============================] - 1s 116us/step - loss: 5.0761 - acc: 0.6829 - val_loss: 5.0762 - val_acc: 0.6827\n",
      "Epoch 83/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.0948 - acc: 0.6817 - val_loss: 5.0629 - val_acc: 0.6835\n",
      "Epoch 84/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.1265 - acc: 0.6797 - val_loss: 5.0207 - val_acc: 0.6860\n",
      "Epoch 85/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.0861 - acc: 0.6820 - val_loss: 5.0658 - val_acc: 0.6830\n",
      "Epoch 86/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.1181 - acc: 0.6800 - val_loss: 5.0353 - val_acc: 0.6851\n",
      "Epoch 87/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 5.0845 - acc: 0.6823 - val_loss: 5.0855 - val_acc: 0.6821\n",
      "Epoch 88/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.0427 - acc: 0.6847 - val_loss: 5.0816 - val_acc: 0.6819\n",
      "Epoch 89/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 5.1163 - acc: 0.6798 - val_loss: 5.0759 - val_acc: 0.6824\n",
      "Epoch 90/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.0992 - acc: 0.6812 - val_loss: 5.0553 - val_acc: 0.6838\n",
      "Epoch 91/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.0910 - acc: 0.6816 - val_loss: 5.0494 - val_acc: 0.6843\n",
      "Epoch 92/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9495 - acc: 0.6908 - val_loss: 5.0745 - val_acc: 0.6830\n",
      "Epoch 93/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.1146 - acc: 0.6806 - val_loss: 5.0818 - val_acc: 0.6821\n",
      "Epoch 94/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.0148 - acc: 0.6867 - val_loss: 5.0535 - val_acc: 0.6838\n",
      "Epoch 95/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 4.9921 - acc: 0.6878 - val_loss: 5.0823 - val_acc: 0.6824\n",
      "Epoch 96/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.0293 - acc: 0.6858 - val_loss: 5.0592 - val_acc: 0.6835\n",
      "Epoch 97/500\n",
      "7396/7396 [==============================] - 1s 102us/step - loss: 5.0200 - acc: 0.6860 - val_loss: 5.0723 - val_acc: 0.6827\n",
      "Epoch 98/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0032 - acc: 0.6870 - val_loss: 5.0669 - val_acc: 0.6830\n",
      "Epoch 99/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.0521 - acc: 0.6837 - val_loss: 5.0525 - val_acc: 0.6838\n",
      "Epoch 100/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0145 - acc: 0.6856 - val_loss: 5.0574 - val_acc: 0.6838\n",
      "Epoch 101/500\n",
      "7396/7396 [==============================] - 1s 127us/step - loss: 4.9986 - acc: 0.6875 - val_loss: 5.0686 - val_acc: 0.6832\n",
      "Epoch 102/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.0292 - acc: 0.6859 - val_loss: 5.0732 - val_acc: 0.6830\n",
      "Epoch 103/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0669 - acc: 0.6833 - val_loss: 5.0715 - val_acc: 0.6830\n",
      "Epoch 104/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 5.0789 - acc: 0.6824 - val_loss: 5.0313 - val_acc: 0.6854\n",
      "Epoch 105/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 5.0597 - acc: 0.6832 - val_loss: 5.0491 - val_acc: 0.6843\n",
      "Epoch 106/500\n",
      "7396/7396 [==============================] - 1s 137us/step - loss: 5.0864 - acc: 0.6821 - val_loss: 5.0788 - val_acc: 0.6827\n",
      "Epoch 107/500\n",
      "7396/7396 [==============================] - 1s 135us/step - loss: 5.0377 - acc: 0.6850 - val_loss: 5.0831 - val_acc: 0.6824\n",
      "Epoch 108/500\n",
      "7396/7396 [==============================] - 1s 125us/step - loss: 4.9999 - acc: 0.6878 - val_loss: 5.1819 - val_acc: 0.6764\n",
      "Epoch 109/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.1312 - acc: 0.6796 - val_loss: 5.1291 - val_acc: 0.6797\n",
      "Epoch 110/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 5.1112 - acc: 0.6810 - val_loss: 5.1411 - val_acc: 0.6788\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.1785 - acc: 0.6770 - val_loss: 5.2236 - val_acc: 0.6742\n",
      "Epoch 112/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.2096 - acc: 0.6754 - val_loss: 5.2236 - val_acc: 0.6742\n",
      "Epoch 113/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.1854 - acc: 0.6767 - val_loss: 5.1911 - val_acc: 0.6758\n",
      "Epoch 114/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.0782 - acc: 0.6833 - val_loss: 5.1944 - val_acc: 0.6755\n",
      "Epoch 115/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.0453 - acc: 0.6854 - val_loss: 5.1944 - val_acc: 0.6755\n",
      "Epoch 116/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.2032 - acc: 0.6756 - val_loss: 5.2114 - val_acc: 0.6747\n",
      "Epoch 117/500\n",
      "7396/7396 [==============================] - 1s 116us/step - loss: 5.0798 - acc: 0.6832 - val_loss: 5.1947 - val_acc: 0.6758\n",
      "Epoch 118/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.1765 - acc: 0.6771 - val_loss: 5.2119 - val_acc: 0.6747\n",
      "Epoch 119/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.1793 - acc: 0.6770 - val_loss: 5.2343 - val_acc: 0.6733\n",
      "Epoch 120/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.1400 - acc: 0.6790 - val_loss: 5.1121 - val_acc: 0.6808\n",
      "Epoch 121/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.0599 - acc: 0.6839 - val_loss: 5.1118 - val_acc: 0.6805\n",
      "Epoch 122/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.0065 - acc: 0.6873 - val_loss: 5.0884 - val_acc: 0.6821\n",
      "Epoch 123/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.1370 - acc: 0.6793 - val_loss: 5.1116 - val_acc: 0.6808\n",
      "Epoch 124/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0216 - acc: 0.6866 - val_loss: 5.0975 - val_acc: 0.6816\n",
      "Epoch 125/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9906 - acc: 0.6885 - val_loss: 5.1062 - val_acc: 0.6810\n",
      "Epoch 126/500\n",
      "7396/7396 [==============================] - 1s 109us/step - loss: 5.0187 - acc: 0.6867 - val_loss: 5.1045 - val_acc: 0.6810\n",
      "Epoch 127/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 5.0040 - acc: 0.6874 - val_loss: 5.1066 - val_acc: 0.6810\n",
      "Epoch 128/500\n",
      "7396/7396 [==============================] - 1s 127us/step - loss: 5.0503 - acc: 0.6846 - val_loss: 5.1040 - val_acc: 0.6813\n",
      "Epoch 129/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.0375 - acc: 0.6856 - val_loss: 5.1040 - val_acc: 0.6813\n",
      "Epoch 130/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 4.9387 - acc: 0.6917 - val_loss: 5.1064 - val_acc: 0.6810\n",
      "Epoch 131/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.0086 - acc: 0.6873 - val_loss: 5.1067 - val_acc: 0.6810\n",
      "Epoch 132/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0698 - acc: 0.6831 - val_loss: 5.1117 - val_acc: 0.6805\n",
      "Epoch 133/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 5.0640 - acc: 0.6837 - val_loss: 5.0784 - val_acc: 0.6827\n",
      "Epoch 134/500\n",
      "7396/7396 [==============================] - 1s 102us/step - loss: 4.9853 - acc: 0.6883 - val_loss: 5.0825 - val_acc: 0.6824\n",
      "Epoch 135/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 4.9947 - acc: 0.6881 - val_loss: 5.0868 - val_acc: 0.6821\n",
      "Epoch 136/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9866 - acc: 0.6882 - val_loss: 5.0950 - val_acc: 0.6816\n",
      "Epoch 137/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 5.0275 - acc: 0.6855 - val_loss: 5.0583 - val_acc: 0.6838\n",
      "Epoch 138/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9389 - acc: 0.6908 - val_loss: 5.0829 - val_acc: 0.6824\n",
      "Epoch 139/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.0134 - acc: 0.6862 - val_loss: 5.0829 - val_acc: 0.6824\n",
      "Epoch 140/500\n",
      "7396/7396 [==============================] - 1s 169us/step - loss: 4.9969 - acc: 0.6875 - val_loss: 5.0965 - val_acc: 0.6816\n",
      "Epoch 141/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9246 - acc: 0.6924 - val_loss: 5.1157 - val_acc: 0.6805\n",
      "Epoch 142/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 5.0121 - acc: 0.6870 - val_loss: 5.1163 - val_acc: 0.6805\n",
      "Epoch 143/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9832 - acc: 0.6886 - val_loss: 5.1163 - val_acc: 0.6805\n",
      "Epoch 144/500\n",
      "7396/7396 [==============================] - 1s 196us/step - loss: 4.9379 - acc: 0.6909 - val_loss: 5.1023 - val_acc: 0.6813\n",
      "Epoch 145/500\n",
      "7396/7396 [==============================] - 1s 127us/step - loss: 4.9385 - acc: 0.6913 - val_loss: 5.1065 - val_acc: 0.6810\n",
      "Epoch 146/500\n",
      "7396/7396 [==============================] - 1s 127us/step - loss: 4.9467 - acc: 0.6908 - val_loss: 5.1586 - val_acc: 0.6780\n",
      "Epoch 147/500\n",
      "7396/7396 [==============================] - 1s 163us/step - loss: 5.0389 - acc: 0.6855 - val_loss: 5.1517 - val_acc: 0.6783\n",
      "Epoch 148/500\n",
      "7396/7396 [==============================] - 1s 129us/step - loss: 5.0761 - acc: 0.6832 - val_loss: 5.1867 - val_acc: 0.6764\n",
      "Epoch 149/500\n",
      "7396/7396 [==============================] - 1s 158us/step - loss: 5.0501 - acc: 0.6852 - val_loss: 5.2208 - val_acc: 0.6744\n",
      "Epoch 150/500\n",
      "7396/7396 [==============================] - 1s 123us/step - loss: 5.2502 - acc: 0.6729 - val_loss: 5.3348 - val_acc: 0.6676\n",
      "Epoch 151/500\n",
      "7396/7396 [==============================] - 1s 131us/step - loss: 5.1935 - acc: 0.6764 - val_loss: 5.2309 - val_acc: 0.6739\n",
      "Epoch 152/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.1331 - acc: 0.6800 - val_loss: 5.2399 - val_acc: 0.6733\n",
      "Epoch 153/500\n",
      "7396/7396 [==============================] - 1s 156us/step - loss: 5.1820 - acc: 0.6771 - val_loss: 5.2049 - val_acc: 0.6753\n",
      "Epoch 154/500\n",
      "7396/7396 [==============================] - 1s 120us/step - loss: 5.0467 - acc: 0.6854 - val_loss: 5.1973 - val_acc: 0.6758\n",
      "Epoch 155/500\n",
      "7396/7396 [==============================] - 1s 102us/step - loss: 5.0788 - acc: 0.6832 - val_loss: 5.2209 - val_acc: 0.6742\n",
      "Epoch 156/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.0807 - acc: 0.6828 - val_loss: 5.1853 - val_acc: 0.6764\n",
      "Epoch 157/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.1117 - acc: 0.6814 - val_loss: 5.2261 - val_acc: 0.6742\n",
      "Epoch 158/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.1339 - acc: 0.6800 - val_loss: 5.1986 - val_acc: 0.6758\n",
      "Epoch 159/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.0916 - acc: 0.6827 - val_loss: 5.1986 - val_acc: 0.6758\n",
      "Epoch 160/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.2034 - acc: 0.6758 - val_loss: 5.2906 - val_acc: 0.6701\n",
      "Epoch 161/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.5932 - acc: 0.6517 - val_loss: 5.6097 - val_acc: 0.6508\n",
      "Epoch 162/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 5.5262 - acc: 0.6559 - val_loss: 5.3852 - val_acc: 0.6646\n",
      "Epoch 163/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.1532 - acc: 0.6789 - val_loss: 5.2393 - val_acc: 0.6733\n",
      "Epoch 164/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.2240 - acc: 0.6743 - val_loss: 5.2192 - val_acc: 0.6744\n",
      "Epoch 165/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.0055 - acc: 0.6877 - val_loss: 5.1622 - val_acc: 0.6777\n",
      "Epoch 166/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0650 - acc: 0.6840 - val_loss: 5.1595 - val_acc: 0.6777\n",
      "Epoch 167/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0122 - acc: 0.6873 - val_loss: 5.1683 - val_acc: 0.6775\n",
      "Epoch 168/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9897 - acc: 0.6886 - val_loss: 5.1808 - val_acc: 0.6766\n",
      "Epoch 169/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 5.0162 - acc: 0.6871 - val_loss: 5.1628 - val_acc: 0.6777\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9782 - acc: 0.6894 - val_loss: 5.1874 - val_acc: 0.6764\n",
      "Epoch 171/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.0328 - acc: 0.6859 - val_loss: 5.2028 - val_acc: 0.6753\n",
      "Epoch 172/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 5.1071 - acc: 0.6813 - val_loss: 5.2014 - val_acc: 0.6755\n",
      "Epoch 173/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.0393 - acc: 0.6858 - val_loss: 5.1669 - val_acc: 0.6777\n",
      "Epoch 174/500\n",
      "7396/7396 [==============================] - 1s 120us/step - loss: 5.0655 - acc: 0.6842 - val_loss: 5.2055 - val_acc: 0.6753\n",
      "Epoch 175/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9680 - acc: 0.6902 - val_loss: 5.2055 - val_acc: 0.6753\n",
      "Epoch 176/500\n",
      "7396/7396 [==============================] - 1s 93us/step - loss: 5.0877 - acc: 0.6827 - val_loss: 5.2942 - val_acc: 0.6698\n",
      "Epoch 177/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.0549 - acc: 0.6846 - val_loss: 5.1670 - val_acc: 0.6777\n",
      "Epoch 178/500\n",
      "7396/7396 [==============================] - 1s 93us/step - loss: 5.0909 - acc: 0.6825 - val_loss: 5.1538 - val_acc: 0.6786\n",
      "Epoch 179/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.0303 - acc: 0.6859 - val_loss: 5.1425 - val_acc: 0.6788\n",
      "Epoch 180/500\n",
      "7396/7396 [==============================] - 1s 93us/step - loss: 4.9477 - acc: 0.6910 - val_loss: 5.1614 - val_acc: 0.6777\n",
      "Epoch 181/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 4.9701 - acc: 0.6900 - val_loss: 5.1675 - val_acc: 0.6775\n",
      "Epoch 182/500\n",
      "7396/7396 [==============================] - 1s 93us/step - loss: 4.9462 - acc: 0.6915 - val_loss: 5.1374 - val_acc: 0.6794\n",
      "Epoch 183/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0134 - acc: 0.6873 - val_loss: 5.1240 - val_acc: 0.6802\n",
      "Epoch 184/500\n",
      "7396/7396 [==============================] - 1s 146us/step - loss: 5.0189 - acc: 0.6870 - val_loss: 5.1740 - val_acc: 0.6772\n",
      "Epoch 185/500\n",
      "7396/7396 [==============================] - 1s 156us/step - loss: 4.9626 - acc: 0.6904 - val_loss: 5.1740 - val_acc: 0.6772\n",
      "Epoch 186/500\n",
      "7396/7396 [==============================] - 1s 123us/step - loss: 5.0053 - acc: 0.6877 - val_loss: 5.1688 - val_acc: 0.6775\n",
      "Epoch 187/500\n",
      "7396/7396 [==============================] - 1s 144us/step - loss: 4.9149 - acc: 0.6932 - val_loss: 5.1448 - val_acc: 0.6788\n",
      "Epoch 188/500\n",
      "7396/7396 [==============================] - 1s 139us/step - loss: 4.9037 - acc: 0.6939 - val_loss: 5.1544 - val_acc: 0.6780\n",
      "Epoch 189/500\n",
      "7396/7396 [==============================] - 1s 137us/step - loss: 4.9563 - acc: 0.6905 - val_loss: 5.1466 - val_acc: 0.6788\n",
      "Epoch 190/500\n",
      "7396/7396 [==============================] - 1s 154us/step - loss: 4.9460 - acc: 0.6913 - val_loss: 5.1413 - val_acc: 0.6791\n",
      "Epoch 191/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9046 - acc: 0.6939 - val_loss: 5.1413 - val_acc: 0.6791\n",
      "Epoch 192/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 4.9046 - acc: 0.6939 - val_loss: 5.1413 - val_acc: 0.6791\n",
      "Epoch 193/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9542 - acc: 0.6908 - val_loss: 5.1413 - val_acc: 0.6791\n",
      "Epoch 194/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 4.9672 - acc: 0.6901 - val_loss: 5.1413 - val_acc: 0.6791\n",
      "Epoch 195/500\n",
      "7396/7396 [==============================] - 1s 169us/step - loss: 4.9677 - acc: 0.6901 - val_loss: 5.1413 - val_acc: 0.6791\n",
      "Epoch 196/500\n",
      "7396/7396 [==============================] - 1s 163us/step - loss: 4.9761 - acc: 0.6894 - val_loss: 5.1413 - val_acc: 0.6791\n",
      "Epoch 197/500\n",
      "7396/7396 [==============================] - 1s 150us/step - loss: 4.9681 - acc: 0.6898 - val_loss: 5.1440 - val_acc: 0.6788\n",
      "Epoch 198/500\n",
      "7396/7396 [==============================] - 1s 131us/step - loss: 4.9581 - acc: 0.6905 - val_loss: 5.1043 - val_acc: 0.6810\n",
      "Epoch 199/500\n",
      "7396/7396 [==============================] - 1s 146us/step - loss: 4.9063 - acc: 0.6936 - val_loss: 5.1394 - val_acc: 0.6791\n",
      "Epoch 200/500\n",
      "7396/7396 [==============================] - 1s 146us/step - loss: 4.9078 - acc: 0.6933 - val_loss: 5.1632 - val_acc: 0.6777\n",
      "Epoch 201/500\n",
      "7396/7396 [==============================] - 1s 129us/step - loss: 4.9003 - acc: 0.6942 - val_loss: 5.1632 - val_acc: 0.6777\n",
      "Epoch 202/500\n",
      "7396/7396 [==============================] - 1s 150us/step - loss: 4.9810 - acc: 0.6892 - val_loss: 5.2011 - val_acc: 0.6755\n",
      "Epoch 203/500\n",
      "7396/7396 [==============================] - 1s 129us/step - loss: 5.0696 - acc: 0.6836 - val_loss: 5.1520 - val_acc: 0.6786\n",
      "Epoch 204/500\n",
      "7396/7396 [==============================] - 1s 152us/step - loss: 4.9258 - acc: 0.6925 - val_loss: 5.1520 - val_acc: 0.6786\n",
      "Epoch 205/500\n",
      "7396/7396 [==============================] - 1s 142us/step - loss: 4.9647 - acc: 0.6901 - val_loss: 5.1608 - val_acc: 0.6780\n",
      "Epoch 206/500\n",
      "7396/7396 [==============================] - 1s 152us/step - loss: 5.0561 - acc: 0.6847 - val_loss: 5.1664 - val_acc: 0.6777\n",
      "Epoch 207/500\n",
      "7396/7396 [==============================] - 1s 146us/step - loss: 4.9854 - acc: 0.6892 - val_loss: 5.1664 - val_acc: 0.6777\n",
      "Epoch 208/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 4.9631 - acc: 0.6905 - val_loss: 5.1921 - val_acc: 0.6761\n",
      "Epoch 209/500\n",
      "7396/7396 [==============================] - 1s 167us/step - loss: 4.9924 - acc: 0.6886 - val_loss: 5.1556 - val_acc: 0.6783\n",
      "Epoch 210/500\n",
      "7396/7396 [==============================] - 1s 129us/step - loss: 4.9667 - acc: 0.6901 - val_loss: 5.1605 - val_acc: 0.6780\n",
      "Epoch 211/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9956 - acc: 0.6883 - val_loss: 5.1634 - val_acc: 0.6780\n",
      "Epoch 212/500\n",
      "7396/7396 [==============================] - 1s 144us/step - loss: 5.1245 - acc: 0.6806 - val_loss: 5.1907 - val_acc: 0.6764\n",
      "Epoch 213/500\n",
      "7396/7396 [==============================] - 1s 135us/step - loss: 5.0544 - acc: 0.6846 - val_loss: 5.1879 - val_acc: 0.6764\n",
      "Epoch 214/500\n",
      "7396/7396 [==============================] - 1s 123us/step - loss: 4.9990 - acc: 0.6882 - val_loss: 5.1965 - val_acc: 0.6758\n",
      "Epoch 215/500\n",
      "7396/7396 [==============================] - 1s 135us/step - loss: 4.9827 - acc: 0.6892 - val_loss: 5.1965 - val_acc: 0.6758\n",
      "Epoch 216/500\n",
      "7396/7396 [==============================] - 1s 152us/step - loss: 5.0532 - acc: 0.6850 - val_loss: 5.1628 - val_acc: 0.6780\n",
      "Epoch 217/500\n",
      "7396/7396 [==============================] - 1s 137us/step - loss: 5.0648 - acc: 0.6840 - val_loss: 5.1920 - val_acc: 0.6761\n",
      "Epoch 218/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.0051 - acc: 0.6878 - val_loss: 5.1609 - val_acc: 0.6780\n",
      "Epoch 219/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0720 - acc: 0.6837 - val_loss: 5.1966 - val_acc: 0.6758\n",
      "Epoch 220/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 5.0261 - acc: 0.6866 - val_loss: 5.1966 - val_acc: 0.6758\n",
      "Epoch 221/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 5.0492 - acc: 0.6852 - val_loss: 5.1770 - val_acc: 0.6772\n",
      "Epoch 222/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.1201 - acc: 0.6809 - val_loss: 5.1729 - val_acc: 0.6775\n",
      "Epoch 223/500\n",
      "7396/7396 [==============================] - 1s 102us/step - loss: 5.0297 - acc: 0.6863 - val_loss: 5.1457 - val_acc: 0.6788\n",
      "Epoch 224/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9601 - acc: 0.6904 - val_loss: 5.0928 - val_acc: 0.6819\n",
      "Epoch 225/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9375 - acc: 0.6915 - val_loss: 5.0928 - val_acc: 0.6819\n",
      "Epoch 226/500\n",
      "7396/7396 [==============================] - 1s 95us/step - loss: 4.9695 - acc: 0.6897 - val_loss: 5.1160 - val_acc: 0.6805\n",
      "Epoch 227/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 4.9291 - acc: 0.6920 - val_loss: 5.1109 - val_acc: 0.6808\n",
      "Epoch 228/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9322 - acc: 0.6917 - val_loss: 5.0958 - val_acc: 0.6816\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9542 - acc: 0.6902 - val_loss: 5.1024 - val_acc: 0.6813\n",
      "Epoch 230/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.8990 - acc: 0.6939 - val_loss: 5.1024 - val_acc: 0.6813\n",
      "Epoch 231/500\n",
      "7396/7396 [==============================] - 1s 93us/step - loss: 5.0161 - acc: 0.6869 - val_loss: 5.1025 - val_acc: 0.6813\n",
      "Epoch 232/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.8565 - acc: 0.6967 - val_loss: 5.1441 - val_acc: 0.6788\n",
      "Epoch 233/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 4.8549 - acc: 0.6970 - val_loss: 5.1390 - val_acc: 0.6791\n",
      "Epoch 234/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9083 - acc: 0.6933 - val_loss: 5.1048 - val_acc: 0.6810\n",
      "Epoch 235/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9213 - acc: 0.6923 - val_loss: 5.0897 - val_acc: 0.6819\n",
      "Epoch 236/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 4.8902 - acc: 0.6946 - val_loss: 5.1150 - val_acc: 0.6805\n",
      "Epoch 237/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9286 - acc: 0.6920 - val_loss: 5.1235 - val_acc: 0.6799\n",
      "Epoch 238/500\n",
      "7396/7396 [==============================] - 1s 93us/step - loss: 4.9337 - acc: 0.6917 - val_loss: 5.1153 - val_acc: 0.6805\n",
      "Epoch 239/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 4.8816 - acc: 0.6948 - val_loss: 5.1163 - val_acc: 0.6802\n",
      "Epoch 240/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9878 - acc: 0.6883 - val_loss: 5.1314 - val_acc: 0.6794\n",
      "Epoch 241/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9141 - acc: 0.6929 - val_loss: 5.1001 - val_acc: 0.6813\n",
      "Epoch 242/500\n",
      "7396/7396 [==============================] - 1s 95us/step - loss: 4.9170 - acc: 0.6927 - val_loss: 5.1013 - val_acc: 0.6813\n",
      "Epoch 243/500\n",
      "7396/7396 [==============================] - 1s 102us/step - loss: 4.9319 - acc: 0.6920 - val_loss: 5.1204 - val_acc: 0.6802\n",
      "Epoch 244/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0012 - acc: 0.6878 - val_loss: 5.1204 - val_acc: 0.6802\n",
      "Epoch 245/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.8909 - acc: 0.6946 - val_loss: 5.1253 - val_acc: 0.6799\n",
      "Epoch 246/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 4.9565 - acc: 0.6905 - val_loss: 5.1332 - val_acc: 0.6794\n",
      "Epoch 247/500\n",
      "7396/7396 [==============================] - 1s 95us/step - loss: 4.9236 - acc: 0.6928 - val_loss: 5.1411 - val_acc: 0.6791\n",
      "Epoch 248/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9306 - acc: 0.6923 - val_loss: 5.1441 - val_acc: 0.6788\n",
      "Epoch 249/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.8675 - acc: 0.6962 - val_loss: 5.1449 - val_acc: 0.6788\n",
      "Epoch 250/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 4.9975 - acc: 0.6881 - val_loss: 5.1592 - val_acc: 0.6780\n",
      "Epoch 251/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9296 - acc: 0.6924 - val_loss: 5.1398 - val_acc: 0.6791\n",
      "Epoch 252/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9665 - acc: 0.6900 - val_loss: 5.1546 - val_acc: 0.6780\n",
      "Epoch 253/500\n",
      "7396/7396 [==============================] - 1s 93us/step - loss: 4.9336 - acc: 0.6919 - val_loss: 5.1546 - val_acc: 0.6780\n",
      "Epoch 254/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9413 - acc: 0.6915 - val_loss: 5.1532 - val_acc: 0.6783\n",
      "Epoch 255/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.8906 - acc: 0.6948 - val_loss: 5.1620 - val_acc: 0.6777\n",
      "Epoch 256/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 4.9351 - acc: 0.6919 - val_loss: 5.1867 - val_acc: 0.6764\n",
      "Epoch 257/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9901 - acc: 0.6886 - val_loss: 5.1665 - val_acc: 0.6777\n",
      "Epoch 258/500\n",
      "7396/7396 [==============================] - 1s 93us/step - loss: 5.0027 - acc: 0.6881 - val_loss: 5.1997 - val_acc: 0.6755\n",
      "Epoch 259/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.0529 - acc: 0.6848 - val_loss: 5.2009 - val_acc: 0.6755\n",
      "Epoch 260/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9823 - acc: 0.6893 - val_loss: 5.1920 - val_acc: 0.6761\n",
      "Epoch 261/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.0500 - acc: 0.6851 - val_loss: 5.2098 - val_acc: 0.6750\n",
      "Epoch 262/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.0004 - acc: 0.6878 - val_loss: 5.1622 - val_acc: 0.6780\n",
      "Epoch 263/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 5.0219 - acc: 0.6869 - val_loss: 5.2025 - val_acc: 0.6753\n",
      "Epoch 264/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 4.9639 - acc: 0.6902 - val_loss: 5.1620 - val_acc: 0.6777\n",
      "Epoch 265/500\n",
      "7396/7396 [==============================] - 1s 123us/step - loss: 4.9750 - acc: 0.6893 - val_loss: 5.1323 - val_acc: 0.6797\n",
      "Epoch 266/500\n",
      "7396/7396 [==============================] - 1s 135us/step - loss: 4.9906 - acc: 0.6885 - val_loss: 5.1323 - val_acc: 0.6797\n",
      "Epoch 267/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9298 - acc: 0.6924 - val_loss: 5.1323 - val_acc: 0.6797\n",
      "Epoch 268/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 4.9407 - acc: 0.6916 - val_loss: 5.1445 - val_acc: 0.6788\n",
      "Epoch 269/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.8791 - acc: 0.6951 - val_loss: 5.1459 - val_acc: 0.6786\n",
      "Epoch 270/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9483 - acc: 0.6910 - val_loss: 5.1488 - val_acc: 0.6786\n",
      "Epoch 271/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 4.9900 - acc: 0.6885 - val_loss: 5.1579 - val_acc: 0.6780\n",
      "Epoch 272/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 4.9310 - acc: 0.6917 - val_loss: 5.1072 - val_acc: 0.6810\n",
      "Epoch 273/500\n",
      "7396/7396 [==============================] - 1s 125us/step - loss: 4.9266 - acc: 0.6923 - val_loss: 5.1195 - val_acc: 0.6802\n",
      "Epoch 274/500\n",
      "7396/7396 [==============================] - 1s 120us/step - loss: 4.9022 - acc: 0.6936 - val_loss: 5.1162 - val_acc: 0.6802\n",
      "Epoch 275/500\n",
      "7396/7396 [==============================] - 1s 129us/step - loss: 4.8793 - acc: 0.6951 - val_loss: 5.1153 - val_acc: 0.6802\n",
      "Epoch 276/500\n",
      "7396/7396 [==============================] - 1s 127us/step - loss: 4.9162 - acc: 0.6928 - val_loss: 5.0893 - val_acc: 0.6821\n",
      "Epoch 277/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 4.9047 - acc: 0.6935 - val_loss: 5.1017 - val_acc: 0.6813\n",
      "Epoch 278/500\n",
      "7396/7396 [==============================] - 1s 116us/step - loss: 4.8823 - acc: 0.6947 - val_loss: 5.1118 - val_acc: 0.6805\n",
      "Epoch 279/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9339 - acc: 0.6919 - val_loss: 5.1116 - val_acc: 0.6808\n",
      "Epoch 280/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 4.8883 - acc: 0.6946 - val_loss: 5.1116 - val_acc: 0.6808\n",
      "Epoch 281/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9145 - acc: 0.6931 - val_loss: 5.1439 - val_acc: 0.6788\n",
      "Epoch 282/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 4.9560 - acc: 0.6901 - val_loss: 5.1414 - val_acc: 0.6791\n",
      "Epoch 283/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 4.9391 - acc: 0.6919 - val_loss: 5.1649 - val_acc: 0.6777\n",
      "Epoch 284/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9701 - acc: 0.6898 - val_loss: 5.1550 - val_acc: 0.6783\n",
      "Epoch 285/500\n",
      "7396/7396 [==============================] - 1s 116us/step - loss: 4.9482 - acc: 0.6912 - val_loss: 5.1373 - val_acc: 0.6794\n",
      "Epoch 286/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.0031 - acc: 0.6877 - val_loss: 5.1963 - val_acc: 0.6758\n",
      "Epoch 287/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 5.0186 - acc: 0.6870 - val_loss: 5.1651 - val_acc: 0.6775\n",
      "Epoch 288/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9629 - acc: 0.6905 - val_loss: 5.1881 - val_acc: 0.6764\n",
      "Epoch 289/500\n",
      "7396/7396 [==============================] - 1s 93us/step - loss: 4.9651 - acc: 0.6902 - val_loss: 5.2008 - val_acc: 0.6755\n",
      "Epoch 290/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9628 - acc: 0.6902 - val_loss: 5.2008 - val_acc: 0.6755\n",
      "Epoch 291/500\n",
      "7396/7396 [==============================] - 1s 125us/step - loss: 4.9671 - acc: 0.6901 - val_loss: 5.2023 - val_acc: 0.6753\n",
      "Epoch 292/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9955 - acc: 0.6882 - val_loss: 5.2023 - val_acc: 0.6753\n",
      "Epoch 293/500\n",
      "7396/7396 [==============================] - 1s 140us/step - loss: 4.9521 - acc: 0.6910 - val_loss: 5.1875 - val_acc: 0.6764\n",
      "Epoch 294/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 5.0315 - acc: 0.6860 - val_loss: 5.1535 - val_acc: 0.6786\n",
      "Epoch 295/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9561 - acc: 0.6906 - val_loss: 5.2054 - val_acc: 0.6753\n",
      "Epoch 296/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 4.9876 - acc: 0.6889 - val_loss: 5.1808 - val_acc: 0.6769\n",
      "Epoch 297/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 4.9996 - acc: 0.6878 - val_loss: 5.1863 - val_acc: 0.6761\n",
      "Epoch 298/500\n",
      "7396/7396 [==============================] - 1s 120us/step - loss: 4.9536 - acc: 0.6908 - val_loss: 5.1723 - val_acc: 0.6775\n",
      "Epoch 299/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0765 - acc: 0.6835 - val_loss: 5.2088 - val_acc: 0.6753\n",
      "Epoch 300/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 5.1015 - acc: 0.6819 - val_loss: 5.1857 - val_acc: 0.6766\n",
      "Epoch 301/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 5.0323 - acc: 0.6862 - val_loss: 5.1718 - val_acc: 0.6775\n",
      "Epoch 302/500\n",
      "7396/7396 [==============================] - 1s 127us/step - loss: 5.0117 - acc: 0.6875 - val_loss: 5.1492 - val_acc: 0.6788\n",
      "Epoch 303/500\n",
      "7396/7396 [==============================] - 1s 131us/step - loss: 5.0254 - acc: 0.6866 - val_loss: 5.2053 - val_acc: 0.6753\n",
      "Epoch 304/500\n",
      "7396/7396 [==============================] - 1s 123us/step - loss: 4.9213 - acc: 0.6929 - val_loss: 5.1637 - val_acc: 0.6777\n",
      "Epoch 305/500\n",
      "7396/7396 [==============================] - 1s 133us/step - loss: 4.9290 - acc: 0.6925 - val_loss: 5.1512 - val_acc: 0.6783\n",
      "Epoch 306/500\n",
      "7396/7396 [==============================] - 1s 135us/step - loss: 4.9594 - acc: 0.6905 - val_loss: 5.1512 - val_acc: 0.6783\n",
      "Epoch 307/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9112 - acc: 0.6933 - val_loss: 5.1454 - val_acc: 0.6788\n",
      "Epoch 308/500\n",
      "7396/7396 [==============================] - 1s 142us/step - loss: 4.8890 - acc: 0.6944 - val_loss: 5.1351 - val_acc: 0.6794\n",
      "Epoch 309/500\n",
      "7396/7396 [==============================] - 1s 125us/step - loss: 4.8898 - acc: 0.6942 - val_loss: 5.1104 - val_acc: 0.6808\n",
      "Epoch 310/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.8917 - acc: 0.6940 - val_loss: 5.1104 - val_acc: 0.6808\n",
      "Epoch 311/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 4.8933 - acc: 0.6935 - val_loss: 5.1104 - val_acc: 0.6808\n",
      "Epoch 312/500\n",
      "7396/7396 [==============================] - 1s 125us/step - loss: 4.8798 - acc: 0.6946 - val_loss: 5.0912 - val_acc: 0.6819\n",
      "Epoch 313/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 4.9069 - acc: 0.6931 - val_loss: 5.0912 - val_acc: 0.6819\n",
      "Epoch 314/500\n",
      "7396/7396 [==============================] - 1s 125us/step - loss: 4.9476 - acc: 0.6905 - val_loss: 5.0566 - val_acc: 0.6838\n",
      "Epoch 315/500\n",
      "7396/7396 [==============================] - 1s 123us/step - loss: 4.9742 - acc: 0.6886 - val_loss: 5.0995 - val_acc: 0.6813\n",
      "Epoch 316/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 4.9940 - acc: 0.6874 - val_loss: 5.0178 - val_acc: 0.6862\n",
      "Epoch 317/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9772 - acc: 0.6882 - val_loss: 5.0123 - val_acc: 0.6862\n",
      "Epoch 318/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.0140 - acc: 0.6856 - val_loss: 5.0890 - val_acc: 0.6816\n",
      "Epoch 319/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 5.1287 - acc: 0.6786 - val_loss: 5.2182 - val_acc: 0.6731\n",
      "Epoch 320/500\n",
      "7396/7396 [==============================] - 1s 127us/step - loss: 5.1090 - acc: 0.6793 - val_loss: 5.2683 - val_acc: 0.6701\n",
      "Epoch 321/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.1672 - acc: 0.6755 - val_loss: 5.1871 - val_acc: 0.6753\n",
      "Epoch 322/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.0364 - acc: 0.6842 - val_loss: 5.1785 - val_acc: 0.6758\n",
      "Epoch 323/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.0859 - acc: 0.6812 - val_loss: 5.1915 - val_acc: 0.6750\n",
      "Epoch 324/500\n",
      "7396/7396 [==============================] - 1s 137us/step - loss: 5.0483 - acc: 0.6840 - val_loss: 5.0545 - val_acc: 0.6838\n",
      "Epoch 325/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9938 - acc: 0.6871 - val_loss: 5.1540 - val_acc: 0.6775\n",
      "Epoch 326/500\n",
      "7396/7396 [==============================] - 1s 127us/step - loss: 5.0876 - acc: 0.6808 - val_loss: 5.1951 - val_acc: 0.6747\n",
      "Epoch 327/500\n",
      "7396/7396 [==============================] - 1s 102us/step - loss: 5.1507 - acc: 0.6767 - val_loss: 5.2520 - val_acc: 0.6709\n",
      "Epoch 328/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.1584 - acc: 0.6767 - val_loss: 5.1733 - val_acc: 0.6761\n",
      "Epoch 329/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.0887 - acc: 0.6802 - val_loss: 5.1777 - val_acc: 0.6758\n",
      "Epoch 330/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0743 - acc: 0.6812 - val_loss: 5.1867 - val_acc: 0.6753\n",
      "Epoch 331/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 4.9971 - acc: 0.6865 - val_loss: 5.1903 - val_acc: 0.6750\n",
      "Epoch 332/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0036 - acc: 0.6863 - val_loss: 5.1435 - val_acc: 0.6780\n",
      "Epoch 333/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.0219 - acc: 0.6854 - val_loss: 5.1435 - val_acc: 0.6780\n",
      "Epoch 334/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9639 - acc: 0.6889 - val_loss: 5.1435 - val_acc: 0.6780\n",
      "Epoch 335/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 4.9883 - acc: 0.6867 - val_loss: 5.1435 - val_acc: 0.6780\n",
      "Epoch 336/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.0631 - acc: 0.6827 - val_loss: 5.1864 - val_acc: 0.6753\n",
      "Epoch 337/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0745 - acc: 0.6820 - val_loss: 5.1864 - val_acc: 0.6753\n",
      "Epoch 338/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9969 - acc: 0.6869 - val_loss: 5.1863 - val_acc: 0.6753\n",
      "Epoch 339/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.0105 - acc: 0.6859 - val_loss: 5.1452 - val_acc: 0.6780\n",
      "Epoch 340/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0418 - acc: 0.6842 - val_loss: 5.0721 - val_acc: 0.6827\n",
      "Epoch 341/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9781 - acc: 0.6879 - val_loss: 5.0721 - val_acc: 0.6827\n",
      "Epoch 342/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9998 - acc: 0.6869 - val_loss: 5.0323 - val_acc: 0.6851\n",
      "Epoch 343/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.0589 - acc: 0.6831 - val_loss: 5.1773 - val_acc: 0.6758\n",
      "Epoch 344/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9754 - acc: 0.6879 - val_loss: 5.1505 - val_acc: 0.6775\n",
      "Epoch 345/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0212 - acc: 0.6850 - val_loss: 5.1926 - val_acc: 0.6747\n",
      "Epoch 346/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.0770 - acc: 0.6816 - val_loss: 5.1885 - val_acc: 0.6750\n",
      "Epoch 347/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7396/7396 [==============================] - 1s 95us/step - loss: 4.9856 - acc: 0.6878 - val_loss: 5.1407 - val_acc: 0.6783\n",
      "Epoch 348/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.0265 - acc: 0.6851 - val_loss: 5.0221 - val_acc: 0.6860\n",
      "Epoch 349/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 4.9750 - acc: 0.6879 - val_loss: 5.0938 - val_acc: 0.6813\n",
      "Epoch 350/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.0039 - acc: 0.6867 - val_loss: 5.0349 - val_acc: 0.6851\n",
      "Epoch 351/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 4.9819 - acc: 0.6882 - val_loss: 5.0378 - val_acc: 0.6849\n",
      "Epoch 352/500\n",
      "7396/7396 [==============================] - 1s 93us/step - loss: 4.9990 - acc: 0.6871 - val_loss: 5.0088 - val_acc: 0.6868\n",
      "Epoch 353/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9476 - acc: 0.6901 - val_loss: 5.0406 - val_acc: 0.6849\n",
      "Epoch 354/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 4.9654 - acc: 0.6888 - val_loss: 5.0301 - val_acc: 0.6854\n",
      "Epoch 355/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9211 - acc: 0.6919 - val_loss: 5.0132 - val_acc: 0.6865\n",
      "Epoch 356/500\n",
      "7396/7396 [==============================] - 1s 93us/step - loss: 4.9565 - acc: 0.6890 - val_loss: 5.0288 - val_acc: 0.6854\n",
      "Epoch 357/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 4.9453 - acc: 0.6894 - val_loss: 5.1008 - val_acc: 0.6808\n",
      "Epoch 358/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9629 - acc: 0.6886 - val_loss: 5.1154 - val_acc: 0.6799\n",
      "Epoch 359/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 5.0262 - acc: 0.6846 - val_loss: 5.1528 - val_acc: 0.6775\n",
      "Epoch 360/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.0232 - acc: 0.6850 - val_loss: 5.0436 - val_acc: 0.6843\n",
      "Epoch 361/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9663 - acc: 0.6890 - val_loss: 5.0436 - val_acc: 0.6843\n",
      "Epoch 362/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9818 - acc: 0.6877 - val_loss: 5.0190 - val_acc: 0.6857\n",
      "Epoch 363/500\n",
      "7396/7396 [==============================] - 1s 127us/step - loss: 4.9259 - acc: 0.6912 - val_loss: 5.0594 - val_acc: 0.6838\n",
      "Epoch 364/500\n",
      "7396/7396 [==============================] - 1s 139us/step - loss: 5.0002 - acc: 0.6869 - val_loss: 5.0316 - val_acc: 0.6854\n",
      "Epoch 365/500\n",
      "7396/7396 [==============================] - 1s 131us/step - loss: 4.9138 - acc: 0.6924 - val_loss: 5.0262 - val_acc: 0.6857\n",
      "Epoch 366/500\n",
      "7396/7396 [==============================] - 1s 129us/step - loss: 5.0256 - acc: 0.6854 - val_loss: 5.0768 - val_acc: 0.6827\n",
      "Epoch 367/500\n",
      "7396/7396 [==============================] - 1s 135us/step - loss: 4.9394 - acc: 0.6906 - val_loss: 5.0768 - val_acc: 0.6827\n",
      "Epoch 368/500\n",
      "7396/7396 [==============================] - 1s 131us/step - loss: 4.9148 - acc: 0.6924 - val_loss: 5.0782 - val_acc: 0.6824\n",
      "Epoch 369/500\n",
      "7396/7396 [==============================] - 1s 131us/step - loss: 4.9764 - acc: 0.6885 - val_loss: 5.0226 - val_acc: 0.6860\n",
      "Epoch 370/500\n",
      "7396/7396 [==============================] - 1s 115us/step - loss: 4.9263 - acc: 0.6915 - val_loss: 5.0347 - val_acc: 0.6851\n",
      "Epoch 371/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9346 - acc: 0.6909 - val_loss: 5.0763 - val_acc: 0.6821\n",
      "Epoch 372/500\n",
      "7396/7396 [==============================] - 1s 100us/step - loss: 5.0402 - acc: 0.6836 - val_loss: 5.1550 - val_acc: 0.6772\n",
      "Epoch 373/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0294 - acc: 0.6844 - val_loss: 5.1691 - val_acc: 0.6764\n",
      "Epoch 374/500\n",
      "7396/7396 [==============================] - 1s 95us/step - loss: 5.0900 - acc: 0.6806 - val_loss: 5.2121 - val_acc: 0.6736\n",
      "Epoch 375/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.1119 - acc: 0.6783 - val_loss: 5.2079 - val_acc: 0.6739\n",
      "Epoch 376/500\n",
      "7396/7396 [==============================] - 1s 95us/step - loss: 5.1202 - acc: 0.6786 - val_loss: 5.1947 - val_acc: 0.6747\n",
      "Epoch 377/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.1305 - acc: 0.6775 - val_loss: 5.1904 - val_acc: 0.6750\n",
      "Epoch 378/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0705 - acc: 0.6819 - val_loss: 5.1904 - val_acc: 0.6750\n",
      "Epoch 379/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.0231 - acc: 0.6847 - val_loss: 5.1649 - val_acc: 0.6766\n",
      "Epoch 380/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.0646 - acc: 0.6824 - val_loss: 5.1660 - val_acc: 0.6766\n",
      "Epoch 381/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9834 - acc: 0.6871 - val_loss: 5.0476 - val_acc: 0.6843\n",
      "Epoch 382/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9322 - acc: 0.6908 - val_loss: 5.0476 - val_acc: 0.6843\n",
      "Epoch 383/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 4.9820 - acc: 0.6879 - val_loss: 5.0681 - val_acc: 0.6830\n",
      "Epoch 384/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.0693 - acc: 0.6821 - val_loss: 5.1864 - val_acc: 0.6753\n",
      "Epoch 385/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 5.1037 - acc: 0.6786 - val_loss: 5.1691 - val_acc: 0.6764\n",
      "Epoch 386/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.0939 - acc: 0.6805 - val_loss: 5.1746 - val_acc: 0.6758\n",
      "Epoch 387/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.1005 - acc: 0.6804 - val_loss: 5.1746 - val_acc: 0.6758\n",
      "Epoch 388/500\n",
      "7396/7396 [==============================] - 1s 116us/step - loss: 5.0901 - acc: 0.6804 - val_loss: 5.1691 - val_acc: 0.6764\n",
      "Epoch 389/500\n",
      "7396/7396 [==============================] - 1s 137us/step - loss: 5.0660 - acc: 0.6823 - val_loss: 5.1615 - val_acc: 0.6769\n",
      "Epoch 390/500\n",
      "7396/7396 [==============================] - 1s 139us/step - loss: 5.0300 - acc: 0.6839 - val_loss: 5.1494 - val_acc: 0.6777\n",
      "Epoch 391/500\n",
      "7396/7396 [==============================] - 1s 139us/step - loss: 4.9568 - acc: 0.6881 - val_loss: 5.1781 - val_acc: 0.6755\n",
      "Epoch 392/500\n",
      "7396/7396 [==============================] - 1s 133us/step - loss: 5.0388 - acc: 0.6836 - val_loss: 5.1541 - val_acc: 0.6775\n",
      "Epoch 393/500\n",
      "7396/7396 [==============================] - 1s 146us/step - loss: 5.0011 - acc: 0.6862 - val_loss: 5.1413 - val_acc: 0.6783\n",
      "Epoch 394/500\n",
      "7396/7396 [==============================] - 1s 137us/step - loss: 5.0100 - acc: 0.6851 - val_loss: 5.1780 - val_acc: 0.6758\n",
      "Epoch 395/500\n",
      "7396/7396 [==============================] - 1s 146us/step - loss: 5.0435 - acc: 0.6836 - val_loss: 5.1539 - val_acc: 0.6775\n",
      "Epoch 396/500\n",
      "7396/7396 [==============================] - 1s 165us/step - loss: 5.0341 - acc: 0.6848 - val_loss: 5.0305 - val_acc: 0.6854\n",
      "Epoch 397/500\n",
      "7396/7396 [==============================] - 1s 169us/step - loss: 4.8999 - acc: 0.6936 - val_loss: 5.0587 - val_acc: 0.6838\n",
      "Epoch 398/500\n",
      "7396/7396 [==============================] - 1s 133us/step - loss: 4.8982 - acc: 0.6936 - val_loss: 5.0447 - val_acc: 0.6846\n",
      "Epoch 399/500\n",
      "7396/7396 [==============================] - 1s 144us/step - loss: 4.9804 - acc: 0.6883 - val_loss: 5.0654 - val_acc: 0.6830\n",
      "Epoch 400/500\n",
      "7396/7396 [==============================] - 1s 158us/step - loss: 4.9979 - acc: 0.6869 - val_loss: 5.0262 - val_acc: 0.6857\n",
      "Epoch 401/500\n",
      "7396/7396 [==============================] - 1s 146us/step - loss: 5.0031 - acc: 0.6869 - val_loss: 5.0767 - val_acc: 0.6824\n",
      "Epoch 402/500\n",
      "7396/7396 [==============================] - 1s 131us/step - loss: 4.9900 - acc: 0.6869 - val_loss: 5.0767 - val_acc: 0.6824\n",
      "Epoch 403/500\n",
      "7396/7396 [==============================] - 1s 156us/step - loss: 4.9513 - acc: 0.6894 - val_loss: 5.0555 - val_acc: 0.6838\n",
      "Epoch 404/500\n",
      "7396/7396 [==============================] - 1s 144us/step - loss: 4.9779 - acc: 0.6883 - val_loss: 5.1241 - val_acc: 0.6794\n",
      "Epoch 405/500\n",
      "7396/7396 [==============================] - 1s 142us/step - loss: 4.9460 - acc: 0.6898 - val_loss: 5.0219 - val_acc: 0.6860\n",
      "Epoch 406/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7396/7396 [==============================] - 1s 148us/step - loss: 4.9925 - acc: 0.6873 - val_loss: 5.0219 - val_acc: 0.6860\n",
      "Epoch 407/500\n",
      "7396/7396 [==============================] - 1s 146us/step - loss: 4.9420 - acc: 0.6902 - val_loss: 5.0449 - val_acc: 0.6846\n",
      "Epoch 408/500\n",
      "7396/7396 [==============================] - 1s 133us/step - loss: 4.9440 - acc: 0.6904 - val_loss: 5.0538 - val_acc: 0.6841\n",
      "Epoch 409/500\n",
      "7396/7396 [==============================] - 1s 123us/step - loss: 4.9849 - acc: 0.6882 - val_loss: 5.0454 - val_acc: 0.6843\n",
      "Epoch 410/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9781 - acc: 0.6888 - val_loss: 5.0454 - val_acc: 0.6843\n",
      "Epoch 411/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 4.9652 - acc: 0.6894 - val_loss: 5.0448 - val_acc: 0.6846\n",
      "Epoch 412/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.8913 - acc: 0.6938 - val_loss: 5.0815 - val_acc: 0.6824\n",
      "Epoch 413/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9451 - acc: 0.6909 - val_loss: 5.0815 - val_acc: 0.6824\n",
      "Epoch 414/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9934 - acc: 0.6873 - val_loss: 5.0778 - val_acc: 0.6824\n",
      "Epoch 415/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9256 - acc: 0.6915 - val_loss: 5.0446 - val_acc: 0.6846\n",
      "Epoch 416/500\n",
      "7396/7396 [==============================] - 1s 121us/step - loss: 4.9492 - acc: 0.6901 - val_loss: 5.0765 - val_acc: 0.6827\n",
      "Epoch 417/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 4.8934 - acc: 0.6939 - val_loss: 5.0727 - val_acc: 0.6830\n",
      "Epoch 418/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 4.9624 - acc: 0.6897 - val_loss: 5.0917 - val_acc: 0.6819\n",
      "Epoch 419/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 4.9676 - acc: 0.6897 - val_loss: 5.0923 - val_acc: 0.6819\n",
      "Epoch 420/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 4.9506 - acc: 0.6906 - val_loss: 5.0923 - val_acc: 0.6819\n",
      "Epoch 421/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 5.0041 - acc: 0.6874 - val_loss: 5.1613 - val_acc: 0.6777\n",
      "Epoch 422/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.0025 - acc: 0.6877 - val_loss: 5.1112 - val_acc: 0.6808\n",
      "Epoch 423/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 5.0663 - acc: 0.6835 - val_loss: 5.1326 - val_acc: 0.6794\n",
      "Epoch 424/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 4.9945 - acc: 0.6881 - val_loss: 5.1326 - val_acc: 0.6794\n",
      "Epoch 425/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9824 - acc: 0.6888 - val_loss: 5.1607 - val_acc: 0.6777\n",
      "Epoch 426/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.0350 - acc: 0.6854 - val_loss: 5.1809 - val_acc: 0.6766\n",
      "Epoch 427/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.0777 - acc: 0.6831 - val_loss: 5.1857 - val_acc: 0.6764\n",
      "Epoch 428/500\n",
      "7396/7396 [==============================] - 1s 102us/step - loss: 5.0047 - acc: 0.6873 - val_loss: 5.1481 - val_acc: 0.6786\n",
      "Epoch 429/500\n",
      "7396/7396 [==============================] - 1s 115us/step - loss: 5.0429 - acc: 0.6851 - val_loss: 5.1630 - val_acc: 0.6777\n",
      "Epoch 430/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 4.9691 - acc: 0.6896 - val_loss: 5.1195 - val_acc: 0.6802\n",
      "Epoch 431/500\n",
      "7396/7396 [==============================] - 1s 116us/step - loss: 5.0336 - acc: 0.6854 - val_loss: 5.0982 - val_acc: 0.6813\n",
      "Epoch 432/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.8662 - acc: 0.6956 - val_loss: 5.1007 - val_acc: 0.6813\n",
      "Epoch 433/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 5.0014 - acc: 0.6871 - val_loss: 5.1106 - val_acc: 0.6808\n",
      "Epoch 434/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.8831 - acc: 0.6947 - val_loss: 5.1054 - val_acc: 0.6810\n",
      "Epoch 435/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 5.0220 - acc: 0.6865 - val_loss: 5.1054 - val_acc: 0.6810\n",
      "Epoch 436/500\n",
      "7396/7396 [==============================] - 1s 125us/step - loss: 4.9784 - acc: 0.6890 - val_loss: 5.0987 - val_acc: 0.6813\n",
      "Epoch 437/500\n",
      "7396/7396 [==============================] - 1s 123us/step - loss: 4.9465 - acc: 0.6910 - val_loss: 5.0828 - val_acc: 0.6824\n",
      "Epoch 438/500\n",
      "7396/7396 [==============================] - 1s 123us/step - loss: 5.0043 - acc: 0.6874 - val_loss: 5.1221 - val_acc: 0.6799\n",
      "Epoch 439/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.0108 - acc: 0.6869 - val_loss: 5.0871 - val_acc: 0.6821\n",
      "Epoch 440/500\n",
      "7396/7396 [==============================] - 1s 116us/step - loss: 4.9141 - acc: 0.6929 - val_loss: 5.0940 - val_acc: 0.6816\n",
      "Epoch 441/500\n",
      "7396/7396 [==============================] - 1s 102us/step - loss: 4.9077 - acc: 0.6929 - val_loss: 5.0719 - val_acc: 0.6830\n",
      "Epoch 442/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 5.0112 - acc: 0.6865 - val_loss: 5.0806 - val_acc: 0.6824\n",
      "Epoch 443/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 4.9879 - acc: 0.6878 - val_loss: 5.0539 - val_acc: 0.6841\n",
      "Epoch 444/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 5.0376 - acc: 0.6851 - val_loss: 5.1049 - val_acc: 0.6810\n",
      "Epoch 445/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 4.9820 - acc: 0.6888 - val_loss: 5.1061 - val_acc: 0.6810\n",
      "Epoch 446/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.9262 - acc: 0.6919 - val_loss: 5.1011 - val_acc: 0.6813\n",
      "Epoch 447/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 4.9392 - acc: 0.6908 - val_loss: 5.1198 - val_acc: 0.6802\n",
      "Epoch 448/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 4.9185 - acc: 0.6924 - val_loss: 5.1411 - val_acc: 0.6788\n",
      "Epoch 449/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 4.8803 - acc: 0.6946 - val_loss: 5.0916 - val_acc: 0.6816\n",
      "Epoch 450/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9976 - acc: 0.6877 - val_loss: 5.0927 - val_acc: 0.6819\n",
      "Epoch 451/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 4.9346 - acc: 0.6912 - val_loss: 5.1093 - val_acc: 0.6808\n",
      "Epoch 452/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 4.9515 - acc: 0.6904 - val_loss: 5.1066 - val_acc: 0.6810\n",
      "Epoch 453/500\n",
      "7396/7396 [==============================] - 1s 129us/step - loss: 4.9324 - acc: 0.6913 - val_loss: 5.1066 - val_acc: 0.6810\n",
      "Epoch 454/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9020 - acc: 0.6935 - val_loss: 5.1870 - val_acc: 0.6761\n",
      "Epoch 455/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 4.8977 - acc: 0.6928 - val_loss: 5.0975 - val_acc: 0.6816\n",
      "Epoch 456/500\n",
      "7396/7396 [==============================] - 1s 123us/step - loss: 4.8584 - acc: 0.6958 - val_loss: 5.0992 - val_acc: 0.6813\n",
      "Epoch 457/500\n",
      "7396/7396 [==============================] - 1s 123us/step - loss: 4.8968 - acc: 0.6936 - val_loss: 5.0779 - val_acc: 0.6827\n",
      "Epoch 458/500\n",
      "7396/7396 [==============================] - 1s 123us/step - loss: 4.8770 - acc: 0.6943 - val_loss: 5.0831 - val_acc: 0.6824\n",
      "Epoch 459/500\n",
      "7396/7396 [==============================] - 1s 133us/step - loss: 4.8425 - acc: 0.6956 - val_loss: 5.0831 - val_acc: 0.6824\n",
      "Epoch 460/500\n",
      "7396/7396 [==============================] - 1s 123us/step - loss: 4.9638 - acc: 0.6889 - val_loss: 5.0873 - val_acc: 0.6821\n",
      "Epoch 461/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9319 - acc: 0.6905 - val_loss: 5.0873 - val_acc: 0.6821\n",
      "Epoch 462/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 4.8954 - acc: 0.6935 - val_loss: 5.1769 - val_acc: 0.6766\n",
      "Epoch 463/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 4.8798 - acc: 0.6951 - val_loss: 5.1292 - val_acc: 0.6797\n",
      "Epoch 464/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 4.9196 - acc: 0.6912 - val_loss: 5.1469 - val_acc: 0.6786\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.8868 - acc: 0.6940 - val_loss: 5.1619 - val_acc: 0.6775\n",
      "Epoch 466/500\n",
      "7396/7396 [==============================] - 1s 97us/step - loss: 4.8466 - acc: 0.6965 - val_loss: 5.1828 - val_acc: 0.6764\n",
      "Epoch 467/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 4.9057 - acc: 0.6928 - val_loss: 5.1648 - val_acc: 0.6775\n",
      "Epoch 468/500\n",
      "7396/7396 [==============================] - 1s 125us/step - loss: 4.8986 - acc: 0.6931 - val_loss: 5.1447 - val_acc: 0.6786\n",
      "Epoch 469/500\n",
      "7396/7396 [==============================] - 1s 120us/step - loss: 4.8836 - acc: 0.6939 - val_loss: 5.1447 - val_acc: 0.6786\n",
      "Epoch 470/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.8882 - acc: 0.6936 - val_loss: 5.1409 - val_acc: 0.6788\n",
      "Epoch 471/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 4.9153 - acc: 0.6915 - val_loss: 5.0889 - val_acc: 0.6821\n",
      "Epoch 472/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 4.8780 - acc: 0.6939 - val_loss: 5.0889 - val_acc: 0.6821\n",
      "Epoch 473/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9449 - acc: 0.6906 - val_loss: 5.1908 - val_acc: 0.6758\n",
      "Epoch 474/500\n",
      "7396/7396 [==============================] - 1s 120us/step - loss: 4.8735 - acc: 0.6947 - val_loss: 5.1469 - val_acc: 0.6786\n",
      "Epoch 475/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.9355 - acc: 0.6912 - val_loss: 5.1282 - val_acc: 0.6797\n",
      "Epoch 476/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.8709 - acc: 0.6947 - val_loss: 5.1010 - val_acc: 0.6813\n",
      "Epoch 477/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9533 - acc: 0.6900 - val_loss: 5.1113 - val_acc: 0.6808\n",
      "Epoch 478/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.8723 - acc: 0.6948 - val_loss: 5.1202 - val_acc: 0.6802\n",
      "Epoch 479/500\n",
      "7396/7396 [==============================] - 1s 131us/step - loss: 4.8992 - acc: 0.6928 - val_loss: 5.1015 - val_acc: 0.6813\n",
      "Epoch 480/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.9176 - acc: 0.6925 - val_loss: 5.1239 - val_acc: 0.6799\n",
      "Epoch 481/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9384 - acc: 0.6902 - val_loss: 5.1737 - val_acc: 0.6769\n",
      "Epoch 482/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 4.9300 - acc: 0.6913 - val_loss: 5.1399 - val_acc: 0.6788\n",
      "Epoch 483/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.9209 - acc: 0.6916 - val_loss: 5.0938 - val_acc: 0.6819\n",
      "Epoch 484/500\n",
      "7396/7396 [==============================] - 1s 114us/step - loss: 4.8990 - acc: 0.6938 - val_loss: 5.1662 - val_acc: 0.6775\n",
      "Epoch 485/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 4.8792 - acc: 0.6940 - val_loss: 5.1326 - val_acc: 0.6794\n",
      "Epoch 486/500\n",
      "7396/7396 [==============================] - 1s 118us/step - loss: 4.8998 - acc: 0.6919 - val_loss: 5.1192 - val_acc: 0.6802\n",
      "Epoch 487/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 4.8949 - acc: 0.6929 - val_loss: 5.1039 - val_acc: 0.6810\n",
      "Epoch 488/500\n",
      "7396/7396 [==============================] - 1s 99us/step - loss: 4.8948 - acc: 0.6929 - val_loss: 5.0871 - val_acc: 0.6821\n",
      "Epoch 489/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 4.8334 - acc: 0.6962 - val_loss: 5.0964 - val_acc: 0.6816\n",
      "Epoch 490/500\n",
      "7396/7396 [==============================] - 1s 112us/step - loss: 4.9413 - acc: 0.6908 - val_loss: 5.1379 - val_acc: 0.6791\n",
      "Epoch 491/500\n",
      "7396/7396 [==============================] - 1s 120us/step - loss: 4.9257 - acc: 0.6917 - val_loss: 5.1379 - val_acc: 0.6791\n",
      "Epoch 492/500\n",
      "7396/7396 [==============================] - 1s 106us/step - loss: 4.8604 - acc: 0.6952 - val_loss: 5.1617 - val_acc: 0.6777\n",
      "Epoch 493/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.8613 - acc: 0.6958 - val_loss: 5.1337 - val_acc: 0.6794\n",
      "Epoch 494/500\n",
      "7396/7396 [==============================] - 1s 110us/step - loss: 4.9425 - acc: 0.6894 - val_loss: 5.1205 - val_acc: 0.6799\n",
      "Epoch 495/500\n",
      "7396/7396 [==============================] - 1s 100us/step - loss: 4.8938 - acc: 0.6931 - val_loss: 5.1339 - val_acc: 0.6794\n",
      "Epoch 496/500\n",
      "7396/7396 [==============================] - 1s 108us/step - loss: 4.8978 - acc: 0.6929 - val_loss: 5.1339 - val_acc: 0.6794\n",
      "Epoch 497/500\n",
      "7396/7396 [==============================] - 1s 104us/step - loss: 4.8365 - acc: 0.6967 - val_loss: 5.0981 - val_acc: 0.6816\n",
      "Epoch 498/500\n",
      "7396/7396 [==============================] - 1s 101us/step - loss: 4.8403 - acc: 0.6961 - val_loss: 5.0994 - val_acc: 0.6813\n",
      "Epoch 499/500\n",
      "7396/7396 [==============================] - 2s 209us/step - loss: 4.9062 - acc: 0.6919 - val_loss: 5.1237 - val_acc: 0.6799\n",
      "Epoch 500/500\n",
      "7396/7396 [==============================] - 1s 116us/step - loss: 4.9285 - acc: 0.6912 - val_loss: 5.1282 - val_acc: 0.6797\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model_dense=dense_model(X_train, dense_units1=64, dense_units2=16)\n",
    "model_dense.summary()\n",
    "model_dense.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
    "history=model_dense.fit(X_train,y_train,epochs=500,batch_size=32,validation_data=(X_test, y_test))\n",
    "draw_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dense on embedded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 1000, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 100000)            0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 800008    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,800,081\n",
      "Trainable params: 1,800,065\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Train on 7396 samples, validate on 3643 samples\n",
      "Epoch 1/50\n",
      "7396/7396 [==============================] - 56s 8ms/step - loss: 33.2797 - acc: 0.5458 - val_loss: 0.7002 - val_acc: 0.4944\n",
      "Epoch 2/50\n",
      "7396/7396 [==============================] - 50s 7ms/step - loss: 0.7093 - acc: 0.5504 - val_loss: 0.7585 - val_acc: 0.5056\n",
      "Epoch 3/50\n",
      "7396/7396 [==============================] - 56s 8ms/step - loss: 1.4041 - acc: 0.5604 - val_loss: 2.1305 - val_acc: 0.5608\n",
      "Epoch 4/50\n",
      "7396/7396 [==============================] - 53s 7ms/step - loss: 1.5761 - acc: 0.5675 - val_loss: 3.0229 - val_acc: 0.6717\n",
      "Epoch 5/50\n",
      "7396/7396 [==============================] - 59s 8ms/step - loss: 1.6610 - acc: 0.5786 - val_loss: 1.2622 - val_acc: 0.6099\n",
      "Epoch 6/50\n",
      "7396/7396 [==============================] - 61s 8ms/step - loss: 1.9046 - acc: 0.5815 - val_loss: 1.6900 - val_acc: 0.6832\n",
      "Epoch 7/50\n",
      "7396/7396 [==============================] - 52s 7ms/step - loss: 1.5975 - acc: 0.5771 - val_loss: 1.8597 - val_acc: 0.6648\n",
      "Epoch 8/50\n",
      "7396/7396 [==============================] - 58s 8ms/step - loss: 1.9173 - acc: 0.5768 - val_loss: 1.6173 - val_acc: 0.6879\n",
      "Epoch 9/50\n",
      "7396/7396 [==============================] - 60s 8ms/step - loss: 1.6658 - acc: 0.5800 - val_loss: 2.0072 - val_acc: 0.6453\n",
      "Epoch 10/50\n",
      "7396/7396 [==============================] - 54s 7ms/step - loss: 2.1514 - acc: 0.5730 - val_loss: 1.6790 - val_acc: 0.6849\n",
      "Epoch 11/50\n",
      "7396/7396 [==============================] - 50s 7ms/step - loss: 1.3842 - acc: 0.5753 - val_loss: 1.1105 - val_acc: 0.6805\n",
      "Epoch 12/50\n",
      "7396/7396 [==============================] - 51s 7ms/step - loss: 2.2365 - acc: 0.5814 - val_loss: 3.0204 - val_acc: 0.6703\n",
      "Epoch 13/50\n",
      "7396/7396 [==============================] - 51s 7ms/step - loss: 1.4869 - acc: 0.5767 - val_loss: 0.8172 - val_acc: 0.6508\n",
      "Epoch 14/50\n",
      "7396/7396 [==============================] - 53s 7ms/step - loss: 1.1372 - acc: 0.5842 - val_loss: 2.0476 - val_acc: 0.6379\n",
      "Epoch 15/50\n",
      "7396/7396 [==============================] - 57s 8ms/step - loss: 1.4777 - acc: 0.5201 - val_loss: 0.6957 - val_acc: 0.4944\n",
      "Epoch 16/50\n",
      "7396/7396 [==============================] - 58s 8ms/step - loss: 0.6941 - acc: 0.5035 - val_loss: 0.6935 - val_acc: 0.4944\n",
      "Epoch 17/50\n",
      "7396/7396 [==============================] - 59s 8ms/step - loss: 0.6936 - acc: 0.5009 - val_loss: 0.6936 - val_acc: 0.4944\n",
      "Epoch 18/50\n",
      "7396/7396 [==============================] - 54s 7ms/step - loss: 0.6938 - acc: 0.5031 - val_loss: 0.6937 - val_acc: 0.4944\n",
      "Epoch 19/50\n",
      "7396/7396 [==============================] - 57s 8ms/step - loss: 0.6938 - acc: 0.4985 - val_loss: 0.6937 - val_acc: 0.4944\n",
      "Epoch 20/50\n",
      "7396/7396 [==============================] - 53s 7ms/step - loss: 0.6937 - acc: 0.5004 - val_loss: 0.6934 - val_acc: 0.4944\n",
      "Epoch 21/50\n",
      "7396/7396 [==============================] - 51s 7ms/step - loss: 0.6933 - acc: 0.5027 - val_loss: 0.6933 - val_acc: 0.4944\n",
      "Epoch 22/50\n",
      "7396/7396 [==============================] - 51s 7ms/step - loss: 0.6934 - acc: 0.4984 - val_loss: 0.6933 - val_acc: 0.4944\n",
      "Epoch 23/50\n",
      "7396/7396 [==============================] - 51s 7ms/step - loss: 0.6930 - acc: 0.5135 - val_loss: 0.6932 - val_acc: 0.4944\n",
      "Epoch 24/50\n",
      "7396/7396 [==============================] - 54s 7ms/step - loss: 0.6935 - acc: 0.4976 - val_loss: 0.6934 - val_acc: 0.4944\n",
      "Epoch 25/50\n",
      "7396/7396 [==============================] - 53s 7ms/step - loss: 0.6932 - acc: 0.5023 - val_loss: 0.6933 - val_acc: 0.4944\n",
      "Epoch 26/50\n",
      "7396/7396 [==============================] - 54s 7ms/step - loss: 0.6932 - acc: 0.5016 - val_loss: 0.6933 - val_acc: 0.4944\n",
      "Epoch 27/50\n",
      "7396/7396 [==============================] - 54s 7ms/step - loss: 0.6931 - acc: 0.5116 - val_loss: 0.6933 - val_acc: 0.4944\n",
      "Epoch 28/50\n",
      "7396/7396 [==============================] - 52s 7ms/step - loss: 0.6932 - acc: 0.5011 - val_loss: 0.6933 - val_acc: 0.4944\n",
      "Epoch 29/50\n",
      "7396/7396 [==============================] - 52s 7ms/step - loss: 0.6934 - acc: 0.4954 - val_loss: 0.6933 - val_acc: 0.4944\n",
      "Epoch 30/50\n",
      "7396/7396 [==============================] - 54s 7ms/step - loss: 0.6932 - acc: 0.4993 - val_loss: 0.6932 - val_acc: 0.4944\n",
      "Epoch 31/50\n",
      "7396/7396 [==============================] - 54s 7ms/step - loss: 0.6934 - acc: 0.4961 - val_loss: 0.6933 - val_acc: 0.4944\n",
      "Epoch 32/50\n",
      "7396/7396 [==============================] - 51s 7ms/step - loss: 0.6933 - acc: 0.5072 - val_loss: 0.6933 - val_acc: 0.4944\n",
      "Epoch 33/50\n",
      "7396/7396 [==============================] - 54s 7ms/step - loss: 0.6932 - acc: 0.5045 - val_loss: 0.6932 - val_acc: 0.4944\n",
      "Epoch 34/50\n",
      "7396/7396 [==============================] - 54s 7ms/step - loss: 0.6932 - acc: 0.4986 - val_loss: 0.6933 - val_acc: 0.4944\n",
      "Epoch 35/50\n",
      "7396/7396 [==============================] - 48s 7ms/step - loss: 0.6931 - acc: 0.5065 - val_loss: 0.6941 - val_acc: 0.4944\n",
      "Epoch 36/50\n",
      "7396/7396 [==============================] - 47s 6ms/step - loss: 0.6935 - acc: 0.5045 - val_loss: 0.6938 - val_acc: 0.4944\n",
      "Epoch 37/50\n",
      "7396/7396 [==============================] - 46s 6ms/step - loss: 0.6938 - acc: 0.4928 - val_loss: 0.6943 - val_acc: 0.4944\n",
      "Epoch 38/50\n",
      "7396/7396 [==============================] - 46s 6ms/step - loss: 0.6940 - acc: 0.5037 - val_loss: 0.6941 - val_acc: 0.4944\n",
      "Epoch 39/50\n",
      "7396/7396 [==============================] - 46s 6ms/step - loss: 0.6941 - acc: 0.4966 - val_loss: 0.6937 - val_acc: 0.4944\n",
      "Epoch 40/50\n",
      "7396/7396 [==============================] - 47s 6ms/step - loss: 0.6942 - acc: 0.5038 - val_loss: 0.6947 - val_acc: 0.4944\n",
      "Epoch 41/50\n",
      "7396/7396 [==============================] - 50s 7ms/step - loss: 0.6951 - acc: 0.5015 - val_loss: 0.6942 - val_acc: 0.4944\n",
      "Epoch 42/50\n",
      "7396/7396 [==============================] - 56s 8ms/step - loss: 0.6948 - acc: 0.5005 - val_loss: 0.6955 - val_acc: 0.4944\n",
      "Epoch 43/50\n",
      "7396/7396 [==============================] - 53s 7ms/step - loss: 0.6950 - acc: 0.4999 - val_loss: 0.6967 - val_acc: 0.4944\n",
      "Epoch 44/50\n",
      "7396/7396 [==============================] - 52s 7ms/step - loss: 0.6947 - acc: 0.5018 - val_loss: 0.6963 - val_acc: 0.4944\n",
      "Epoch 45/50\n",
      "7396/7396 [==============================] - 51s 7ms/step - loss: 0.6958 - acc: 0.5012 - val_loss: 0.7146 - val_acc: 0.4944\n",
      "Epoch 46/50\n",
      "7396/7396 [==============================] - 51s 7ms/step - loss: 0.7652 - acc: 0.4999 - val_loss: 0.6974 - val_acc: 0.4944\n",
      "Epoch 47/50\n",
      "7396/7396 [==============================] - 50s 7ms/step - loss: 0.6950 - acc: 0.5020 - val_loss: 0.6941 - val_acc: 0.4944\n",
      "Epoch 48/50\n",
      "7396/7396 [==============================] - 48s 6ms/step - loss: 0.6940 - acc: 0.4976 - val_loss: 0.6939 - val_acc: 0.4944\n",
      "Epoch 49/50\n",
      "7396/7396 [==============================] - 52s 7ms/step - loss: 0.6940 - acc: 0.5011 - val_loss: 0.6942 - val_acc: 0.4944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "7396/7396 [==============================] - 52s 7ms/step - loss: 0.6943 - acc: 0.4999 - val_loss: 0.6955 - val_acc: 0.4944\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_embedded_dense=embedding_flatten_model(X_train,max_words=max_words,embedding_units=100,dense_units1=8,dropout=0.5,dense_units2=4,embeddings_regularizer=regularizers.l2(0.15), kernel_regularizer=regularizers.l2(0.15),bias_regularizer=regularizers.l2(0.15),activity_regularizer=regularizers.l2(0.15))\n",
    "model_embedded_dense.summary()\n",
    "model_embedded_dense.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "history=model_embedded_dense.fit(X_train,y_train,epochs=50,batch_size=32,validation_data=(X_test, y_test))\n",
    "draw_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 1000, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,017,297\n",
      "Trainable params: 1,017,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7396 samples, validate on 3643 samples\n",
      "Epoch 1/30\n",
      "7396/7396 [==============================] - 220s 30ms/step - loss: 0.6930 - acc: 0.5107 - val_loss: 0.6929 - val_acc: 0.5084\n",
      "Epoch 2/30\n",
      "7396/7396 [==============================] - 226s 31ms/step - loss: 0.6397 - acc: 0.6572 - val_loss: 0.5831 - val_acc: 0.6887\n",
      "Epoch 3/30\n",
      "7396/7396 [==============================] - 235s 32ms/step - loss: 0.5177 - acc: 0.7541 - val_loss: 0.5867 - val_acc: 0.6909\n",
      "Epoch 4/30\n",
      "7396/7396 [==============================] - 234s 32ms/step - loss: 0.3852 - acc: 0.8418 - val_loss: 0.6773 - val_acc: 0.6739\n",
      "Epoch 5/30\n",
      "7396/7396 [==============================] - 213s 29ms/step - loss: 0.2796 - acc: 0.8901 - val_loss: 0.7562 - val_acc: 0.6618\n",
      "Epoch 6/30\n",
      "7396/7396 [==============================] - 311s 42ms/step - loss: 0.2150 - acc: 0.9213 - val_loss: 0.8762 - val_acc: 0.6582\n",
      "Epoch 7/30\n",
      "7396/7396 [==============================] - 302s 41ms/step - loss: 0.1452 - acc: 0.9504 - val_loss: 1.0304 - val_acc: 0.6577\n",
      "Epoch 8/30\n",
      " 288/7396 [>.............................] - ETA: 5:12 - loss: 0.1256 - acc: 0.9688"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-df57401bf2a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdraw_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=lstm_model(X_train, max_words=max_words, embedding_units=100 ,lstm_units=32, dense_units=8, dropout=0, recurrent_dropout=0.2,embeddings_regularizer=None, activity_regularizer=None,kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None)\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(0.0005),metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,y_train,batch_size=32,epochs=30, validation_data=(X_test,y_test))\n",
    "\n",
    "draw_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_14 (Embedding)     (None, 1000, 20)          200000    \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 4)                 368       \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 200,373\n",
      "Trainable params: 200,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7396 samples, validate on 3643 samples\n",
      "Epoch 1/30\n",
      " 224/7396 [..............................] - ETA: 8:41 - loss: 0.1333 - acc: 0.9598"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-80618eca4382>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdraw_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_bi_lstm=bidirectional_lstm_model(X_train, max_words,embedding_units=100 ,lstm_units=16, dropout=0, recurrent_dropout=0.5)\n",
    "model_bi_lstm.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(0.005),metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,y_train,batch_size=32,epochs=30, validation_data=(X_test,y_test))\n",
    "draw_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn=cnn(data=X_train, max_words=max_words, embedding_units=20, conv_1_filter=25,conv_1_length=9, pooling_length= 5,conv_2_filter=32,conv_2_length=9)\n",
    "model_cnn.summary()\n",
    "\n",
    "model_cnn.compile(optimizer=RMSprop(0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model_cnn.fit(X_train, y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN and LSTM mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_27 (Embedding)     (None, 1000, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 994, 8)            5608      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 994, 8)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 198, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 192, 32)           1824      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 192, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 8)                 1312      \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,008,753\n",
      "Trainable params: 1,008,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7396 samples, validate on 3643 samples\n",
      "Epoch 1/20\n",
      "7396/7396 [==============================] - 216s 29ms/step - loss: 0.6280 - acc: 0.6568 - val_loss: 0.5824 - val_acc: 0.7038\n",
      "Epoch 2/20\n",
      "7396/7396 [==============================] - 194s 26ms/step - loss: 0.5521 - acc: 0.7274 - val_loss: 0.5639 - val_acc: 0.7096\n",
      "Epoch 3/20\n",
      "7396/7396 [==============================] - 193s 26ms/step - loss: 0.4608 - acc: 0.7902 - val_loss: 0.5385 - val_acc: 0.7368\n",
      "Epoch 4/20\n",
      "7396/7396 [==============================] - 182s 25ms/step - loss: 0.3829 - acc: 0.8387 - val_loss: 0.5545 - val_acc: 0.7373\n",
      "Epoch 5/20\n",
      "7396/7396 [==============================] - 201s 27ms/step - loss: 0.3188 - acc: 0.8759 - val_loss: 0.6152 - val_acc: 0.7230\n",
      "Epoch 6/20\n",
      "7396/7396 [==============================] - 181s 24ms/step - loss: 0.2602 - acc: 0.9027 - val_loss: 0.6491 - val_acc: 0.7208\n",
      "Epoch 7/20\n",
      "7396/7396 [==============================] - 192s 26ms/step - loss: 0.2168 - acc: 0.9237 - val_loss: 0.7375 - val_acc: 0.7060\n",
      "Epoch 8/20\n",
      "7396/7396 [==============================] - 180s 24ms/step - loss: 0.1813 - acc: 0.9377 - val_loss: 0.8106 - val_acc: 0.6915\n",
      "Epoch 9/20\n",
      "7396/7396 [==============================] - 177s 24ms/step - loss: 0.1534 - acc: 0.9494 - val_loss: 0.8251 - val_acc: 0.7033\n",
      "Epoch 10/20\n",
      "6848/7396 [==========================>...] - ETA: 9s - loss: 0.1208 - acc: 0.9613 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-6f019449b954>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                     validation_split=0,validation_data=(X_test,y_test))\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mdraw_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_cnn_lstm=cnn_lstm_model(X_train, max_words, embedding_units=100,conv_1_filter=8,lstm_units=8,conv_1_length=7, pooling_length= 5,conv_2_filter=32,conv_2_length=7, dropout=0.2,recurrent_dropout=0.2)\n",
    "model_cnn_lstm.summary()\n",
    "\n",
    "model_cnn_lstm.compile(optimizer=RMSprop(lr=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model_cnn_lstm.fit(X_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0,validation_data=(X_test,y_test))\n",
    "draw_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare pretrained embedded layer with self learned layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196016 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Get Glove weights\n",
    "glove_dir = 'E:\\\\Marius\\\\Documents\\\\Studium\\\\Programmieren\\\\Daten\\\\Text\\\\glove.840B.300d'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.840B.300d.txt'),'r', encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.27204001, -0.06203   , -0.1884    , ...,  0.13015001,\n",
       "        -0.18317001,  0.1323    ],\n",
       "       [ 0.31924   ,  0.06316   , -0.27858001, ...,  0.082745  ,\n",
       "         0.097801  ,  0.25044999],\n",
       "       ...,\n",
       "       [ 0.30193999,  0.20740999, -0.139     , ...,  0.32253   ,\n",
       "        -0.033622  , -0.43294999],\n",
       "       [-0.57036   , -0.25433999,  0.31031999, ..., -0.049099  ,\n",
       "        -0.31325001,  0.42824   ],\n",
       "       [-0.36895001,  0.28227001, -0.022205  , ...,  0.15346999,\n",
       "         0.15895   , -0.91720003]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build embedding matrix\n",
    "embedding_dim = 300\n",
    "# Train Tokenizer\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(serie_texts)\n",
    "word_index=tok.word_index\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_31 (Embedding)     (None, 1000, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,042,897\n",
      "Trainable params: 42,897\n",
      "Non-trainable params: 3,000,000\n",
      "_________________________________________________________________\n",
      "Train on 7396 samples, validate on 3643 samples\n",
      "Epoch 1/30\n",
      "7396/7396 [==============================] - 986s 133ms/step - loss: 132775.0422 - acc: 0.5039 - val_loss: 135230.1467 - val_acc: 0.4941\n",
      "Epoch 2/30\n",
      "2336/7396 [========>.....................] - ETA: 6:46 - loss: 133641.1894 - acc: 0.5158"
     ]
    }
   ],
   "source": [
    "model=lstm_model(X_train,max_words=max_words,embedding_units=300,lstm_units=32,dense_units=8,dropout=0.2,embeddings_regularizer=regularizers.l2(0.15), kernel_regularizer=regularizers.l2(0.15),bias_regularizer=regularizers.l2(0.15),activity_regularizer=regularizers.l2(0.15))\n",
    "\n",
    "#Freeze layer\n",
    "model.layers[1].set_weights([embedding_matrix])\n",
    "model.layers[1].trainable=False\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,y_train,batch_size=32,epochs=30, validation_data=(X_test,y_test))\n",
    "\n",
    "draw_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def define_model(length, vocab_size):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length,))\n",
    "    embedding1 = Embedding(vocab_size, 100)(inputs1)\n",
    "    conv1 = Conv1D(filters=32, kernel_size=4, activation='relu')(embedding1)\n",
    "    drop1 = Dropout(0.5)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    # channel 2\n",
    "    inputs2 = Input(shape=(length,))\n",
    "    embedding2 = Embedding(vocab_size, 100)(inputs2)\n",
    "    conv2 = Conv1D(filters=32, kernel_size=6, activation='relu')(embedding2)\n",
    "    drop2 = Dropout(0.5)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    # channel 3\n",
    "    inputs3 = Input(shape=(length,))\n",
    "    embedding3 = Embedding(vocab_size, 100)(inputs3)\n",
    "    conv3 = Conv1D(filters=32, kernel_size=8, activation='relu')(embedding3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    # interpretation\n",
    "    dense1 = Dense(10, activation='relu')(merged)\n",
    "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_complex=define_model(length=max_len, vocab_size=max_words)\n",
    "model_complex.summary()\n",
    "\n",
    " # compile\n",
    "model_complex.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# summarize\n",
    "print(model_complex.summary())\n",
    "#plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
    "history = model_complex.fit([X_train,X_train,X_train], np.array(y_train),\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([list(X_train),list(X_train),list(X_train)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.array(X_train).reshape([7396,1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
