After reading simultaneously in a number of German introductory quantum mechanics books, I suddenly noticed that not a single one had the courage to say that a Hermitian operator is in general only partially defined on the corresponding Hilbert space. The theory of rigged Hilbert spaces seems simple enough to me, so I started to wonder where this overwhelming fear against partially defined operations comes from. It's a bit ironic too, considering that quantum mechanic itself is so fond of some interpretation which make claims about some sort of fundamental undefinedness. The fear seems to come from mathematics itself, i.e. mathematics is unbelievably dismissive towards partially (un)defined operations. Then I thought a bit about whether the theory of rigged Hilbert spaces could me made even simpler, if the corresponding mathematics embraced partial undefinedness even more fully, and that's the context where families of semi-norms, partially defined norms and partially defined semilattices seemed to paint a simple and beautiful picture. 

The connection to the law of excluded middle is that often the structure of a complete semilattice (among propositions, formulas or sentences) arises naturally, but a complete semilattice is nearly indistinguishable from a complete lattice. But you can define an implication operation ("from A follows B" for a Heyting algebra, but in general rather "from A, B, C, ... follows Z") which allows to distinguish "and" and "or" (or "meet" and "join") properly. This is important, because the symmetry between "and" and "or" so typical for classical logic is often just an illusion caused by the fact that complete semilattices are so hard to distinguish from complete lattices. But if the maximal element (infinity) is removed from the complete semilattice, then it becomes much easier to distinguish it from a complete lattice. 

One main reason why the law of excluded middle can fail is that some operations are simply undefined in some contexts. This doesn't even mean that they are undefinable in principle, it just means that they are not defined in the current context. If I have a real computer and a real bound on the time I'm willing to wait, then some programs will simply fail to give a definitive answer for some inputs under these constraints. Forcing the answer arbitrarily to some definite value in such cases will often only obscure the true structure of the problem. This doesn't mean that logical inconsistencies will arise if we insist to do so, but we may be trading a finite context for an infinite context just to avoid undefined operations.