Has necessity really harmed science? More importantly, as a scientist myself, I also don't see how the use of necessity has harmed science at all; on the contrary, I think it has been a profoundly useful guide in separating fact from fiction so as to arrive as close as we can to the truth. Also, "necessity" is not at odds with "possibility"; I don't see a conflict there at all, and find that science is all about both. 

I think the key word here is "discovers", specifically present tense and not past or future tense. That essentially implies that Mary is in fact—right now, presently—in New York. As I summarized in a comment below, for this work problem in a basic textbook, I think it's appropriate that we infer the least implications, i.e., not include an in the future implication as a possible interpretation of the original premise. I think if the book authors wanted to write "in the future" they probably would have, and it would have made the answer clearcut (i.e., there would be no entailments). But the fact that they left it out suggests either they wanted the opposite (an entailment such that A entails B), or they wanted everyone to be confused. As pernicious as some school textbook authors may seem to be, I think it's reasonable we can assume they did not intend the latter... :P 

So simply saying, "Yes, X (economy, jobs, taxes, etc) is bad, but it's not my fault because I voted for the other guy" isn't a very compelling argument, because if the official was bad enough, that person should have done something about it. 

Thus, I believe that fairest answer is that (A) presupposes (B). 

I think you'd be hard-pressed to prove that science's reliance on "necessity" has anything to do with philosophy "being taken seriously as a cultural form". To be a philosopher was once a very respectable position to have. The difficulty is that it has almost always been the province of the wealthy — if you were of the working class you more likely had to spend most of your day putting food on the table. To have access to the rich philosophy that came before us, you had to have had the luxury of an education, and even then, the logical mind for it. Philosophy's current position, I would argue, is simply because A) in our modern society being a philosopher won't get you paid and we tend to greatly value money, and B) the ideas/concepts remain rather obtuse to the layperson. Most people, I'm afraid, do not have the training, discipline of mind, or even willingness to learn philosophy because it will appear to have no practical use to them. I can't see how removing "necessity" from philosophy would change that. 

It would be one thing if we were stuck with nothing better and had to make do. But there is deductive notion of validity that has none of these problems. Deduction is valid if each step obtains from previous ones by the usual logical rules (modus ponens, etc). Inference is valid if there is a valid deduction with the same premise and conclusion. Deduction is a formal couterpart to intuitive argument, its validity is not determined solely by premise and conclusion, but by all steps. And deductive notion of validity tracks how we actually verify logical validity, unlike Tarskian inference. The need to deal with "meanings" is much reduced, and the metaphysical load is accordingly lighter. See McKeon's IEP article. 

The dominance of first order logic is based on technical results of Skolem and Gödel, rather than on philosophical arguments. Skolem proved that first order logic has nice model theory, Gödel proved that it is recursively axiomatizable and hence has a nice proof theory (unlike higher order logics), and compact (unlike infinitary logics). At the same time, first order Zermelo-Fraenkel set theory (made first order by Skolem, who modified Zermelo's comprehension axiom accordingly) proved to be more than sufficient not only for all of classical mathematics, but even for higher set theory and model theory. On the other hand, higher order set theories, like Russell's, proved to be unwieldy. In the end, Russell had to introduce the infamous "axiom of reducibility" which effectively reduces the logic of his set theory to first order. 

Frege, Quine, Geach and Dummett are all worth studying on this subject. The SEP article on identity is a helpful introduction. 

To say 1=1 does not express identity because there is a spatial difference between the left and right is confusing the thing with the symbol that denotes it. The number one is identical with itself. Of course a serious issue arises over how symbols denote things, and there is much debate over this. Frege held that names are a kind of abbreviated definite description, but this is only one of many accounts of the meaning of names. 

Classically, there is no difference. Identity is a two place predicate which has the value true if its arguments are numerically identical and false otherwise. One can write such a predicate as Identical(x,y) or one can write it as x=y. The latter is just 'syntactic sugar' that makes sentences easier to read, but it expresses the same thing. This is the way identity is employed in logic, in particular in predicate logic, and by extension in mathematics.