It's the basic hypocrisy of the West in a nutshell. But perhaps the opposite is true as well, at least once we detach the ought from axiomatic moral judgment; maybe this could be explored in terms of Hume's empiricism and the inseparable gulf between an is and an ought. This can also perhaps be read alongside Nietzsche's doubts about ways of life that denounce existence in favor of something else. In other words: there is also an ethical relation of obligation that is independent of moral axioms and the logic of judgment and punishment; a positive order of joy and levity, characterized by an empirical investigation into ways of living, thinking and feeling -- this is ethics in the classical sense as an art of living. It is the abandonment of moral judgments about reality ("existence is blameworthy") that seems key to me here; an experimental ethics yields a very different spirit of analysis than a transcendental morality that knows everything in advance. Very simply it is less gloomy, less bored -- it lacks the gravity and sad passions that motivate moral responsibilities (bitterness, grief, melancholy, resentment, vengeance and so on.) And so just to complicate this schema a bit, perhaps an absolutely immanent ethics makes use of a certain "transcendent" moment in its own way. But there is a different relation; it is no longer a starting point (Spinoza makes this very clear -- it is important not to start out with the idea of God, but rather to reach it as swiftly as possible...) Some futurologists predict that we may have human-level artificial intelligences within the next few decades. What might be the most significant philosophical consequences of such a development, and in particular, what might a reasonable ethical policy look like with regards to the rights of sentient machines? Would it be ethical to own a machine with a human-level intellect? It does not sound like a suitable finality for human subjectivity to abandon creation and give up production altogether. On the other hand, maybe alienated production under the constraint of profit (for profits' sake) is also not a suitable finality for human subjectivity. Ethics indicates a set of optional rules assessing what we do and say in relation to ways of existing. Ethics addresses itself to the "art of living": the properly ethical question is which mode of existence, which style of living. An ethical analysis would interpret actions and propositions as so many sets of symptoms that express or “dramatize” the mode of existence of the doer or speaker. First, let's suppose we have such a human-level artificial intelligence. Depending on the constitution of the machine, it may have 'transparent access' to its own cognitive structure. In such a situation, the machine would have a choice as to whether or not to experience the pain, or indeed attenuate the intensity experienced (by, say, 17%) before the pain-experiences even begin. Presumably posthumans and active mindfiles would have the same capabilities in terms of manipulating the intensity of their input sources. Wikipedia gives this interpretation via Emma Goldman: I am tempted to claim there is even an ethical or religious dimension here demanding absolute respect (even love) for the other, including their mode of communication. As for the ethicality of your own citizens (allegedly) collaborating with a foreign adversary to help guide the spread of disinformation towards specific districts with an eye towards gaining an electoral advantage -- this seems clearly over any kind of reasonable line (and may well be illegal.) You might be interested in this syllabus for a Literary Theory and Criticism course entitled "The Ethics of Reading". The moral problem Kant finds in lying is indeed universal, and would presumably apply to lying by omission as much as outright fabulation. In any case my understanding is that it's the moral failing involved in taking another human being as a means to an end which is important. After all, are mourning or crying motivated by happiness? Pascal's example may seem particularly bizarre in this light when he claims that even suicide is motivated by happiness. Morality relies on a transcendent good-evil distinction. Very generally it means a set of constraining rules (a code) consisting in judging actions by relating them to universal values. Morality addresses itself to jurisprudence: "This is right, that's wrong." We have a chat room, and we could even consider organizing group readings or discussions if that might be interesting to people. As noted in comments we can create rooms for particular themes or problems. Also mods can create "gallery" chats where only certain people can talk -- this might be helpful in terms of facilitating more structured interactions like debates. To try to briefly respond to the larger concern here with some resources -- Derrida is one of the sharpest thinkers on the "founding absence" of international law (at least in the sense of "global order"; Derrida suggests there is no international law as such.) This absence is maybe characterizable as one sense of "globalization" -- a linking-together through gaps, stratification and exclusion, which can only take place because international-legal conditions are missing: that is, the workable, effective, practical arrangements that would be the precondition of any thinking of any planetary ethics, in a unified political, social and legal sense. SEP's entry on the thinker offers some brief but intriguing points in this direction: You can read about a recent presentation by the creator of Minecraft where he makes more or less this case; he emphasizes the difference between pirating and theft and the incoherence of the "lost sale" concept, as well as the importance of giving people a reason to buy. From there: