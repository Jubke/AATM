This situation is probably rare because it just happens to be difficult to produce a nonhomorganic nasal-obstruent sequence. A process like vowel harmony, on the other hand, is different, since it is not especially difficult to produce, say, a [+ATR] vowel and a [-ATR] vowel in consecutive syllables (see Archangeli & Pulleyblank 2007 for discussion of some examples of opacity in vowel harmony. There would be no strong articulatory pressure against an opaque rule interaction involving vowel harmony like there would with nasal place assimilation. 

I am looking for any recent studies dealing substantially with "broken vowels," or vocoid elements which have a noticeably nonstable formant trajectory, yet for which there are no good phonological arguments that they are diphthongs. "Broken vowels" might alternately be referred to as vowels with an "offglide" or "onglide". 

It depends what you will count as evidence, and which position you want to argue against. Internal evidence would show that aspects of a phonological system cannot be described perspicaciously without recourse to segments, while external evidence would involve arguments based on the performance of speakers to the effect that their behavior could not be explained without positing segments in a mental representation. There are two possible positions to argue against, (a) that not all of phonology is organized into segments, or (b) that none of phonology is organized as segments. Obviously (b) will be easier to argue against. 

Can I have help with other examples? 

It seems that whisperers articulate stop consonants in such a way that the aerodynamic effect of producing them is similar to normal speech. In normal speech voiced consonants have less pressure buildup behind the closure than do voiceless consonants phonation will not occur with too high of a transglottal flowrate. In whispered speech I think that talkers produce a voiced stop so that it has a pressure gradient across the constriction similar to what would be experienced if phonation were occurring. Listeners can then identify a voicing contrast by the intensity of the release burst. I think this is true because for both the Gengbe and Korean participants, identification of voicing/laryngeal contrasts was best for velar stops. Velar stops have a higher burst intensity overall than stops at other places of articulation, so differences between more and less intense bursts will be more palpable. Identification for Gengbe was worst for labial velar stops, which have a very faint burst release, and Korean labial stops were also poorly distinguished. Korean listeners were also able to distinguish at better than chance rates the fortis-lenis distinction, and I think that they were able to make use of duration differences to help with this. 

Source-filter theory is based on the same general mathematical framework that is used in signal processing research and control theory, fields which are highly developed with numerous practical applications. The method is more or less as follows [contributors with better math/engineering background feel free to edit this part]: the Laplace transform of an observed signal is treated as the product of a Laplace-transformed (actually occurring or ideal) input signal and one or more transfer functions (see the Wikipedia article for details). i.e., 

In a language I am studying I have just noticed a significant but subtle difference in the length of [f] segments in tonic versus atonic syllables (an ~50ms difference which is statistically significant). When mentioning the effect to a colleague, I was asked whether such an effect, where consonants differ in their lengths (closure or constriction time) depending on their position in the word, is cross-linguistically common. I said that surely it must be, but I realized that I could only think of two examples, in English [s] (Klatt 1974) and Ibibio nasals (Akinlabi & Urua 2002: 135, fn.11).