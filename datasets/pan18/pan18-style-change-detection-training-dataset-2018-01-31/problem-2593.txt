Thematic dependencies between empty theta heads θ and their specificiers (specifier-head dependencies), these specifiers being what one traditionally understands to be the arguments of the predicate Xs. 

In my view, this is junk science. It sounds impressive, but it's nonsense. In order to buy into this view of syntactic structure, one has to take the leap of syntactic faith that I associate with much of Chomskyan syntax. I even think many Chomskyans would reject the understanding of syntax that is put forward in the book. The approach is, for example, contrary to basic notions of X-bar theory, in which complements (as well as many specifiers) are arguments. On the approach in the book, all complements are actually predicates. 

I have the following questions in this regard: 

But to answer the actual question, my understanding of the final sentence in the passage is that the head-complement dependency associated with standard X-bar-type structures is actually present, but its presence is manifest as the dependency between the theta head, which is always an empty element!, and the predicate, which is represented by X in the complement position. The empty theta head θ takes a predicate X as its complement; a dependency exists between the two. But since the dependency is unlike the dependencies that are traditionally assumed, Rowlett calls it a "grammatical dependency", a nebulous term. 

Many adjuncts can be identified using certain diagnostics. Take the adverb yesterday as an example: Bill did it yesterday. It can be separated off and put in a conjoined clause: Bill did it, and that happened yesterday. This is not possible with arguments: *Bill gave a gift, and that that happened Jessica, *Bill gave Jessica, and that happened a gift. Arguments are typically nouns (or noun phrases) as with Jessica and a gift, whereas adjuncts are typically adverbs or PPs. It is therefore quite certain that neither Jessica nor a gift in the original example can be viewed as an adjunct. 

Rowlett is thus pursuing an approach to syntax that takes specifiers to be the arguments of complements in a sense, as opposed to the arguments of head predicates, which is much more standard. I think such an approach is going to be difficult for many a syntactician to swallow. 

Is the USD approach to function words (e.g. auxiliaries and prepositions) a matter of debate in computational circles? 

This explanation resides with the analysis of that-clauses and wh-clauses (matrix vs. embedded). If one assumes that the head/root of a that-clause is the subordinator that and the head/root of an embedded wh-clause is the wh-element, then the explanation comes into view. The subordinator that does not have the status of of a nominal, whereas wh-elements do (because of their wh-feature). In other words, prepositions are subcategorizing for a nominal dependent; that-subordinators do not have nominal status, whereas wh-subordinators and wh-elements do have this status. 

There is no consensus about the best analysis of the phenomenon. What this means for your example is that you have some freedom to posit a parse that you believe fits your understanding of syntax best. The Wikipedia article that Ivan linked to (https://en.wikipedia.org/wiki/Right_node_raising) gives three possible theoretical accounts; you might choose the one that you think is best. 

If a typology of lexical verbs is actually what you are interested in, many dictionaries provide sentence frames indicating how verbs are used. For instance, I have Wahrig's Woerterbuch der deutschen Sprache here in front of me now. It classifies verbs into about 100 different types according to their valency. Perhaps this is what you are actually interested in. If so, I imagine that there are dictionaries of Russian that also provide sentence frames indicating the valency of verbs. If the term "valency" does not call up clear associations, try reading this article here. 

But if one is striving to maintain strict binarity of branching, then the structural analysis of the first example sentence might be something like the following: 

The question is good insofar as it reveals one of the central problems with the classic X-bar schema. There is little empirical evidence backing the assumption that Mary and seated should form a constituent. Constituency tests reveal, rather, that the structure is flat: Mary is a constituent and seated is a constituent, but the two together do not form a constituent. 

In both languages, therefore, the subject position is non-thematic (no argument = no theta role), but a difference arises at this point: English being a non-pro-drop language (= the Extended Projection Principle of Chomsky's early GB/P&P Theory), in English the subject slot must be occupied by a pronounceable 'dummy' (it, in this case), whereas, Spanish being a pro-drop language, no 'dummy' is required - nor possible, under Economy - (cf. *Ello parece que se odian) and so Spanish clauses of this type apparently have nothing in subject position. 

No serious attempt has ever been made to justify in semantic (and ultimately ontological) terms the extremely rich inventory of functional categories that Cinque has been elaborating since the late 1990’s for both the clause and the DP (and the categories of their complements, i.e., the ‘entities’ that e.g., Cinque’s adverbials must predicate higher order properties of!), and I’m afraid, for the time being (and for many years to come, at best) you may as well abandon all hope of seeing most of the functional categories posited in his cartographic work grounded on empirically credible ontological/semantic categories. 

Their section 2.3 presents a series of empirical arguments against TM; for instance, "John is being easy to please" would have to come from "*To please John is being easy". (Their arguments are this "progressive" argument, the "try" argument, the indefinite NP argument, the intentionality argument, and the modal argument"). Overall the argument does not appear to be theory-driven, i.e. they aren't arguing that we have to get rid of TM because it violates some valuable grammatical principle, it just that raising doesn't work. 

[Furthermore....] The primary concept that is relevant here is, roughly speaking, about how some nominal element relates syntactically to other elements of the sentence -- I'm being deliberately open-ended. One example is the relationship between "Bill" and either "cat" or "sold a cat" in "Bill sold a cat". That relationship can be indicated by word order (as in English), by some kind of abstract featural property realized as morphological affixation of some kind (as in Russian or Kipsigis), or by a seriously complicated system of gender agreement patterns in Khoekhoe; and there are other ways. In English, certain syntactic relations are primarily signalled by word order (and there is very little, though not no form-changing as is the case in Chinese). In Sanskrit and Walpiri, these relations are signalled via affixation (and not so much with word order).