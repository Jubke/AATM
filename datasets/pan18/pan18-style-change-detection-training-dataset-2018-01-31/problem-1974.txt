From a percentage POV, it looks like you're getting closer and closer to what is expected from an honest coin. Now suppose the number of coin tosses is N, and let's say that N is getting pretty large. The expected value of the random variable that is the number heads out of the N tosses is going to be around the mean Np, which for an honest coin is N/2. If the probability of heads = p , then the probability of tails = 1-p . If it's a fair coin, then p = 1-p and the probability of either heads or tails is p = 1/2. The variance of the random variable (the total number of heads out of N tosses) is Np(1-p) (which, for the honest coin, is N/4) which is the square of the standard deviation. This means if N is increased by a factor of 4, then the standard deviation only increases by a factor of 2. So as the number of tosses increases, the deviation of the number of heads (which is sqrt(N)/2)) from the expected mean (which is N/2) does increase, but not as fast as the number of tosses increases. When you divide by N, the percentage of that expected deviation, inside the total number of tosses, gets smaller and gets closer to the expected 50%. This is because it's (sqrt(N)/2)/N = 1/(2 sqrt(N)) . From a count POV, it doesn't look exactly the same. If you toss an honest coin 1,000,000 times, the number of heads will likely be some distance away from 500,000. But the percentage of the number of heads out of the total number of tosses will be very close to 50%. And it will get closer to 50% with more and more tosses, but the absolute distance away from the 50% mark will grow at a rate proportional to sqrt(N). But the number of tosses is growing at a rate of N. When we have a collection of five things, we say things about how that collection combines with other such collections that has nothing to do with the actual things, (and might be wrong on that account -- combine three foxes and four rabbits and, eventually, you have left at most four animals.) a bias toward rapid rule formation, a bias toward optimism, and a bias toward seeing the customary as either objective or planned. The first of these increases our ability to be educated. People give a few examples and we are meant to intuit a rule. (This is discussed as 'over-imitation' in the first reference.) So child rearing and work coordination are better. But it is not reasonable to look at nature-in-the-raw in this way, we need to back away very far from the idea that nature is actively teaching us the truth, in order to really learn from it. (Neo-)Intuitionists generalize this to the whole of mathematics and logic, making the range of structures expressed by mathematical and logical objects part of rational psychology, rather than of ontology. Mathematical facts do not describe what is true of anything or even what is truly necessary in the world, but they do dictate what it necessary for humanity to truly grasp any aspect of the outside world and give it a shared expression. But it would not answer this question. Universal Algebra and its cohorts Model Theory and Category Theory are fascinating in that they highlight commonalities we see between different logical structures we never imagined were so similar, and lets us classify them in a clean and compelling way. The third allows us to take part wholeheartedly in groups' politics. We follow leadership that is not really there, taking direction from our peers that leads to collaboration and the formation of values. At the same time, we are motivated to look behind uniformity for (others') biases, or we would converge too quickly into rigid forms that serve only the leadership or the status-quo, and undercut the benefits of competition. We want to split our experience of rule-following into preferring agreement (the 'Social Exchange Heuristic') and avoiding being controlled (e.g. 'Commitment Skepticism'), so we lose sight of what ordinary, objective uniformity looks like. If you think many of these 'phantasies' constitute a shared factor in human experience, then they must reflect the composite intuition humans have developed to approach measurement and combination. In that case, they are not completely formal, but are based on something real. So perhaps only the set of aesthetically appealing universes with a given set of interacting sources of value is really a good model. It can capture these two, and other human drives. The variance of the random variable (the total number of heads out of N tosses) is Np(1-p) (which, for the honest coin, is N/4) which is the square of the standard deviation. This means if N is increased by a factor of 4, then the standard deviation only increases by a factor of 2. So as the number of tosses increases, the deviation of the number of heads (which is sqrt(N)/2)) from the expected mean (which is N/2) does increase, but not as fast as the number of tosses increases. When you divide by N, the percentage of that expected deviation, inside the total number of tosses, gets smaller and gets closer to the expected 50%. This is because it's (sqrt(N)/2)/N = 1/(2 sqrt(N)) . From a percentage POV, it looks like you're getting closer and closer to what is expected from an honest coin. If the probability of heads = p , then the probability of tails = 1-p . If it's a fair coin, then p = 1-p and the probability of either heads or tails is p = 1/2. Now suppose the number of coin tosses is N, and let's say that N is getting pretty large. The expected value of the random variable that is the number heads out of the N tosses is going to be around the mean Np, which for an honest coin is N/2. From a count POV, it doesn't look exactly the same. If you toss an honest coin 1,000,000 times, the number of heads will likely be some distance away from 500,000. But the percentage of the number of heads out of the total number of tosses will be very close to 50%. And it will get closer to 50% with more and more tosses, but the absolute distance away from the 50% mark will grow at a rate proportional to sqrt(N). But the number of tosses is growing at a rate of N.