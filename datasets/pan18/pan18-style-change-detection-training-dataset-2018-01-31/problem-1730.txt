Step two of the cited argument from Sider is a step that relies upon a certain link between conceivability and possibility. It could have been split into two steps and phrased thusly: "2a) Gunky objects are conceivable 2b) (therefore) Gunky objects are possible". Possible worlds seems to play a merely heuristic role here. 

An important challenge to any set of criteria for theory choice are worries about underdetermination. The worries floated here are that no matter what criteria you settle on, there will always be multiple mutually incompatible theories that satisfy your criteria just as well as one another. Given your criteria, the worry goes, all of these theories would have equal claim to being the theory you should adopt, yet only one can be true. 

In both cases, however, the entities being posited must be coherent which I take to involve something like Jo Wheeler's (1) and (2). While Set Theory is a highly fruitful mathematical theory, the original, naïve formulation was famously inconsistent. Modern set theory has largely settled on ZFC (Zermelo-Fraenkel set theory with the axiom of choice) as the appropriate formalization of the concept of "set", there are alternatives (e.g., Morse-Kelley set theory) as well as various extensions (e.g., the addition of large cardinal axioms). So, even if you think ZFC is true and so sets exist, that still leaves open exactly what the set-theoretic universe is like and what properties these sets must have. All of this is to say that what it takes to satisfy the criterion of being well-defined is not perfectly clear, even in the comparatively uncontroversial case of math. Similarly, while we believe ZFC is free of contradiction the results of Gödel show us that we cannot hope for any absolute proof of its consistency (and indeed, this holds for theories much weaker than ZFC). 

There are any number of replies and counter-replies to each of these. The first four are less commonly referred to in modern times because they are essentially idealist, and the modern perspective has made a sharp shift towards materialism. For that reason, the last argument has become the most prominent. The most currently prominent counter-argument is Dawkins' contention that the theory of evolution renders a purposeful designer for life unnecessary. A counter-counter-argument might be that this just pushes the evidence of design back one level (i.e. that the existence of biological evolution is evidence that the universe was designed to be fecund). 

In the simulated world, the reason for this ontological parsimony is clear: It is a savings on resources to fake up the parts of the simulation that receive the most scrutiny more convincingly than others. If it would take, as seems reasonable, a universe's worth of resources to actually simulate an entire universe, then it might be a necessity for a simulation to appear more complex than it actually is, at least if it is being simulated in a universe like the one being simulated. If, on the other hand, the world is in the mind of God, who presumably has infinite resources, then why would God cheat? As Descartes concluded in his Meditations, we must assume a good and honest God who is not deceiving us, because without such an assumption, we can never actually know anything. 

However, this is not entirely a bad thing, since modern logic was created by substituting fuzzy natural language concepts with new, well-defined ones. 

Your own perspective seems closer to one hinted at by contemporary philosopher Nick Bostrom in his "simulation" theory, that postulates we all exist inside a computer simulated world. In a deliberately simulated world, some parts, which will be interacted with, might be "real" (at least by the standards of the simulation) meaning they are actually simulated. Others may just appear to exist, to make the simulation appear larger than it is. Similarly some people in such a world might be fully simulated, others might be "avatars", directly controlled by the simulators, and others might be "zombies" --background figures with no actual consciousness or agency. 

I've been studying this particular theory recently. While I agree that it has significant flaws at a deep level, it's harder to debunk than it might initially seem. You might want to read the originating paper, by philosopher Nick Bostrom, it is neither long nor difficult. 

The concept of an agent's degree of confidence, a graded belief. For example, “I am not sure that it will rain in Canberra this week, but it probably will.” 

For the abstractionist, possible worlds don't (necessarily) have the properties they represent certain possibilities as having--- they merely represent. 

Substance: the fundamental kinds of things. It comes up in Philosophy of Mind, for instance, when we speak of Substance Monists (who believe in only a single sort of substance, most commonly physical substance) or Substance Dualists (who believe in two sorts of substance, most commonly mental and physical substance; Descartes is commonly taken to be a substance dualist). 

In both cases, however, we would need some reason to think the relevant body of claims is true. In the case of math, we typically think that the utility of mathematics in describing and making predictions about the world gives us reason to believe the claims are true. Our experience of counting seems to give us reason to accept arithmetic, and measurement seems to commit us to something like a theory of real numbers. The truth of the corresponding mathematical theories seems to be the best explanation for the regularities we find in counting and measurement. So, we think these abstract theories are true.