As expected, tonal contrasts are very poorly preserved, and my Gengbe participant could not distinguish at better than chance rates high and low tones. I don't think tonal contrasts should be ruled out altogether: one could in principle differentiate tones by altering the tension of the pharyngeal walls, making the airflow more or less turbulent, though this is just speculation. I think that source-filter theory is the major theory in the field of acoustic phonetics. Current textbooks on voice production and phonetics (e.g. Stevens 1998; Titze 2000) make use of the theory, and do not mention any radically different alternatives. I've done a couple of little experiments on the identification of stop consonants in whispered speech, though I haven't published the results or even fully analyzed the data, and don't know if I ever will. One of them was with a single Gengbe speaker, and the other was with 15 Korean speakers (if my memory serves me correctly). With that caveat in mind, I'll venture some guesses about whispered speech. One point to add is that ability to produce a word in isolation does not translate into ability to produce that word faithfully in extemporaneous running speech. Fluency in speaking requires you to be able to pronounce words accurately without having to concentrate on pronunciation in itself. Your working memory will already be taxed by demands on forming ideas, selecting the appropriate grammatical constructions, lexical access, the emotional effect you are trying to impart, etc. Fluency requires correct pronunciation under pressure. A viable strategy for most L2 speakers is to settle on a bad pronunciation but an understandable message that is not delivered haltingly. Titze, I. 2000. Principles of voice production. Place of articulation is determined by spectral properties of the speech signal which do not require periodic excitation of the oral cavity, so we would predict that vowel and consonant place of articulation information is well preserved in whispered speech, and I didn't find anything to contradict this. Gengbe makes a distinction between lamino-dental and apico-alveolar voiced stops, and these two were never confused by my participant. Stevens, K. N. 1998. Acoustic Phonetics. The strong segmentalist view propounded by Chomsky in the 1960's and still by Halle is that phonological representations are matrices, where each column represents a segment. Arguments about the autosegmental nature of tone and accent have made this position difficult to adhere to. The more reasonable segmentalist position today is that phonological representations are made of timing nodes which are linked to different universal features. The timing slots correspond to segments. The argument made by Lodge (in his 2009 book "Fundamental concepts in phonology") is that the features are not universal, and can therefore be assigned an arbitrary phonetic interpretation. He does not, however, argue that phonological representations lack any sort of timing tier. His model of phonology still requires timing nodes, but varies from generativist work in rejecting the universality of features. Silverman (in his 2006 book "A Critical Introduction to Phonology") brings up external evidence against features, citing a well-known 1979 Study by Morais et al (Cognition 7:(4) 323-331) showing that Portuguese illiterates were unable to perform a task requiring them to add or subtract a segment to/from the beginning of a word. As far as I can tell, there is no opponent of segments who would argue that phonological words are always stored, perceived and produced as indivisible wholes, but this would be a good artificial endpoint to set in evaluating different proposals.