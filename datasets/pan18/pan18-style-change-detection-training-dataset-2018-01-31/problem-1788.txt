Decidability is linked to the second meaning of completeness. 

We can rephrase the above assertion as : "when there is rain, there are clouds" and also with : "there is rain, only when there are clouds". 

For detailed discussions of the so-called Lucas-Penrose arguments, see : 

Now use R ∨ ¬R (Excluded Middle) for a new ∨-elim: 

Now two sub-proofs, for ∨-elim: 

See Christine Ladd-Franklin, “On the Algebra of Logic”, in Charles Sanders Peirce (editor), Studies in Logic (1883), page 17-on; see pages 61-62. 

NO, completeness of first-order logic does not imply decidability. 

Your fallacy regards the "basic property" of validity : 

For proofs, see the posts: Why is this true and Proof of Drinker paradox. 

This (negative) result concerns another aspect of intuitive "completeness" (in the sense of adequacy) : for a mathematical theory, like arithmetic or set theory, it is a reasonable expectation that the axioms (formalized with first-order logic) are able to "capture" all the mathematical truth expressible in that theory. 

The rule has the proviso that the variable to be quantified, in this case x, must not be free in any assumption; in the proof, we have Fx as assumption, and x is free in it. 

Unfortunately, the semantics leaves the most interesting — and difficult — philosophical questions largely unanswered [emphasis added]. 

But the theory T is incomplete (according to Gödel's incompleteness theorem), i.e. there is a true arithmetical sentence φ not provable from the axioms of T. 

Going back to decidability, why a complete theory is so ? 

For most of "little bit complex" mathematical theories, this is not possible. 

It is enough to consider a truth assignment v such that: 

This leads to a contradiction since it can be shown to be both true and false (and not neither of them as you suggested). 

On the other hand, you can tell that an argument is invalid if you provide a counter model (i.e. an interpretation that makes the premises true and the conclusion false). But if the argument is valid you would never find such a model. 

You can read more and see some technical details here. 

The term "material implication" was coined by Russell, who made a distinction between formal and material implication. 

Time is composed only of instants. At any single instant, an apparently moving arrow doesn't travel any distance, i.e. the arrow is at rest during every instant. That means that the arrow is at rest for the entire time period. Therefore, the arrow cannot be moving at all. I think your explanation is on the right track. 

What does the definition mean? 

A more recent version of the problem is Moore's Paradox of Analysis. 

However, a few things to note: 

An important thing to note here is that the guy you quoted takes the ontological argument to be talking about god as a predicate rather than as a name of an entity. 

Admittedly, the proof is only semi-formal, but I hope it will be sufficient to motivate the claim that we really need reductio to prove certain claims of the syllogistic. 

i.e. if Ns are Ms, and some Xs are not Ms, then we may conclude that some Xs are not Ns. I don't want to claim that Bocardo has no direct proof (by means of axioms and conversion rules), but merely to demonstrate how its indirect proof might proceed using this interpretation. 

The first one (often called semantic brackets) is mostly found in formal semantics, and it's the name of the evaluation function, which maps expressions in a formal language to objects in the model of evaluation. Suppose A is the sentence "snow is white." Here's how semantic brackets are used: 

4) ∃xDx ∧ ∀x∀y((Dx ∧ Dy) → x=y) There is a dog, and any two things that are dogs are identical. 

It appears that "nothing" is a subject in these sentences, i.e., a thing about which other things are said. But actually the semantic value of "nothing" (i.e., what "nothing" contributes to the meaning of the entire sentence) is not some object, but a function from sentences to truth-values. "Nothing", like "everything", "no one", "each day", "exactly one", and so on, is a generalized quantifier. Before getting to the particular cases (1–2), let's look at a standard way of giving the semantic value of "nothing":