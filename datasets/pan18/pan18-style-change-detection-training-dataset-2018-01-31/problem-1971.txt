Fourth, a physicist (can't remember which one) said that if we had only thought more carefully about the ambiguous definition of a "point" we would never have been surprised by quantum paradoxes. Our instinct is to think additively. A good corrective to this is information theory, in which knowledge increases by the elimination of "uncertainty." A Hegelian "negation of negation." 

This is a very good question, one that brings metaphysics to life. Unfortunately, I do not have a good answer, though I've tried to think about it. 

Your urge seems to be the otherworldly allure of old-fashioned Platonism, and the very reverse of most modern tendencies, which is nice. In the ancient sense, Geometry indicates a form of completion, purification, or "self-enclosure" that at last eliminates the contingencies and irrationalities of physical experience and presumably transcends its own origins. It is well worth reading the opening of his Logic, where he "begins" with "Being" and demonstrates how it passes by itself into "Nothing" to generate, through the Aufhebung, the movement of "Becoming." The is not unlike physics finding that it could never reach the bottommost "particle," but only a kind of oscillating indeterminacy out of which particles arise... or perhaps the paradoxes in mathematics relating to zero and infinity. 

We simply cannot reason about, re-flect upon, or re-cognize singular events, they are like the Kantian ding-an-sich. Yet the idea of randomness introduces this assumption of a kind of noumenal singularity. It surely exists, but we cannot know it exists. Like zero, it is a kind of negative construct that we introduce into ordering processes for certain abstract manipulations, but nothing the eye or even the mind's eye can see. Moreover, in Kolmogorov's definition, the random sequence cannot be compressed, reduced, or divisible by... anything not equal to "itself." Or at least, I believe this is a crude rendering of his meaning. So this too contains a hint of absolute "singularity." One form of Platonism entails the actual existence of mathematical objects. Godel and others were known to feel intuitively that they were working with and actually perceiving entities different from, but every bit as "real" as, physical objects. 

If the probability of heads = p , then the probability of tails = 1-p . If it's a fair coin, then p = 1-p and the probability of either heads or tails is p = 1/2. 

The variance of the random variable (the total number of heads out of N tosses) is Np(1-p) (which, for the honest coin, is N/4) which is the square of the standard deviation. This means if N is increased by a factor of 4, then the standard deviation only increases by a factor of 2. From a count POV, it doesn't look exactly the same. If you toss an honest coin 1,000,000 times, the number of heads will likely be some distance away from 500,000. But the percentage of the number of heads out of the total number of tosses will be very close to 50%. And it will get closer to 50% with more and more tosses, but the absolute distance away from the 50% mark will grow at a rate proportional to sqrt(N). But the number of tosses is growing at a rate of N. 

From a percentage POV, it looks like you're getting closer and closer to what is expected from an honest coin. 

So as the number of tosses increases, the deviation of the number of heads (which is sqrt(N)/2)) from the expected mean (which is N/2) does increase, but not as fast as the number of tosses increases. When you divide by N, the percentage of that expected deviation, inside the total number of tosses, gets smaller and gets closer to the expected 50%. This is because it's (sqrt(N)/2)/N = 1/(2 sqrt(N)) .