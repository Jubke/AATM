Agile is based on the knowledge that scope is variable, therefore effort estimates are unreliable and not supported. Yes, you can add stories to a running sprint, if the team agrees to it. It's not a good practice though as it reduces the usefulness and predictive ability of the methodology. Yes, burn down charts can go sometimes up instead of down. It's probably not something you want, though! The customer will guide the project and decide during development what features are going to be delivered. The total cost of the project will be depending on how many iterations the customer will decide to pay for. Each will deliver a set of features. This may sound like a step back from waterfall, but it is a very powerful approach which has very desirable qualities: Value does not depend on the team exclusively: a very good team working on a very bad product will produce less value than the same team working on a very good product Agile projects are delivered at regular intervals or continuously. There is no "deadline" as such, and since one can't do estimates without the team -- one can't do estimates without the team in waterfall either -- estimates are made as late as possible in the game, when more domain knowledge usually results in better numbers. As new information emerges the product owner might discover that they need more stories (or less!) than originally thought. This is expected. Add or remove stories from the backlog with impunity. Add or remove stories from the sprint only if the team agrees to the change and commits to it. If you feel that stories were estimated as simple and get more complex as the sprint is developed, there might be a few underlying issues: All in all - these are the basic rules which you should look up to: I would argue that there is no clear way of defining "efficiency" in any meaningful way. Lastly, using something across the lines of velocity is flatly wrong. Velocity can be easily doubled by halving the "size" of a point! Of course, you can ask teams not to do that, but you can't prevent teams from inadvertently changing the size of a point across iterations -- it just happens, sizes "drift". Assuming a "perfect" PO, the most valuable stories are developed first. Efficiency will therefore go down as time increases because the stories will be increasingly less valuable As new information emerges the team might discover that it will take longer (or shorter!) to develop a story. This is expected. Story points don't change, hours left change. Value is relative to the user and not necessarily an absolute number that can be measured exactly, for example think of "brand value" -- companies often ship features for free in order to build brand value: how would we estimate it? Assuming that efficiency is somewhere along the line of "value/time", you have two insurmountable problems: In conclusion, my advice is that you take a step back: why are you trying to measure "efficiency" in the first place? Do you not trust your team to be efficient, or are you trying to measure some other quantity and using "efficiency" as a proxy? In other words, the estimation is done each iteration. The software will be (potentially) delivered in any case each iteration so you can think of each as a "fixed time" mini-project. This is relatively unimportant: that's why stories are not measured in hours, but in points: the time estimates may vary during the sprint. That said, you only need to keep track of the time left, not the time elapsed.