I tend to view the presence of paradoxes not as an indication that the quality of the model is poor, but rather, the opposite; any model which does not contain paradoxes is most likely too simple a model to accurately model our world (and based on insufficiently subtle axioms). Since the original questioner refers to a mathematical background, I'll try to stick with mathematical examples. EDIT: Due to the rephrasing of the question, and the conversation in the comments, I will try to elaborate here a bit more on the issue more generally. Now, as to the larger issue of whether or not formal logic is appropriate for arguments. The short answer is: yes, it should be used, as far as it can be-- but the meat of most arguments lies in the definitions, and the implications to be drawn. It is rare that you will see a philosophical argument fall due to an error in formal reasoning; much more likely, it is attacked because of some unquestioned assumption implied in the structure of the claims. 

Each of these represents a real paradox; none are due to imprecision of language, equivocation, or ill-defined boundary conditions. There are some parts of the world which are, sad to say, paradoxical-- and if one remains committed to explosive logics, one is faced with the prospect of either a) attempting to satisfactorily resolve all of these paradoxes (and many others), or b) forsaking reason altogether (since now everything and and nothing is provable.) 

...is not true. (If p then q) and (if r then s) does not in any way allow us to claim that one of (if p then s) or (if r then q) is true. So, we're not dealing with valid formal reasoning here, but fallacious reasoning. I just want to clarify that I know that the "tautology" listed above is, indeed, tautologous according to the truth table. However, in order to be able to apply the formal logic encased within to something less abstract than the truth table, we need to construe the material implication operator as having some real-world significance. In this case (and in many other cases), this translation fails to obtain. This does not mean that formal logic is wrong, per se, as much as it is not applicable to the domain (of facts, and not the domain of truth tables.) 

Finally, it is dangerous to think that formal logic is the "one reliable tool for reasoning", because it raises the question: by what means do you reliably know that formal logic is reliable? Logic is (famously) not self-grounding; there is no logical proof that the axioms of logic are valid. For a nice (and canonical) example, see Lewis Carroll's What the Tortoise Said to Achilles. 

A definition (in the mathematical context) is simply the granting of a new name. When we define pi to be the ratio of the circumference to the diameter of a circle, we are not making a claim of any kind; we're simply agreeing to use a given greek letter to substitute for a given notion. 

There are a few issues conflated here. Obviously, this is far from the mainstream in terms of most Western philosophy, but N훮g훮rjuna forms the philosophical basis of pretty much all Mah훮y훮na Buddhism, so this is actually quite an orthodox position (in some quarters). This is really more of an English question than a logic question, so you may wish to run it by the English Language and Usage Stackexchange, but since you asked it here: 

Since the question was updated to mention Kant's analytic/synthetic distinction, I thought I'd update my answer as well. 

Fortunately, this doesn't hamper our ability to use the square root of 2; from a philosophical perspective, we can do this by adopting a position known as Fictionalism-- in short, we can treat numbers a fictional objects, and substituted them into formulas without making any ontological commitments as to their existence. As long as the substitution satisfies the constraints (which is to say, in a broader context, is adequate to the phenomena) we're golden.