From the javadoc for StringTokenizer: 

The java tool launches a Java application. It does this by starting a Java runtime environment, loading a specified class, and invoking that class's main method. The method declaration must look like the following: 

does using slf4j cause any change in my configuration file? (i.e. something that I would have to declare differently, vs. just using java.util.logging or log4j directly) 

3) your class C1 extends library class L1, and L1 implements interface I1 and extends library class L2: C1 has a compile-time dependency on L1, L2, and I1. 

2) if your class C1 dynamically instantiates an interface I1 using Class.forName() or some other mechanism, and the implementing class for interface I1 is class L1, then C1 has a runtime dependency on I1 and L1, but only a compile time dependency on I1. 

This “is<PropertyName>” method may be provided instead of a “get<PropertyName>” method, or it may be provided in addition to a “get<PropertyName>” method. In either case, if the “is<PropertyName>” method is present for a boolean property then we will use the “is<PropertyName>” method to read the property value. An example boolean property might be: 

edit: I can think of at least 5 different situations to judge this question. Can anyone else come up with more? I want to make sure I understand the subtleties here. 

In case it is not already obvious: 

Throwing exceptions in a constructor is not bad practice. In fact, it is the only reasonable way for a constructor to indicate that there is a problem; e.g. that the parameters are invalid. 

Failing that, does anyone know of a JSON library with a parser and a generator that can be configured to output "pretty" JSON with the attributes in (say) lexical order? (A Java or Ruby library would be ideal, but other leads are also welcome.) 

The problems are to do with your paths. 

Peter Lawrey's benchmarking indicates that thread creation is significantly faster these days in absolute terms, but it is unclear how much of this is due improvements in Java and/or the OS ... or faster processor speeds. But his numbers still indicate a 150+ fold improvement if you use a thread pool versus creating/starting a new thread each time. (And he makes the point that this is all relative ...) 

It is also expensive in the sense that the thread ties down resources as long as it is alive; e.g. the thread stack, any objects reachable from the stack, the JVM thread descriptors, the OS native thread descriptors. 

You create and use byte array I/O streams as follows: 

(Note that this kind of thing can be specific to a particular chip model number or even version. The results of your benchmarks could be different on other systems.) 

NB: JAVA_HOME should NOT end with "\bin"1. 

1 - This is how the "throughput" collector works. Concurrent collectors such as CMS and G1 use different criteria to decide when to start the garbage collector. 

Does anyone know of an existing open source tool that will perform this task? 

Before you use Project Lombok (or any other game-changing technology) in some project (open source or other wise), you need to make sure that the project stake holders agree to this. This includes the developers, and any important users (e.g. formal or informal sponsors). 

The multiply is likely to be faster than the second conditional branch if the hardware-level branch prediction is ineffective. As you increase the ratio ... the branch prediction is becoming less effective. 

"You need to install the Java SDK (e.g. from Oracle's download site), and you should install it to a pathname without spaces, such as c:\j2se1.6."' 

That's not on! If the agreed project strategy is to use Lombok, then commiters who gratuitously de-Lombok the code should be chastised, and if necessary have their commit rights withdrawn. 

If you project the curves beyond 0.9 on the X-axis, it looks like 1) they will meet at about 1.0 and 2) the meeting point will be at roughly the same Y value as for X = 0.0. 

The problem you have is that 0.1 is not an exact representation, and by performing the calculation twice, you are compounding that error. 

Why do I do this? Because the average time to write a message is 35-100 ns depending on length and using a plain write() isn't as fast. If I memory map and clean up in the current thread this takes 50-130 microseconds, using a background thread to do it takes about 3-5 microseconds for the main thread to swap buffers. Why do I need to be swapping buffers at all? Because I am writing many GB of data and ByteBuffer cannot be 2+ GB in size. 

If you don't know the order of the min/max values 

You can use enums to implement an interface. 

However, 100 can be represented accurately, so try: 

Link deleted. Adding main points 

Imagine the maximum depth is 5 

EDIT: The OS is Centos 5.7, I have seen the behaviour on i7 and a Dual Xeon machines.