Both arguments are equally unsound and weak. However, using other evidence (for example that nobody has ever seen a unicorn), we can say something about the probability of Alice's and Joe's conclusions: given the evidence that nobody has ever seen a unicorn, it is likelier that Joe is right than that Alice is right. This does not say anything about the weakness of their arguments though, only about the truth of their conclusions. There is an 'interpretation' possible in which snow does not melt during the day in the Sahara / a human lives without oxygen / photons have no mass. That is because these statements can only be verified with a posteriori knowledge. Note for example that ∀y ∀x (x ∈ y ∨ y ∈ x) is equivalent to a subformula (namely the whole formula), but not a subformula itself, because it doesn't exist in the parse tree. You need to modify the structure to get to that form. There are really so many way to do this and which one you choose largely depends on your personal preference. Here are some: You can use a parse tree for this. First you draw the parse tree, then you draw boxes around subtrees. Or, in even other words: it is not impossible to imagine a cold Sahara, a human who doesn't need oxygen, or a photon that has no mass; but it is impossible to imagine P and Q such that (P ∨ Q) → (Q ∨ P) is false. Logic symbols are extensively used, especially in programming languages. As a random example I have been working with lately, this 2014 paper featuring a new block cipher shows this very well in appendix H: These tables were made with CleanLogic. Disclaimer: I developed that. It's somewhat peculiar that that textbook talks about validity without first defining it. It's a pretty straightforward definition, but usually these books are very precise. Since "the stronger the restriction, the narrower the class", Y will be smaller when P is stronger. And since N = X ∖ Y, this means that N will be greater, therefore, ¬P will be weaker. A similar argument can be made when P gets weaker: Y will be greater, so N smaller, therefore, ¬P will be stronger. I'm helping in a computing science course about basic math, and last week someone asked me: [4.] Why can only IND determine END? Eg: an IND for a cat may not resolve unclear and vague cases; eg, some strange felid hybrid may match all your attributes, but may still not be a cat. I desire to, but I am unsure whether I should, abridge my long quote; feel free to emend my post. Source: A Concise Introduction to Logic (12 Ed, 2014) by Patrick J. Hurley I do not understand the grey above, but do understand all else. In the 2 Logic textbooks read (the above and Hurley's), from the given premises, no exercise will ask you to determine the conclusion yourself; instead the textbook divulges the conclusion and then asks you to deduce it. But this is irrealistic; real life, one must determine conclusions oneself. Source: p 287, Sweet Reason: A Field Guide to Modern Logic (2010 2 ed) by Henle, Garfield, Tymoczko. So without computers, from given premises (that may be long and convoluted), how can you conjecture, before deducing, the conclusion yourself? One must at least conjecture a conclusion before attempting any deduction or (dis)proof. Birkhoff and Von Neuman proposed in the 1930s that the paradoxes of Quantum Mechanics can be explained if we abandoned classical logic and used some form of Quantum logic instead. Such a Quantum logic would change or abandon all together some of the rules of classical logic, and would be a perfect case of logical axioms arrived at by observation. While intuitively it might seem that quantum superposition (i.e something being in more than one base state at the same time) is what challenges the rules of logic, by invalidating the law of non-contradiction, this is not the case. An electron in a superposition of spin |+> and spin |-> might seem like a contradiction, but it can simply be treated as being in a distinct third state of being "either |+> or |->". My philosophical question here is that this doesn't make sense to me from the dealership's point of view: Doesn't game theory in general indicate that in such situations, cooperation will benefit the group better than selfish behavior? Doesn't the dealership stand to benefit more from having the sales people work together to achieve more sales, than for each individual to try to sell as many cars as possible, even at the cost of preventing other people from closing sales? If their pay structure was more inductive to cooperation, the experienced sales person would have handed the sure fire customer over to the rookie, and focused their efforts on the undecided customer. The dealership as whole would have potentially made two sales instead of one.