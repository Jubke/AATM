It's reasonable to suggest that "powers" might not be sufficiently broad a notion to allow for definitions that might generate the contradicting notion you need - this would be an analogue to Asimov's response. But the converse is also a possibility; naive notions of "ability" might well be such that one could specify an ability that precludes the possibility of having every ability. 

Saul Kripke, in his paper "An Outline of a Theory of Truth", talks a little about sentences that don't receive determinate truth values in virtue of their logical structure, such as the self-referential examples you're talking about. Kripke calls these "Ungrounded" sentences. The general intuition behind the idea of ungroundedness is that the valuation of some sentences might be totally unsettled by the way the world is taken to be, and that this shouldn't stop us being able to account for a theory of those sentences that do receive a determinate and positive truth value. 

Secondly, your example student is having a problem with taking Logic and Mathematics to be systems of paradigmatic necessary truths. This seems quite legitimate for someone new to philosophy, since public exposure to these things is generally purely formal. Some Philosophy of Language can help to unsettle some of the prior intuitions that your students might have already established. 

The Truthmaker line is to say, as we did above, that there needs to be something in virtue of which a given proposition is true. This is true of negative propositions as much as it is of positive atomic basics - it can't be the absence of a truthmaker that is responsible for a negated atomic sentence being true, unless we want to reify the notion of truth-making gaps. Beall's suggestion is that we might read the negation operator intensionally, because we understand what it means for a negation of an atomic proposition to be true by considering the scope of possibilities in which that proposition would not be true. 

(In effect, the "possibility" of truth or falsehood in a proposition doesn't commit us to an ontology of alternate universes of states of affairs if we can get this kind of abstract truth function construction going. We do need such an account, because the more natural way to interpret negative propositions in the picture theory is to point to an inflated ontology with non-actual states of affairs for them to correspond to. And if we can account for negated propositions in this kind of mathematical way, we get the bivalence of any proposition as part of the package.) 

This move allows for so many divergent factors in an account of what negations, negating, contradiction, assertion and truth have to do with one another. We might think that for a number of cases, asserting a negation and not asserting come apart; we might say that the negating function in an assertoric context doesn't always correctly grasp a proposition's "actual" negation, we might say that you can have prima facie and ultima facie contradictions depending on whether we have an internal or external algebra of negation, we might say that you can assert a statement without failing to assert its negation etc. 

What is generally now called Classical logic is the framework that is thought to encapsulate both the Predicate calculus formalism and the compositional aspect that a structured, two-valued algebra of logic gave us in the propositional case. Predicate logic works with the idea that our domain of objects is something that we refer to in the logical structure of making assertions - when I say that "That chair is green", the logical form of what I'm saying actually identifies something in the domain to be "that chair", and to attribute to it the property of "being green". The logical structure of language is such that what I say is true when it turns out that "being green" is, according to the interpretation we make, something that the object that is "that chair" satisfies. We can introduce first-order Variables and Quantifiers to make generalizations about whether properties apply to some object, every object, no object etc. And in the Classical framework, every property is understood to either determinately apply to a given object or to determinately fail to apply to that given object; the payoff being that we can use another (more complex) algebraic analysis to let us build up expressive and complete deductive systems for our logic. 

So there are at least two interesting Dialetheist responses to your question. The first is to pull apart propositional negation from negation in an Assertoric Context. The second is to say that even propositional negation has a modal sense that classical predicate logic doesn't capture effectively. 

The trick here is the work being done by "interpretations" in your working theory of validity. With an interpretation, we're building up a model according to which a particular statement or set of statements might be true. In formal logic we are often very mathematically precise about what sorts of things count as models (we usually need to give an account in terms of algebra or set theory), but we can usually speak informally about conceivable pictures of how things might be. 

What we might say is that software specification and verification ought to be suitably founded in a semantics in just the same way that first order logic is founded in the model-theoretic programme following on from Tarski's initial discoveries. In formal computer science, this is studied in the field of Denotational Semantics and other related programmes, and some of the ideas about what kind of axiomatizations there are for correct software (and also hardware) behaviour are considered in Formal Specification and Verification logics such as Floyd-Hoare logic.