Often the things we can be pretty certain of are ontological commitments. Other computer scientists more explicitly raised questions "with regard to the main technical argument in a recent post by Scott" by asking What ontological commitments are really needed? Even so I only read that paper in order to be entitled to answer this question, I think the paper is really worth reading even if you don't want to answer any question. It's easy to read, covers much ground, and even sketches the proofs for some non-obvious theorems. But is it relevant to philosophy? Well, it is an honest attempt to address an audience of philosophers and tries to reduce (or show how it might be possible to reduce) the gap between theory and reality in certain areas. (2) Why are simple explanations likely to be correct? Or, less ambitiously: what properties must reality have for Occam’s Razor to “work”? One fundamental opposition dominates the spiritual world of primitive men, that between the sacred and the profane. [...] Dualism, which is of the essence of primitive thought, dominates primitive social organisation. In mathematics, when we assert the equality: 1+1=2 we are not asserting that the two strings of symbols 1+1 and 2 are equal, but we are asserting that the objects named respectively with "1+1" and "2" are the same object: the number two. When the hunter notes the traces in the grass, he assume that they has been produced by a beast. clearly, with n "little, we have no problem to "hold epistemically" (to imagine ? to visualize ?) it. I'm not sure about a set S with n = 3567 elements. where A is the conjunction of the axioms of your theory and T is a theorem. (iii) S is justified in believing that P is true. διάνοια (the second form : reasoning), I agree with the above answer, but I'll attack the issue from another point ov view. The issue is that, according to JTB theory, the conclusion : "Jones owns a Ford, or Brown is in Barcelona" appear to be knowledge because it is true (item (i)) : it's a fact that Brown is in Barcelona, and it is believed by Smith (item (ii)) and is justified by a correct use of inference rules (item (iii)) : You can see: Barry Smith (editor), John Searle, Cambridge UP (2003), page 18: Clearly (for me) the problem of induction has not been solved yet (as all interesting philosophical problems ...). In the relevant passages of Apology (see 24b-c and 26b), Plato does not use πίστις in speaking about Socrates' "belief in (city) gods". Other computer scientists more explicitly raised questions "with regard to the main technical argument in a recent post by Scott" by asking A typical example is a Henkin style completeness proof for first order predicate logic. We are talking about formulas and deductions that we "can" write down, so we can be pretty certain that we can write down things. We use this certainty to construct a syntactical model of the axioms. (The consistency of the axioms enters by the "non-collapse" of the constructed model.) Exploiting ontological commitments Could we have felt evidence for SDP!=P? My impression is that the main technical argument failed to convince them, but their high esteem for Scott prevents them from being blunt about this. My question is the following: The post from 2014 tries to construct a single Bayesian argument with a single "Bayesian probability" for P!=NP. All the other posts work with multiple independent reasons, and make no attempt at all to unify this into a single Bayesian probability argument. Is subsuming multiple independent reasons into a single Bayesian judgment really in agreement with the scientific method? What does epistemology says about this? (There are statements which are either true or false, but I'm not sure whether this implies that I should only assign a single Bayesian probability to such a statement quantifying how sure I am that it's true.)