Since then it was pointed out that "absolute certainty" was never absolute, and issues with social acceptance of proofs did not originate with computers. For instance, Kempe's 1879 proof of the four color theorem was accepted as such for 11 years, until Heawood found a flaw in it. A fierce debate about the role of rigor and experiments/simulations commenced when Jaffe and Quinn in 1993 suggested to implement Tymoczko's idea by demarcating "theoretical" (modeled on theoretical physics) and "rigorous" mathematics institutionally, in publications, etc. See discussion and references under What makes something mathematics? The institutionalization idea did not take (some saw the Jaffe-Quinn proposal as an attempt to devalue "theoretical mathematics"), but clear delineation of conjectural/heuristic material remains an informal norm. It is also expected that any substantive use of computer tools, even in calculations let alone proofs, is explicitly mentioned and described enough to be reproducible (which is similar to reporting experiments in science). 

Of course, purely mathematical problems of motion are resolved by calculus, but from a philosophical point of view the nature of instantaneous velocity, a shadow of motion where there can be no motion, is puzzling. And the fact that even classical physical description requires not the sensible physical space, but the hidden configuration space with twice as many dimensions (to account for velocities and make Zeno's arrow move) is even more puzzling. When it comes to time, position, and velocity things get even more puzzling in quantum theory. 

Brouwer gives precedence to ‘two-ity’ in his account of the natural numbers. It is not good enough to merely start with a unit to obtain the natural numbers. Once we become aware of a sensation passing into another sensation, for example, we have the foundation for the abstract two-ity out of which the natural numbers are generated. Suppose we were to mark this awareness as ( | ) | to indicate the retention in memory of what was sensed earlier. This ‘two-ity’ can then be an element of a new two-ity: (( | ) | ) |, and so on... Brouwer emphasizes how in this successive, sequential structure with its ordering of ‘before’ and ‘after’ the ‘before-after’ or ‘first-second’ are held together in consciousness so that we have unity in multitude." 

I am not sure that saving phenomena can be used to argue that Plato and Aristotle admitted or did not admit that different suppositions might be consistent with them. At the time Plato posed the problem of reconciling apparent motions of planets with the Pythagorean ideal of uniform circular motions not only wasn't Ptolemy's system around, but no such theory existed at all. It wasn't clear that it could be done, and there definitely was no notion of mathematized physical theories, or of the scientific method for verifying them. It took the genius of Eudoxus to produce a model that accounted for backward planetary motions at least qualitatively, in response to Plato's challenge. It was extremely clever and counterintuitive, this cleverness might have even suggested to many that it was the only right track. 

The ethico-mathematical analogy is ancient, but it did gain some recent prominence among analytic philosophers. Clarke-Doane's Moral Epistemology: The Mathematics Analogy, Franklin's On the Parallel between Mathematics and Morals, Lear's Ethics, Mathematics and Relativism all focus on the analogy. And all of them name book VII of Plato's Republic as its point of origin, where Plato outlines the work that the analogy is supposed to do: 

Nonetheless, contemporary perceptions were different. Those more concerned with philosophical status of infinitesimals saw Berkeley's criticisms of them as pertinent, and Newton's conception as more coherent (including Kant, his sympathies to Leibniz notwithstanding). One could say that Newton's "kinematic interpretation" of infinitesimals (which he partly owes to Archimedes through Toricelli and Barrow, see Who discovered the power rule for derivatives?) was close to Aristotelian understanding of motion with potential infinities and the classical resolution of Zeno's paradoxes attached. Maclaurin attempted a rigorous exposition of calculus on the basis of the kinematic interpretation in 1742. One could even say that Kant's theory of synthetic construction in mathematics relies on Aristotelian restriction to potential infinities that arguably permeates Euclid's Elements (indeed, Kant explicitly modeled his concept/intuition duality on Aristotle's matter/form). Friedman comments in Kant's Theory of Geometry: 

This multiple realizability is already a problem for philosophers, we would like to think that there is a unique concept of "two", expressed as 2 or {{∅}} or {∅,{∅}}, but set theory can only provide us with an arbitrarily chosen token for it. This leads to popularity of mathematical structuralism, the philosophical position that it is not what it is that makes 2 a 2 but only its place in a structure, in this case the structure of the counting number series described by the Peano axioms. Peano arithmetic already shows that natural numbers, unlike cardinals, can be lifted off of set theory since it does not depend on it. Neither does category theory, which has its own versions of natural numbers. Even within set theory the notion of "finite cardinal" can come apart from that of a natural number if we play around with the axioms. For instance, Dedekind defined "finite cardinals" as equipollents of those sets that can not be put into bijective correspondence with their proper subsets. Well, Russell and Whitehead showed in 1912 that Dedekind finite cardinals can be infinite (on the usual conception) in set theory without the axiom of choice, so-called ZF, or other alternative set theories. Intuitively, this is because those models of set theory do not have enough bijections to "detect" infinity Dedekind's way.