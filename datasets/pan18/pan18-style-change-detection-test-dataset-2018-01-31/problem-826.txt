Propositional semantic theories, like Frege's or Kripke's, may be looking for theoretical unity where none is to be had. Linguistic practice is heterogenous, with multiple ways to pick up usage. Kids may learn to use "meter" in sentences correctly by mimicking and inferring, without bothering to know what it "looks" like. Another problem is that propositional theories seek to assign meaning and reference to expressions in isolation, whereas indications are that linguistic use is holistic, in addition to opportunistic and eclectic. The use of words is learned from how they combine with other words and/or used in pragmatic situations, not so much from their propositional meaning and/or reference. Some of this is addressed in inferential semantics. Question: Realists may like string theory for revealing truths about hidden reality they believe in, but why shouldn't empiricists love it as a vehicle of unification even if it makes no new testable predictions (which is unlikely)? Conventional wisdom says "no", lack of new predictions being the main criticism. Johansson and Matsubara review string theory from various empiricist perspectives, and the best they can say (for string theory) is that it is not the right time to drop it. Yet. They add that it still dominates physics only because "those involved have strong realist convictions". If we do have such a faculty how does it work? A common theme to such reconciliations is that reality is posited as hypothetical with its features determined through some form of inference to the best explanation. Roughly, positing the ontology of our best scientific theories as real/existing best explains their empirical success (Peirce adds that Humean empiricist view of laws of nature defeats science as an explanatory enterprise, an ethical point touching on intellectual values). What is also common to Peirce and Popper (but not Quine) are the partitioning of reality into different kinds of existence, and the idea of convergence of scientific knowledge to "the truth". Peirce had an ontology of acting laws and relations, both inside and outside the "subject", underlying the derivative objects, both concrete and abstract, existent and real-possible, and Popper had his three worlds. According to Germino: Questions: Does naturalized epistemology dictate that natural science should relax sense empiricism, and approach non-empirical phenomena partly first hand? If so, how can the scientific method be adapted to introspective/intuitive phenomena that are not readily reproducible, manipulable, measurable, and/or publicly accessible? What would play the selective role of empirical testing? Can there be non-empirical (more likely, not entirely empirical) natural science? 

There is an unbroken chain of tradition from Kant to all major currents in the philosophy of science. As for demarcation, Kant's standard was far stricter than even Popper's. For example, he called chemistry "systematic art or experimental doctrine but not a proper science", and infamously opined that empirical psychology will never become a science because introspection data is too garbled and ephemeral. Only that which could structure experience according to synthetic a priori principles in a mathematical form (i.e. mathematical physics) deserved the name of (natural) science. He somewhat softened his stance in late years, willing to find a place for chemistry as a kind-of-science in light of Lavoisier's work however. I still suspect that not even modern biology, let alone soft sciences, would pass Kant's muster.