Not all inductive inferences are temporal, so the future "resembling" the past can be moot, a more general idea would be that various parts of nature are "uniform", "resemble" each other. But it is not logical to assume that the future will "resemble" the past, or that the nature is "uniform" in this or that aspect. In many cases such assumptions are blatantly unreasonable and contrary to fact, and much better predictions can be made by assuming the opposite, change and non-uniformity. The trick is to tell which is when, that is the real problem of induction. As outlined by Hume and elaborated by Mill the problem is basically that there is no justification for performing inductions: deductive justifications upend the "inductiveness", and inductive justifications are either circular (if there are finitely many types of induction) or lead to infinite regress (if there are infinitely many). Norton's Material Theory of Induction has a nice review of the current state of the issue. This is likely exaggerated, Kant was in the air of the times, and Husserl did draw parallels with him already in Logical Investigations (1901), while reinterpreting his "synthetic" notion of a priori into intuitive one, and adopted the label and terminology of transcendental idealism around 1915, apparently at Natorp's prompting. There are also undeniable parallels between his approach and that of contemporary neo-Kantians, especially in the early works. The Crisis, on the other hand, is a late work, not completed in Husserl's lifetime, and written under pronounced influence of existentialism, in particular Heidegger's. One has to keep in mind though that what appears to be Kantian framework in Husserl may be at least partly attributable to their common root in Hume. I recently came across a very nice summary of Husserl's theory of cognition in Zhok's Ontological Status of Essences in Husserlâ€™s Thought, which makes Husserl's affinities and breaks with Kant more transparent. 

Such a surreptitious shift from constructive to platonist proofs is what motivated the intuitionist pushback, but as Wittgenstein points out the self-deception involved is far more pervasive. The point affects even formalists, as such shifts may involve major changes in the rules of the "formal games" of mathematics. On the other hand, it would be silly even for intuitionists not to make use of computer assisted proofs pragmatically. After all, when done by competent and trustworthy professionals the degree of certainty they provide is far greater than from numerical checks of conjectures, which have a venerable history involving Euler and Gauss. These are historical examples of the Gettier problem of knowledge as justified true belief (JTB), when a person is justified in her belief, and the belief is true, but the justification relies on elements that are false. To put it plainly, a person believes the right stuff for the wrong reasons, but this "wrongness" is external to justification. Officially, Gettier knowledge is not knowledge, but "X knew that p" is colloquially interpreted as "X believed that q, which is translated into modern terms as p, and comes out as true", otherwise if X still believed that q then "X mistakenly believed that p". 

[...] It is not logic - I should like to say--that compels me to accept a proposition... when there are a million variables in the first two pairs of brackets and two million in the third. I want to say: logic would not compel me to accept any proposition at all in this case. Something else compels me to accept such a proposition as in accord with logic... I want to say: with the logic of Principia Mathematica it would be possible to justify an arithmetic in which 1000 + 1 = 1000; and all that would be necessary for this purpose would be to doubt the sensible correctness of calculations. But if we do not doubt it, then it is not our conviction of the truth of logic that is responsible." It is natural to use it, both aim at the problem of vagueness in predicates. The Sorites paradox is as ancient as the Liar, and much more pervasive, as a list of nicknames suggests: paradox of the heap, paradox of the beard, continuum fallacy, line drawing fallacy, bald man fallacy, etc. One grain is not a heap, adding a grain to not a heap does not make it a heap, therefore no number of grains makes a heap. More generally, if there is an unbroken chain of intermediaries between x and y then the argument concludes that x and y are not essentially different, be it handful and heap, black and white, romance and porn, or art and kitsch. Or contrapositively, if they are essentially different then there must be a bright line separating them. Soritic reasoning is considered fallacious, but telling what exactly is fallacious in it proved to be as intractable as the Liar. Many responses revise classical logic to assign neither true nor false to borderline cases, or both. "I will know it when I see it" is a practical response on a par with Diogenes walking to "refute" Zeno, or Johnson kicking a stone to "refute" Berkeley. P.S. There are many proposals to solve the problem of induction (abductive, Bayesian, Norton's own material one, etc.), but perhaps the best known is Popper's "dissolution" of it. Induction, what induction? Popper's solution to the problem of induction is that there is no induction. What is attributed to induction, according to him, is really a guess followed by a hypothetic deduction of consequences and their corroboration or falsification. Often the guessing is so instinctive and the deduction so trivial (as in say "all crows are black") that we collapse it into undivided "induction". While Popper may have "solved" the problem to his satisfaction, his critics, Norton included, contend that he merely pushed it elsewhere. Because it is unclear what would "justify" entertaining and testing these hypotheses as opposed to infinite others, other than... induction: