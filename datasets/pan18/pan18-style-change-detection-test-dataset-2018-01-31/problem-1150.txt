I generated the DRS by first paraphrasing the sentence as "if a child is not disciplined , the child will be bad ." and then feeding it to appropriate field in the C&C+Boxer demo page. I don't think it's helpful to think of algorithms as being "correct" or "incorrect". Is the grammar model used in the Stanford Parser "correct" because it can parse many sentences perfectly, or "incorrect" because it parses many sentences incorrectly? I think it's more helpful to think in terms of degree of suitability of each algorithm for a particular task. We now have NPs that have become functions that accept Vs and VPs as arguments. Determiners, that play a subordinate role in Phrase Structures, play a key role here in controlling the scope of variables, and the order in which functions apply over arguments. Speaking for myself, the piece did not make me uncomfortable in any way... I just found it very very amusing. I haven't worked with any of these tools, myself. So I can't tell you which ones require you to write software. I understand that you are a student of marketing. I don't know how comfortable you'd be with writing code. But if you have to write code, I think writing Python (for NLTK) should be less of a hair-pulling experience for you, than writing Java for one of the Java-based tools could be. The specific examples you mentioned seem to contradict the general question you are asking. The sentence fragments, S1 and S2 has some surface-level similarity, but are very different semantically; the object that's beautiful is not the same. From the description of your task, I get the impression that you do not really need semantics of any kind â€” you intend to discard many segments of a sentence. I believe that you'd be better off looking at the chunkers listed here. Since the outermost component of this is a material implication, you can disprove it by finding an instance where the child was not disciplined and was still good. Models based on Frame semantics could use the context of the utterance "pass me the ______" to predict the missing word. In the context of a garage, it could be tools like hammers, screwdrivers, etc; in the context of a dining room, it could be salt, pepper, spoon, etc. Besides this, many people have worked on creating and/or analysing RoboCup commentary data. I haven't looked for links for that. But I think they ought to be easy enough to find. Try this website where they have the corpus as an XML file. The text within <nl lang="en"> is what you are looking for, I guess.