Actual infinities collected into sets were not officially contemplated by (philosophizing) mathematicians until Cantor (with some anticipation by Bolzano) countered Aristotelian and scholastic arguments that such objects are paradoxical, see How does actual infinity (of numbers or space) work? Ironically, Cantor rejected the infinitesimals themselves, see What was Cantor's philosophical reason for accepting the infinite but rejecting the infinitesimal? Also, there is a difference between abstraction, which he may have believed was unique, and trying to guess at the unseen from the visible, which by common daily experiences can't be done uniquely. As Aristotle says in Metsaphysics 1010b:"And as concerning reality, that not every appearance is real, we shall say, first, that indeed the perception, at least of the proper object of a sense, is not false, but the impression we get of it is not the same as the perception". When Aristotle was inferring his theory of natural and forced motions from pulled carts and falling rock and feather he was abstracting, but when Eudoxus and Calippus were attaching planets to homocentric spheres they were just speculating about a mechanism behind the visible motions. It's unlikely that Aristotle believed that specific arrangements of inclination angles and rotation speeds they came up with, which were still refined and contested in his time, were uniquely suitable. Aristotle made his own additions to the arrangement to connect spheres for different planets into a single chain driven by his unmoved mover, which required adding counter-spheres in between to prevent planet specific motions from being transferred. In other words, he was aware that mathematics can be altered to fit a theoretical goal without affecting the phenomena. Weyl makes suggestions as to mathematical realization of his fluid continuum and Brouwer built a full blown theory of his somewhat "less" fluid one, but remarks pessimistically that “the inapplicability of the simple laws of classical logic eventually results in an almost unbearable awkwardness”, the closer we get to the intuitive continuum the less palatable it becomes mathematically. Predicative continuum of early Weyl, developed by Feferman and applied to physics by Field, is even less fluid, but was shown to be sufficient for all of classical physics at least. In his time Aristotle could afford to be optimistic, for one finds the same conception of “fluid magnitude” in his Physics, as in Euclid’s Elements. In our time intuitionism could only build chain of continua mediating between philosophical insight and mathematical physics. Now suppose the number of coin tosses is N, and let's say that N is getting pretty large. The expected value of the random variable that is the number heads out of the N tosses is going to be around the mean Np, which for an honest coin is N/2. 

From a count POV, it doesn't look exactly the same. If you toss an honest coin 1,000,000 times, the number of heads will likely be some distance away from 500,000. But the percentage of the number of heads out of the total number of tosses will be very close to 50%. And it will get closer to 50% with more and more tosses, but the absolute distance away from the 50% mark will grow at a rate proportional to sqrt(N). But the number of tosses is growing at a rate of N. The variance of the random variable (the total number of heads out of N tosses) is Np(1-p) (which, for the honest coin, is N/4) which is the square of the standard deviation. This means if N is increased by a factor of 4, then the standard deviation only increases by a factor of 2. 

So as the number of tosses increases, the deviation of the number of heads (which is sqrt(N)/2)) from the expected mean (which is N/2) does increase, but not as fast as the number of tosses increases. When you divide by N, the percentage of that expected deviation, inside the total number of tosses, gets smaller and gets closer to the expected 50%. This is because it's (sqrt(N)/2)/N = 1/(2 sqrt(N)) . 

If the probability of heads = p , then the probability of tails = 1-p . If it's a fair coin, then p = 1-p and the probability of either heads or tails is p = 1/2. 

Hockney also gives an atemporal interpretation of the Big Bang based on his metaphysics, according to which the Big Bang singularity is not an event in time but rather a metaphysical posit somewhat reminiscent of the "initial state" of Plotinian One or Hegel's Geist. I suppose there is also some affinity to the no-boundary cosmological proposals, a la Hartle–Hawking, where the temporal world is emergent on a timeless substrate in a manner that can be remotely analogized to performing a Fourier transform, see On the Emergence of Time in Quantum Gravity by Isham and Butterfield (especially pp.52-62). Here is more Hockney: 

Actual infinities collected into sets were not officially contemplated by (philosophizing) mathematicians until Cantor (with some anticipation by Bolzano) countered Aristotelian and scholastic arguments that such objects are paradoxical, see How does actual infinity (of numbers or space) work? Ironically, Cantor rejected the infinitesimals themselves, see What was Cantor's philosophical reason for accepting the infinite but rejecting the infinitesimal? 

This is not to say that the ratio does not genuinely occur in nature (along with many others), or that some artists did not consciously use it, e.g. Dali in the Sacrament of the Last Supper. Le Corbusier, the architect, developed a whole system of proportions, called Modulor, which "was supposed to provide a standardized system that would automatically confer harmonious proportions to everything, from door handles to high-rise buildings."