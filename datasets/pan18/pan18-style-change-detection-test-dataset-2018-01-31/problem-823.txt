In Remarks on the Foundations of Mathematics, even before the advent of computers, Wittgenstein identified a general phenomenon that feeds such worries. To make a computer capable of assisting in a proof a lot of linguistic conversions are required. We typically assume "transparency of language" and see them as converting the "same" calculations into different formalisms, but supposed "conversions" may alter the conception of what is done. The "dangerous, deceptive thing" about it is that "it makes the determination of a concept - concept formation - look like a fact of nature": Generally, when we discover some persistent empirical coincidence, how are we to decide if it is necessary or just true? I can think of two possible approaches, a testing principle or a guiding principle, perhaps their is a third or they can be mixed. Cassirer's Substance and Function And Einstein's Theory of Relativity (1910/21) was one of the first assimilations of relativity by a major philosopher. Based on it, Cassirer rejected Kant's characterization of space and time as forms of pure sensibility, and described them instead as initial forms of conceptualization by understanding, which can be refined by advancing science into more elaborate forms, such as Einstein's spacetime. Reichenbach in Theory of Relativity and A Priori Knowledge (1920) takes the logical structure of general relativity as a logical blueprint for general empirical theories. He distinguishes "axioms of connection", laws connecting experimentally accessible empirical concepts, and "axioms of coordination", non-empirical principles required to make concepts empirically meaningful in the first place. Without the axioms of coordination, such as the constancy of the speed of light, and the equivalence principle in relativity, the concepts like inertial frames or energy have no empirical meaning, i.e. spacetime and the metric tensor are presupposed a priori. I used to think that Kuhn's "incommensurable paradigms" are an exaggeration, and perhaps they are, but there is a genuine problem there. Let us grant downward correspondence, that is that "less advanced" paradigms can be imported into "more advanced" ones using anachronistic translation, and cheerfully assume that today we know what's true. This still leaves the problem of Gettier knowledge. The justifications historical figures had for their beliefs invariably depended, at one place or another, on something that we now hold false. People often ask on the history site if people knew p before modern times, or who first discovered p. I usually give a colloquial answer, with reservations, and then try to explain how modern concepts emerged, and differ from the historical ones. Is there a more principled way? Kuhn's dissolution of the question as meaningless seems extreme, but the colloquial interpretation is hardly a satisfactory philosophical position. 

As for compatibility with realism, it depends on the type of realism in question. It is generally agreed that indeterminacy rules out the most naive form of realism, which simply projects current theoretical entities onto objective reality. More sophisticated forms of realism impose restrictions on "realistic" theories in addition to their simple agreement with the observations (such as simplicity, theoretical unity), and/or restrict the scope of what is claimed to be objectively real.