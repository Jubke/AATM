Grammar is a very broad term that can roughly be described as The adjuncts to a sentence may be iterated practically unlimitedly - including the possibility of there being none at all -, while the complement position needs to be occupied no less than and no more than once. I don't know what the symbols are intended to mean, but I could imagine this is a grammar describing algebraic terms (like 1+2, (3*4)+6 and so on). With a mixture of terminals and non-terminals on the RHS, but only one non-terminal on the LHS, this would be T2. As you said, they are not expletives, because they are an inherent part of the sentence's meaning. The unmarked syntactic order for a V2 sentence would be Hans hat dem Lehrer das Buch gegeben. The underlying structure (V-final) is Hans dem Lehrer das Buch gegeben hat. So you move hat into C position and gegeben into SpecC. The other constituents stay where they are. is not a regular conditional! Those "would" or "might" constructions are called counterfactuals, and are semantically not identical to material implication (as it would be the case with "if" sentences or the other kinds that you stated), but - at least in the theories I am aware of - rather have to be analysed with respect to possible worlds (roughly, could we imagine a world hopefully close to ours and in which the consequent is implied by the antecedent if it were true, since (as the name already tells) the antecedents usually are not true in the actual world we are talking about), or possibly by adding some more propositions to the antecedent until the consequent eveutally logically follows from the resulting set of propositions. In the end, the analysis of "would" will directly or indirectly involve material implication to be interpreted as "if... then", but still, I'd like to have pointed out that this construction is semantically not of the same type as a classical if-statement. 1 The distinction between "free modifier" and "adjunct" is not as straightforward; "modifier" is a bit more theory-independent in that "adjunct" is usually used in the context of phrase structure grammars, but "modifer" is also a more vague term that is more semantically than syntactically motivated. You'll find both terms in the literature, but in computational parsing, which often relies on dependency structures, "modifier" is probably the more common term. The reason why S is not so nice is that it doesn't really give any information of what it is built from, and doesn't fit the general scheme of constituent trees. In X-bar-theory, variants of which pretty much any major syntax theory is based on, you want to build up your trees systematically starting from lexical items (words) below and making constituents larger and larger, going over to phrases until everything is combined to one maximal structure, thereby assigning every node a combination of a category (such as nominal, verbal, prepositional, inflectional, ..) and a so-called projection level (roughly, it tells us how complete our tree is up to this point: is it a single word, a phrase (= a group of words which somehow belong together) or something in between) encoded in the label name. Labelling the root of your syntax tree with an S doesn't fit into this scheme now, because you do have "S" as an abbreviation for "sentence" and thus a kind of category, but it doesn't tell us anything about the mentioned projection level and isn't build up of anything S-like either (a CP (= complementizer phrase) has a complementizer in it, an IP (= inflectional phrase) contains an inflection node, ...); for all the other constituents further below in your tree, you have a so-called head which determines the category of the phrase, dependents which complement the head and so on, but the S is just standing there as a single S-thing and branches into, e.g., some NP and VP which violates the assumption that sentence structures are built up in sysetmatic and preditable patterns. TP, IP, CP etc. are different here; they do fit the widely accepted X-bar scheme and give us the information we want, namely of what category a sentence is (something tensed/inflected/...) and the projection level (namely a complete phrase that can stand on its own). That's the reason why most modern syntax theories rely on these labels as the top nodes of sentences, because they don't break the general explanatory pattern of how constituent trees are built up. Additionally, IP and TP are labelled so because they are headed by a category "inflection"/"tense" which makes sure that the sentence is properly inflected w.r.t. tense, subject-verb agreement and so on, and it is assumed that this happens at a stage higher up in the hierarchy after all verbs have started off as uninflected. If you don't include an I or T in your tree, but simply say that an NP and a VP combine to an S, the question is where the inflection comes from, because it must be reflected in the tree somewhere. So, no, you can't simply put everything under S without violating basic assumptions shared by major syntax trends. But you can, if you want, make the generalization for yourself that "CP", "IP" etc. are more or less equivalent ot "sentence".