Just kidding, as a fellow engineer, I have an inkling where you are digging at. Welcome to the fascinating underbelly of mathematics, which is constantly churning and mixing with the philosophy of mathematics. It behaves a bit differently than the upper tiers. Instead of trying to make powerful earth shattering statements about our reality, like proving there are countably infinite primes, they're trying to define the most subtle and intuitive assumptions you can make to get there. Your concept that it is an appeal to intuition is valid, because that's what it is. Euclid's definition of a line is really two pieces. The first doesn't care about how it maps to the real world, so he could have said This is mathematics! We can define anything we bloody well want! A FribbleMoose may be a neat definition to work with. However, it is him electing to call it a "straight line" that suggests that this mathematical definition may have real life implications. This implication is not material to the definition. If it turned out that all of society agreed that Euclid's wording was a poor one, it would at least still have at least as much meaning as a FribbleMoose had, although people may complain about his deceitful naming scheme. Livio in The Golden Ratio and Aesthetics is similarly skeptical: 

This becomes clear from the following paragraphs, where Russell describes his definition of 2 as a class with non-"equal" x, y, one of which is always "equal" to any z in this class, and then writes:"if two things have all their properties in common, they cannot be counted as two, since this involves distinguishing them and thereby conferring different properties upon them". In other words, his definition of 2 still works even if the defining class "actually" has more than two objects. 

The notion of "cardinal number" or "cardinality" (even finite) is much more recent, it is one way to make the everyday concept more precise for mathematical use, the one favored by the current formalization of mathematics. The notion was introduced by grammarians in 1590-s to distinguish between counting numerals (one, two, three) and order numerals (first, second, third), so-called ordinals. But their modern mathematical life begins at the end of 19th century in Cantor's set theory, which imported the distinction and made it even more technical. Cantor replaced the elementary concept of a number with a derived and abstract one based on sets (for what it is worth, the informal counting conception is closer to his ordinals than to his cardinals, the notions are equivalent in scope in the finite case but diverge dramatically for infinities). Two sets are equipollent if they can be put into a bijective correspondence (this is now called Hume's principle), and the cardinal number of a set is something like the equivalence class of all sets equipollent to it, or so Cantor wanted to say. This turned out to have technical problems, and now more "concrete" definitions are preferred, ones that identify it with one of very specially generated sets like ∅,{∅},{{∅}},... or ∅,{∅},{∅,{∅}},... , see Set-theoretic definition of natural numbers. The dominance of first order logic is based on technical results of Skolem and Gödel, rather than on philosophical arguments. Skolem proved that first order logic has nice model theory, Gödel proved that it is recursively axiomatizable and hence has a nice proof theory (unlike higher order logics), and compact (unlike infinitary logics). At the same time, first order Zermelo-Fraenkel set theory (made first order by Skolem, who modified Zermelo's comprehension axiom accordingly) proved to be more than sufficient not only for all of classical mathematics, but even for higher set theory and model theory. On the other hand, higher order set theories, like Russell's, proved to be unwieldy. In the end, Russell had to introduce the infamous "axiom of reducibility" which effectively reduces the logic of his set theory to first order. That being said, there are many cases where we wish to talk about a domain of "everything." Such a thing is often called the "Universe," and it encapsulates every "thing" which one may wish to talk about using the language of mathematics. It is often given the symbol "U," but it is typically referred to using words first, to make its meaning perfectly clear. To give a concrete example, the strings of length 3: 0 heads = 1 string ({T, T, T}), 1 heads = 3 strings ({H, T, T}, {T, H, T}, {T, T, H}), 2 heads = 3 strings ({H, H, T}, {H, T, H}, {T, H, H}), 3 heads = 1 string ({H, H, H}). 8 total strings, each with a probability of occurring of 1/8. Thus, by addition, probability of 0 heads = 1/8, 1 heads = 3/8, 2 heads = 3/8, 3 heads = 1/8 What you ask for is a bit tricky because you are using an informal concept to describe variables, rather than the very exacting formal definition of what 'x' really means. In general, informal concepts tend to run into trouble when you try to take the opposite of them, because they weren't sufficiently rigorously defined to survive such a treatment. This visualization can be done in many ways. One way is to look at all the different sequences of heads and tails that can occur. Clearly each sequence occurs with equal probability (with a fair coin). However, when you put these into "bins" based on how many heads you see, you find that there are many more sequences with an "average" number of heads than those which have extraordinary numbers of heads. This causes us to see average numbers more often than extraordinary numbers. The coin toss example is an interesting example. The statistical distribution of the digits of the expansion of π is another. To make this analogous to the coin toss, let's consider the binary expansion of π. This is statistically random. However, it can be shown that sequences of consecutive zeros or consecutive ones of length n occur for any value n. Thus, for example, there exists a sequence of a trillion, trillion, trillion consecutive zeros in the binary expansion of π even though there is a statistically random distribution of 0's and 1's. If such a sequence occured near the beginning, the most non-mathematicans would assume non-randomness. 

As you have noted in your comments, our mathematics, no matter how abstract or remote, can be seen to be rooted in our real world experience. You mention string theory, which is rooted in geometry. Similarly, our theory of large cardinals is demonstrably remote (provably undecidable), but it is rooted in the act of counting. Surely reality includes aspects well beyond our ability to experience, just as it must surely be the case that mathematics includes provable truths which are beyond our ability to imagine or root in our human experience.