This should come close to what you wanted. 

4) In 1678, Gottfried Leibniz proposed lingua generalis. The basic idea was to assign every atomic property a prime number, and complex meanings are then computed as the arithmetic prodcut of these numbers. (Since prime numbers are chosen, any such product is uniquely identified by its atomic properties. However, this means that applying "reverse engineering" to identify the atomic factors boils down to integer factorization which is a rather complex mathematical operation and, as a consequence, not that well suited for practical applications...). I'm not sure, though, whether Leibniz actually computed such a list of atomic properties; I couldn't find any good reference online. 

In the original sense, "generative" doesn't mean that one is interested in generating particular instances of grammatical sentences of a certain language, or in how human language is generated "from neutral pathways towards the utterance". The OP already made a good insight by saying "Typical Chomskian approaches aren't generative in this sense [of "concentrated on production, not on understanding"] - they are very often based on grammaticality judgements". Rather, generative grammar wants to establish a grammatical theory that is able to account for any expression a language MAY generate, rather than just describing, without making any generalisations and predictive explanations, what is already there. It is the explanatory power and the aim to account for linguistic phenonemna univerally that is the essential characteristics of generative grammar, and not an aim to restrict yourself to a certain aspect of language. "Generative" does not neccessarily mean production-focussed. Generative theory wants to be - apart from being explanatory, this is one of the core goals - independent of purpose, it doesn't want to just provide a way to analyse how humans produce sentences, but establish a theoretical framework which has the explanatory power of generalising what is already there and predicting how language would behave in terms of grammaticality when certain parameters are set in this or in that way. Basing your theory on a generative view on language doesn't mean you must focus on production. Therefore, it is well possible to do research that isn't interested in production but rather in an analysis of existing structures, like typological research, with an approach of a theory that is motivated by the goal to be generative (a good linguistic theory, be it syntactic, semantic, phonological, ... should anyway be based on typologically widespread empirical research, so you actually do typological or historical research with generative theories in mind); basing your research on a generative theory doesn't mean you need to use it to produce sentences on your own or, even less, to account for how language is processed neurally or anything. 

If it's about connotation: A word receiving a more negative connotation is called pejoration. A word receiving a more positive connotation is called melioration. 

Does it become clear now? By stating syntactic rules as transformations, we can see recursion as returning to the rule that gave us the output from which we are calling the rule, and this is exactly the reason why it makes totally sense to derive the term from the latin root recursionem.