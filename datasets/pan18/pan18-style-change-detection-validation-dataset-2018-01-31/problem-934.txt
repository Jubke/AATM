In the case of "energy", we have very clear formulas that predict the effects of this occult cause, and the formulas work regardless of whether you believe in the cause or not. It doesn't matter if "energy" as a force actually exists, as long as it is adequate to the phenomena. Thus, oddly enough, we're left with basing our judgments upon the authority of others, and going with the study that comes from the source we judge to be most trustworthy. Which leads, of course, to the question of how we evaluate the qualifications of the authorities themselves-- which leads us back to the same list of epistemological warrants. 

In Nyāya (classical Indian) epistemology, there are recognized four types of epistemological warrants (Pramāṇa-s): 

However, this system of statistics is not the equivalent of baseball. To think so is confusing the map for the territory. 

To cut to the chase, Hume is canonical reference here, and you are quite correct that we only perceive effects, and not causes, and that there is no rigorous way for us to identify what we mean by a cause except circularly through reference to the effects. 

There are at least two extremes as to how one can define the scientific method. One is a process, one is more of a set of principles and a goal. The process is well defined as: In the end, I'd call his theory testable but not falsifiable. He makes the argument that he provides testable hypotheses that we will find more mathematical structures, but there's nothing in the theory which permits Popperian falsification. This puts it in a category alongside many Asian concepts such as Traditional Chinese Medicine, which permit testing but not falisification. Thus, his theory must find its use the same way TCM does. It gets picked up by people who feel their lives are improved by picking it up, but it is rejected by science because it does not conform to the strict rules science uses today. 

It strikes me as though the scientific method advocates use of falsifiable hypotheses except in the case of advocating the scientific method itself, but I cannot tell if that is because of how I interpret how one is expected to apply the scientific method, or if it is indeed intended to be treated as the exception that proves the rule. Finally, science tests its theories. This sounds absurd, because it seems so obvious that you should test them. However, a theory is not accepted at all until it is tested. The result is that anyone with a theory must expend the resources to do the testing before science will do anything with it. Other approaches get away with a different style: you use a theory once you have it, and you test it when you get an opportunity to do so. The tests can also be dangerous. (Edit: I had a reference to the LHC and potential to create black holes here, but it was too contentious. Instead, it has been replaced with a hypothetical example) Consider a hypothetical particle physics experiment. The scientist is rather confident that their theory is correct. They begin experimenting, after calculating that they would like 100 samples to do statistics on. Generally speaking, they are finding their theory holds out for test after test. However, on tests which disagree with their hypothesis (which happens in the scientific method due to noise), the observer notices a burst of energy from the test apparatus. That burst becomes stronger and more dangerous with every data point that disagrees with their hypothesis. At some point, the scientist decides to cut the experiment short, because they are uncomfortable putting their life at risk to finish the test. By the strictest reading of the scientific method, that data cannot be analyzed because it is tainted with the scientist's choice to cut the tests off early. This might induce biases because the scientist is more likely to cut them off faster if the results look good for their theory. Other methodologies are capable of using this data (including the intuition of that scientist, who will not try the exact same experiment again). 

But each discipline is actually made up of sub-disciplines, and each of those has definite periods of its own, where its relationship to the larger theories of its embracing discipline can be in a posture which is 'prescientific' (Whatever we are doing works, so it must fit with their work, but we don't really care how the two harmonize, because we are happy for now), 'revolutionary' (Their theories challenge our groundwork, and we create a succession of bridges to or walls around our work) or 'normal' (We leave off developing our own internal theories and solve specific gaps between our sub-domain and the larger theory). 

It is very hard to really tell these two apart in practice, and Kuhn's theory is layered upon that of his mentor, so they also do not really conflict obviously. Kuhn, in his successive publications, keeps alternately emphasizing this ultimate lack of conflict, and pointing out how much more he favors his own ideas, which, in the end, does not improve our clarity. But the notion of paradigm does seem, to many, to fit the pattern of historical periods of peace and strife within a discipline, as periods where paradigms had been chosen and times when they were in contention with one another. 

Outside the philosophy of science, there are, as Alexander points out more than can be easily named. Time is more of a question in general. But it is clear to me. Memory is achieved via an exothermic chemical process. So if time moved backward, in the sense that entropy locally decreased in a fine-grained and uniform way, we could never remember it. 

If mathematical constructs must be derived to make sense of a theory, that material is a priori. The scientific theory itself then is a posteriori, in that it will deploy the mathematical mechanics against actual observations. The theory might fail, end yet the math might live on and find a different application entirely.