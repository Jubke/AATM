In asking whether ∀x∈∅.P(x)⇒Q(y) is true for some y, we ask whether there is any value of x for which the constraint may be violated. There is not: and this is not because ∀x∈∅.¬P(x) per se (though this is also true), but simply because there are no values of x, and thus none for which P(x) is true. Now this is only one way to argue against Lucas' position. There are others, possibly more powerful, which we shall present later. But this counterargument has special interest because it brings up the fascinating concept trying to create a computer program which can get outside of itself, see itself completely from the outside, and apply the Gödel zapping-trick to itself. Of course this is just as impossible as for a record player to be able to play records which would cause it to break. But-one should not consider [number theory] defective for that reason. If there a defect anywhere, it is not in [number theory], but in our expectations of what it should he able to do. Furthermore, it is helpful to realize that we are equally vulnerable to the word trick which Gödel transplanted into mathematical formalisms [...] It is still of great interest to ponder whether we humans ever can jump out of ourselves [...] One can step out of ruts on occasion. This is still due to the interaction of various subsystems of one’s brain, but it can feel very much like stepping entirely out of oneself. Similarly, it is entirely conceivable that a partial ability to "step outside of itself" could be embodied in a computer program. Causality & Locality — the principle that the world is intelligible in terms of a network of causes and effects; and subsequent to Einstein's qualitative contemplation of the relativity of simultaneity, the principle that causal influences can only be due to spatio-temporally nearby objects, i.e. that despite the success of Newton's theory of gravity, his critics were right to intuit that spatial mediation/separation of interactions are significant. Contingency apart from axioms Consider for example random graph theory. In their seminal paper on the subject Paul Erdős and Alfred Rényi (Erdős+Rényi 1960, "On the evolution of random graphs") consider a process where one connects n abstract 'points' or 'vertices' in pairs by edges, selecting up to some number N of pairs to connect, uniformly at random and in a random order. The description of "what is going on" is presented in highly suggestive time-dependent language. (The very idea of the fact that there is something which is "going on", as opposed to just simply being statically the case, is already a hint of this.) The word 'evolution' in the title is meant literally, for example: they speak of the graph changing with time, of connected components "melting" into one another, and so forth. The Halting Problem indicates that clever reasoning, using an understanding of the big picture and insight into the structure of a logical situation, some times is not enough. There is an infinite hierarchy of logical problems having subtler and subtler structure, receding to a horizon of problems which can scarcely be said to have structure at all; and so to resolve those problems, there exist no time-saving techniques — to find the answers, there is no recourse but brute force computation.