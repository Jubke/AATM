We could reverse engineer your problem: How did language evolve? Before there was writing, language was a series of sounds. High order animals that clearly display some level of thinking also tend to communicate with sounds (Dogs, apes, dolphins and whales, etc...). Chances are their thought processes involves a bunch of sounds in their head as well. Not as precise as humans, but still precise enough that scientists now consider Orcas to have distinct cultures. 

Douglas Hofstadter, in his book "I am a strange loop", has a section (or chapter) I forget, called "On souls and their sizes". In it he posits that, there isn't a specific break between animals and humans, but that instead there is a gradual increase in complexity of their abilities of self perception. The complexity of thoughts possible also followed a similar gradient. Presumably the animals would perceive themselves using the same types of symbols they perceive the world with, so that is how their thoughts are structured. Animals with an advanced sense of smell might associate smells with their mental images instead of sounds for example. 

As far as critical interpretations, note that Slavoj Zizek talks about this movie a bit here and there. I'll begin with a few general remarks. I might suggest one way to look at this is to think about language. In order to become a fluent speaker in the language, you really need to be immersed. Why? Because just knowing the rules themselves really doesn't tell you as much as you might think. 

the fraction of human-level civilizations that reach a posthuman stage is very close to zero; the fraction of posthuman civilizations that are interested in running ancestor-simulations is very close to zero; or the fraction of all people with our kind of experiences that are living in a simulation is very close to one Ockham's Razor would initially indeed seem to suggest that the simulation hypothesis 'requires less assumptions'; however given the degree of unknowability here it would seem as difficult to assert this unqualifiedly as it is to imagine a scientific experiment which could validate the principle. In my opinion it's at least apparently unfalsifiable, though as I have suggested above, hypothetically we might run into certain limits imposed by the simulator on the simulation. A typical example is a Henkin style completeness proof for first order predicate logic. We are talking about formulas and deductions that we "can" write down, so we can be pretty certain that we can write down things. We use this certainty to construct a syntactical model of the axioms. (The consistency of the axioms enters by the "non-collapse" of the constructed model.) One point of contention is how much ontological commitment is really there. Just because I can write down some things doesn't mean that I can write down an arbitrarily huge amount of things. Or maybe I can write them down, but I thereby might destroy things I wrote down earlier. Even so I only read that paper in order to be entitled to answer this question, I think the paper is really worth reading even if you don't want to answer any question. It's easy to read, covers much ground, and even sketches the proofs for some non-obvious theorems. But is it relevant to philosophy? Well, it is an honest attempt to address an audience of philosophers and tries to reduce (or show how it might be possible to reduce) the gap between theory and reality in certain areas.