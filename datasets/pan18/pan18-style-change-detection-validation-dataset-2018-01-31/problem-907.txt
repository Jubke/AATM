In Hartry Field's Saving Truth from Paradox (2009), he splits the resolution of the Liar paradox into two broadly distinct strategies. Either we can accept Classical logic, but need to restrict the class of propositions over which Truth can meaningfully operate, or we can weaken logical inference to block either the deduction of a contradiction from the Liar proposition or, accepting the existence of a contradiction, to deny the principle of Explosion - that whenever we have a contradiction, we can infer anything we like from it. 

Being the case is not a property of propositions, but a property of some aspect of the world that we take the proposition to describe. By contrast, Truth is a property of statements or propositions. It says, of a proposition, that the terms of that proposition in the appropriate relations amount to a correct description of something that is the case. On Russell's view, we might say that Truth is described in terms of language that corresponds to what is the case. Where our talk of something being the case is used to make assertions about the world, our talk of something being true is used to make assertions about other assertions, whether by us or by others. 

David Hume, in his discussions about causality, shared your sense of skepticism that there might be anything other than mere observed regularities to our discussions of natural "laws". His philosophy looks at ways in which our cognitive senses of pattern recognition or resemblance hang together in perceiving and evaluating hypothetical instances of causation - in some sense, "laws" of nature are just consequences of how we are psychologically compelled to evaluate our evidence into a structured and coherent picture of things. 

Supposing the arguments were asymmetrical and the one form is indeed stronger than the other, we should be able to formalise them: 

You can use a parse tree for this. First you draw the parse tree, then you draw boxes around subtrees. 

But also think of bitmasks and other uses of logic in computing science. 

It's somewhat peculiar that that textbook talks about validity without first defining it. It's a pretty straightforward definition, but usually these books are very precise. 

Since "the stronger the restriction, the narrower the class", Y will be smaller when P is stronger. And since N = X ∖ Y, this means that N will be greater, therefore, ¬P will be weaker. A similar argument can be made when P gets weaker: Y will be greater, so N smaller, therefore, ¬P will be stronger. 

There is an 'interpretation' possible in which snow does not melt during the day in the Sahara / a human lives without oxygen / photons have no mass. That is because these statements can only be verified with a posteriori knowledge. 

Note for example that ∀y ∀x (x ∈ y ∨ y ∈ x) is equivalent to a subformula (namely the whole formula), but not a subformula itself, because it doesn't exist in the parse tree. You need to modify the structure to get to that form. 

And you see that you were correct. 

There are really so many way to do this and which one you choose largely depends on your personal preference. Here are some: 

I'm helping in a computing science course about basic math, and last week someone asked me: 

Both arguments are equally unsound and weak. However, using other evidence (for example that nobody has ever seen a unicorn), we can say something about the probability of Alice's and Joe's conclusions: given the evidence that nobody has ever seen a unicorn, it is likelier that Joe is right than that Alice is right. This does not say anything about the weakness of their arguments though, only about the truth of their conclusions. 

Some of the "16 possible compound statements" are in fact trivial cases (and also the ¬ appears twice). Actually, only five of the sixteen cannot be made with one of the standard five operators. See the following table: 

E: Now that we do have the specifics of the system, you could do it like this: 

So in Classical Propositional Logic, rather than having to go through and manually specify values for every single formula, you can instead require that the interpretations assign values to all of the basic formulae (the Atomic propositions) and build up values for more complex sentences inductively. This structure means you can have a theory of deductive inference that "gets things right" on the level of interpreting sentences in line with their mathematical relationships. 

We might think that in order to rise to your challenge, a restriction strategy is of no use, since you want to be able to represent and robustly process the Liar proposition. If that's what we think, then a non-classical logic is essential. 

I'd also like to point out that the system you're working with as presented is radically unstable. 

(You'll also sometimes see that symbol used in the form "PREMISES |= conclusion"; this is shorthand for the Semantic Entailment relation: "all models that make PREMISES true also make conclusion true") 

Tarski's Convention T is not strictly speaking a definition principle for truth - it is an evaluation condition on whether a given axiomatically theorised predicate is a "Materially Adequate" definition to count as a Truth predicate. 

But to try to suggest that Deflationism is at least not trivial, consider firstly that we can make generalized assertions about propositions whose content we don't necessarily know ourselves: 

Truth is exactly the ideal of asserting, and theories of truth are thus supposed to be theories that capture these norms. As such, the semantics of Truth are given in the norms of assertion, rather than in the ontological structure of the world. (In Maths, for instance, the semantics of our language is determined by what you can prove, and the proofs you can construct, rather than the objects out there in the world)