Assuming that any such foundational theory T is such an effectively generated formal system, i.e an axiomatic theory expressive enough to develop basic properties of the natural numbers, T cannot prove its own consistency. Thus is it logically possible that it is inconsistent. 

That ZFC became a pure first-order theory is due to David Hilbert's early work on a subsystem of logic which he called restricted functional calculus (effectively today's first-order logic) and Thoralf Skolem, who in 1923 gave the original first-order axiomatization of Zermelo set theory. Axiomatic set theory effectively became a dominant first-order theory in the mid 30s and is first-order up to this day. The majority of set theorists like the properties of first-order logic (completeness, compactness, etc.) a lot. The fact that first-order set theory deviates from mathematical practice is actually seen as a feature, not as a bug. 

3. The emergence of FOL It is not a coincidence, I think, that it was in this metatheoretical setting, and in the Schröder-Hilbert-Zermelo tradition, that logic was put on the operating table to be dissected, so to speak. It was a direct consequence of the need to investigate metalogically the properties (soundness, completeness, compactness, consistency, categoricity etc.) of various logical fragments: In 1918 Bernays gave the first rigorous proof of completeness of such a subsystem of logic, i.e. propositional logic. Another fragment turned out to be what we now call FOL. Specifically, it was first developed in 1917 under the name restricted functional calculus by Hilbert as a subsystem of his functional calculus (effectively a ramified type theory), but was only published in the classic textbook coauthored with Ackermann Grundzüge der theoretischen Logik in 1928, where it was still treated as a subsystem. Maybe I have to write an answer myself. But this is not really an answer, it is more the background which caused me to ask this question. But it answers some of the objections brought up in comments, even if it could and should be probably elaborated much more thoroughly. (Sorry for misusing the "community answer" feature in that way.) There is good evidence that we can avoid partially undefined operations in most practically relevant cases, if we are willing to cope with infinity. But what about the opposite? Can we avoid infinity in most practically relevant cases, if we are willing to cope with partially undefined operations? There were at least three different idealistic positions regarding the existence of mathematical objects: Both infinity and undefined operations have much more mundane applications where they make life significantly easier. If we adjoin the points at infinity to an affine space, we get a projective space with much nicer properties than the corresponding affine space. But if we adjoin infinity to the possible values of a norm, we don't really do ourself a favor. If we instead allow a norm to be only partially defined, we seem to really get something nice in return, similar to the projective spaces, but of course different. The poorest current "loser" from the fear against partially (un)defined operations are probably inverse semigroups, and semilattices are a special case of inverse semigroups (i.e. idempotent and commutative). 

In this case, I think you could fill in the missing premise with your premise 5: "Since women have as much right to self-esteem as men, women should earn as money as men." and you would create a more complete argument. However, since the book isn't actually asking for the missing premise (they're just using it to help explain what's going on), they chose a simpler premise. It also presumes that an explanation one's actions has to be necessary and sufficient, rather than merely a way to convey information. 

Mendel then does the experiment, analyses the results, determines that H0 can be rejected because it's just too statistically unlikely that the results had anything but a 3:1 ratio. 

Now he goes about "falsifying" Pp, by demonstrating that his new [conflicting] theory, P1, fits the data cleanly while Pp looks less reasonable because it is a poor match to the data. To "prove" P1 using the scientific method, he uses one final proposition, the null-hypothesis, P0: "Pea plant crossings do not operate near a 3:1 ratio with a random variance around that point." If the data from his upcomming rejects this P0, then the only valid theory remaining is P1.