From your perspective it should significantly decrease amount of effort you invest into estimation, as you're just going to assign every new feature to one of general sizes instead of busily estimating story points for each of them. What more, in retrospect you can either choose to assign time spent on feature and its refinements separately or jointly. I would probably go with the latter as it means you're going to estimate how much time you need to finally get a feature ready to release instead of getting the first version of a feature which is going to be adjusted several times. Anyway the choice is yours here. 

For some basic ideas on estimation I strongly recommend Steve McConnell's Software Estimation: Demystifying the Black Art For understanding how estimation based on historical data works I recommend Joel Spolsky's article on Evidence Based Scheduling. Although I don't propose to apply the concept directly it will help you to understand why and how it can improve the quality of your estimates. Deciding what gets, what can get and what doesn't get into a release is pretty popular concept and is covered for example in Mike Cohn's book Agile Estimating and Planning, which by the way you probably know. Variability of work and how it influences planning is pretty well described in David Anderson's Kanban: Successful Evolutionary Change for Your Technology Business. Note however that the main goal of the book is introducing Kanban and not discussing variability. Nevertheless the book is worth recommending anyway as it can help you with other areas of organizing software development as well. I described a bit similar approach I used in my team in a post on Coarse-Grained Estimation. A related topic was standardizing feature size which you may or may not find useful or even feasible in your case. 

UPDATE: Sources/further reading: Another, different approach would be to measure just a coarse-grained size of features and then track down how much time you've spent on a feature in reality. For example, you can start with T-shirt size estimation (S, M, L, XL, etc) and then look how much of variability there is in real effort invested into building these features. (see 2 and 4 in sources) Another problem is accounting all the time spent on task during later stages, e.g. bug-fixing, to the original task. It is tricky as you think not only about regular tests but also about issues you get from production etc. Eventually, we ended up having another task, one per feature, dedicated purely for testing. Its original estimate was 0 and real time was whatever was spent on unplanned tasks, such as bug-fixing. Theoretically it suited the model, although it wasn't really telling you anything about the quality of someone's estimating skills. 

We were splitting our stories, and later features, to so-called development tasks. For each of such tasks we were making estimates in real hours, meaning that we were trying to take into account all the time spent on distracters, context-switching, etc. Then, when a task was finished we were writing down the real time spent on it. Now, whenever we needed to estimate something in detail we could do WBS make our estimates and, basing on historical data, do Monte Carlo analysis (in Excel sheet) and come up with a result. 

On the other hand I could get pretty decent coarse-grained estimates using more generic data (read more about the approach). Also I realized that most of the time I didn't need such exact estimates as I could get using Evidence Based Scheduling, thus we mostly abandoned the method.