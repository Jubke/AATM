The primary professional ethics issues faced by recruiting officers are first dealing with legal issues of the applicants, second, not providing false information, and third not offering false inducements (or threats) to potential applicants, c.f. section 2 of these policies. The last two are similar to other "sales" types of positions, albeit with larger stakes. An example of an ethical failure of this type was an officer in 2005 promising the potential recruit that he/she would not be sent into a combat zone (Iraq) -- a promise that the recruiter could not ensure. 

That these core values of science affect how results are conveyed and interpreted is a more subtle point, and can be described in a way that makes this interaction less interesting than the theory-ladenness of science. In considering theory ladenness it is relatively easy to come up with counterfactuals: e.g. without special relativity, measuring masses in GeV/c^2 doesn't make sense. Trying to construct the same kind of counterfactuals where the essential values of science are violated leads to situations where you are not dealing with science. Public policy research institutes, which adhere to a different set of values, produce research papers that include specific objective facts, but are not doing science. As I currently understand it, some segments of the biomedical research community have stopped doing (or failed to do) science, since the cherry picking of positive outcomes amounts to incomplete reporting of their results. The point is these core values are, for some contexts, less interesting because they are just part of the background that comes into play when discussing science at all. 

This BBC presentation is a great intro to the book: https://www.youtube.com/watch?v=R9IM3ZKNMCk 

Now, Anton Chigurh is a guy of excellence but ignorant of (Aristotelian) human essence, and subsequently the good. His ignorance is assumed to be not his fault. Since Chigurh is epistemically incapable, it seems to me that Aristotle must say that Chigurh cannot be morally responsible for his actions. 

John Stuart Mill's On Liberty is composed to address your question, when and when not to interfere the liberty of others, as an individual and as a society as a whole. 

The second response is an egalitarian response, suggested by John Rawls. Rawls worries that a system of absolute equality would lead to stagnancy in economic growth and breeds inefficiency, and thus needed is the Adam Smithian market, where self-interested, talented indiviiduals freely carry out their personal projects and their entrepreneur ambitions, and are handsomely rewarded for their efforts. This incentive structure of the market, however has the effect of widening economic inequality among people. Rawls aims to strike a balance between equality and efficiency with his difference principle: the difference in wealth among people are morally justified as long as the poor benefit when the talented make money (when a rising tide lifts especially the poor boats). The wealth tax allows the govt to realize the just goal of egalitarianism, and thus the tax is moral. 

Lying is generally considered unethical. Falsely entering into a contract is a form of lying. The Terms of Service for the Stack Exchange sites indicate that accepting the terms indicates that the subscriber is "an individual". The rest of the contract makes clear that the intention is that the subscriber is a (human) person. A bot would be unable to live up to this aspect of the terms of service. 

given that U.S. recruiting officers have made this oath themselves (since they're members of the military), the recruiting officers have an ethical obligation to perform their duties as ordered; this obligation is both personal and civic in nature. Similar oaths are used for declaring citizenship and various official government positions in the United States (might be relevant for sub-question 2); I assume that similar binding oaths are used in similar circumstances in other nations as well. 

This answer is somewhat unsatisfying due to the nature of the question, which is, "if you have these non-moral obligations, to what extent are you morally obligated to uphold them?", which has an obvious answer. 

Edit to add another (better?) phrasing 

Who has explicitly addressed the problem as to when to decide to allow for a specific ethical theory to deviate from common-sense moral intuitions? 

I tend to interpret Quine's conclusion in terms of the readers' side of things: in order to interpret even the most basic, small facet of a scientific result, you need to impose a big background of theory. For an obvious example, take the report that the Higgs Boson has a mass of XXX +/- YYY GeV/c^2; huge amounts of background knowledge are required to even make sense of this one reported number. Even something as basic as "we measured the thickness to be ZZZ mm with calipers" implies a theory that the thickness of the whatever (as opposed to say, its surface roughness) is the salient factor in this context. Similar considerations affect the practitioners' reporting: they can't provide all of the background information so they need to assume (usually implicitly) that the reader will interpret their results in the light of a commonly held theory. This then pushes back into what practitioners actually do: if I can't sensibly communicate it within the theoretical constructs of my scientific community, then it's not worth doing (or if I do it, I'll end up being outside my scientific community).