What makes Korean so special is that it has a third kind of consonant, transcribed typically as pp, which is termed 'fortis; tense; glottal; geminate' – all of these seem to be appropriate descriptions of the facts. These 'tense' consonants have an even lower VOT, which is the element missing for claiming that there are "degrees of aspiration:. However, the 'tense' consonants also have some kind of glottalization associated with them, at least for older speakers. It is possible that some time in the future, the p, pp, ph contrast will develop into a three-way difference in aspiration alone, but at present, there are enough other differences associated with these consonants that we can legitimately treat the system as having two orthogonal two-way differences (aspiration versus glottalization). Unfortunately, no. There are two impediments to such a program. First, there isn't a sufficient database of individual sound recordings. You might cobble together collections of certain common sounds from various resources, for example words containing /a/ or /ɑ/ or /æ/, but it is usually very hard to find recordings of a given putative sound with multiple speakers of a language. Finding multiple speakers for a language is important, because you have to be able to distinguish between peculiarities of a single speaker vs. peculiarities of a language. Taking three speakers to be the minimum sample necessary for making a somewhat credible claim about a single language, note that we still do not know truly language-dependent (as opposed to speaker-dependent) facts of VOT for the languages reported in Lisker & Abramson's classic work on VOT. Now, looking at Cho & Ladefoged 1999 which looks at VOT in a number of languages (all endangered, in a nice twist), they got data from a reasonable number of speakers of each language, and you can see that VOT for the aspirated / unaspirated contrast differs quite substantially across the languages that they sampled. In one way of looking at it, English could provide another example of three-way aspiration differences (though not contrasts). It is well-known that aspiration of voiceless stops is governed by a rule where they are aspirated in foot-initial position and not aspirated elsewhere. This is often treated as a phonological (categorial) allophonic process. However, it has also been observed that for many speakers, the contrast between "g" and "k" does not involve voicing, it involves aspiration ("g" is really unaspirated [k] and "k" is aspirated [kʰ]). Putting these two facts together, one can say that phonetically we have three aspirations states: unaspirated ("g"), lightly aspirated ("k" not in foot-initial position), and more-aspirated ("k" foot-initially as in "cap") Pitch is the perceptual correlate of fundamental frequency. The fundamental frequency of a semi-periodic waveform is the frequency with which the vocal folds vibrate, e.g. 150 times per second. The rate of vibration of the vocal folds is not determined by the degree of constriction in the vocal tract, until the constriction becomes so significant that air-flow is blocked and the vocal folds cease vibrating entirely. The linked description isn't a conventionalized and general method with a name, it's a description of how an individual (may have) learned to pronounce [r]. The magic step is "I somehow tried to hold the [ɾ] instead of immediately lowering my tongue". There may be individual descriptions of what people think they did physiologically to learn to pronounce novel sounds, but generally speaking, such descriptions are not a lot of help and are often just wrong. You need a native speaker with a bit of patience and a good ear: that is how I learned the exotic sounds of Lushootseed. Note that there is not just one phonetic type of [ɾ] and one phonetic type of [r], so if you want to master the trilled [r] of Finnish, you need a speaker or at least recordings of Finnish. If you go to Forvo, you can get over a half million pronunciations of German words. There is a difference between er and e at the end of the word, where final er may be [ɐ]. I don't know of a way to efficiently assemble all of the relevant words, but this is a resource for potentially hearing examples (I'd generally suggest listening to anything with final r). It might be best to pick a single speaker and listen to their pronunciations. Sometimes speakers differ, and you can pick a speaker who has the pronunciation of interest like the first one, and see what similar words there are. Some words are attested with multiple recordings. The basic dichotomy between Ohala and Chomsky & Halle is that for Ohala, everything is historical change, and for Chomsky & Halle, everything is synchronic grammar. It is a somewhat open question how "deeply" a syllabic / non-syllabic distinction is needed. There has always been a strong urge to get rid of the distinction, because most of the time you can predict where things are syllabic. In fact, if you also have syllables (which we don't always have), then you can always predict syllabicity. Problematic cases like the Swahili minimal pair mbuni "ostrich", m̩buni "coffee tree" become non-problematic if you include syllable structure – mbu.ni vs m̩.bu.ni. As it happens, the distinction in Swahili is more superficial and there is no need to admit an underlying contrast in syllabicity types for nasals – it can be predicted, once you have the rule system sorted out. For theories that posit moraicity as the bearer of the concept "syllabic", there isn't much hope of predicting "syllabicness" because moraicity is a fairly fundamental phonemic property (since it is also how you express long versus short). Addressing the question in the title, the answer is no, because no single language has all phones. The question is somewhat ill-conceived, being framed in terms of "phones", since a "phone" is a concrete sound (it would be way too involved to properly explain what a "phone" is). The IPA does not have separate symbols representing the phonetically distinct vowels transcribed for instance [a] in all languages. Thus there is no single language sound corresponding to IPA [i], instead, very many similar sounds are subsumed under the transcriptional symbol [i]. Articulatory explanations of how to pronounce particular sounds are generally of only ancillary utility: what you need is cleanly-recorded models that you can imitate.