{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifikation von Texten mit geteilter Autorenschaft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Inhaltsverzeichnis<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Abstract\" data-toc-modified-id=\"Abstract-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Abstract</a></span></li><li><span><a href=\"#Einführung\" data-toc-modified-id=\"Einführung-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Einführung</a></span><ul class=\"toc-item\"><li><span><a href=\"#Motivation\" data-toc-modified-id=\"Motivation-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Motivation</a></span></li><li><span><a href=\"#Problemstellung\" data-toc-modified-id=\"Problemstellung-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Problemstellung</a></span></li><li><span><a href=\"#Vorgehen\" data-toc-modified-id=\"Vorgehen-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Vorgehen</a></span></li><li><span><a href=\"#Related-Research\" data-toc-modified-id=\"Related-Research-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Related Research</a></span></li><li><span><a href=\"#Theorie\" data-toc-modified-id=\"Theorie-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Theorie</a></span><ul class=\"toc-item\"><li><span><a href=\"#Features\" data-toc-modified-id=\"Features-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Features</a></span></li></ul></li><li><span><a href=\"#Notebook-Vorbereitung\" data-toc-modified-id=\"Notebook-Vorbereitung-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Notebook Vorbereitung</a></span><ul class=\"toc-item\"><li><span><a href=\"#Laden-eigener-Module\" data-toc-modified-id=\"Laden-eigener-Module-2.6.1\"><span class=\"toc-item-num\">2.6.1&nbsp;&nbsp;</span>Laden eigener Module</a></span></li><li><span><a href=\"#Laden-von-externen-Bibliotheken\" data-toc-modified-id=\"Laden-von-externen-Bibliotheken-2.6.2\"><span class=\"toc-item-num\">2.6.2&nbsp;&nbsp;</span>Laden von externen Bibliotheken</a></span></li><li><span><a href=\"#Globale-Intialisierungen\" data-toc-modified-id=\"Globale-Intialisierungen-2.6.3\"><span class=\"toc-item-num\">2.6.3&nbsp;&nbsp;</span>Globale Intialisierungen</a></span></li></ul></li></ul></li><li><span><a href=\"#Verwendete-Datensätze\" data-toc-modified-id=\"Verwendete-Datensätze-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Verwendete Datensätze</a></span><ul class=\"toc-item\"><li><span><a href=\"#CMU-Book-Summary-Datensatz\" data-toc-modified-id=\"CMU-Book-Summary-Datensatz-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>CMU Book Summary Datensatz</a></span></li><li><span><a href=\"#Konstruktion-von-gelabelten-Daten\" data-toc-modified-id=\"Konstruktion-von-gelabelten-Daten-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Konstruktion von gelabelten Daten</a></span><ul class=\"toc-item\"><li><span><a href=\"#Kombinatorische-Variablen\" data-toc-modified-id=\"Kombinatorische-Variablen-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Kombinatorische Variablen</a></span></li><li><span><a href=\"#Ähnlichkeitsmaß\" data-toc-modified-id=\"Ähnlichkeitsmaß-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Ähnlichkeitsmaß</a></span></li><li><span><a href=\"#Konstruktion-von-Datensätzen\" data-toc-modified-id=\"Konstruktion-von-Datensätzen-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Konstruktion von Datensätzen</a></span><ul class=\"toc-item\"><li><span><a href=\"#Book-Summary-1\" data-toc-modified-id=\"Book-Summary-1-3.2.3.1\"><span class=\"toc-item-num\">3.2.3.1&nbsp;&nbsp;</span>Book Summary 1</a></span></li><li><span><a href=\"#Book-Summary-2\" data-toc-modified-id=\"Book-Summary-2-3.2.3.2\"><span class=\"toc-item-num\">3.2.3.2&nbsp;&nbsp;</span>Book Summary 2</a></span></li></ul></li></ul></li><li><span><a href=\"#Alternativer-Datensatz-zur-Verifikation-der-verwendeten-Ansätze\" data-toc-modified-id=\"Alternativer-Datensatz-zur-Verifikation-der-verwendeten-Ansätze-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Alternativer Datensatz zur Verifikation der verwendeten Ansätze</a></span></li></ul></li><li><span><a href=\"#Text-Repräsentation\" data-toc-modified-id=\"Text-Repräsentation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Text Repräsentation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Feature-Auswahl\" data-toc-modified-id=\"Feature-Auswahl-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Feature Auswahl</a></span><ul class=\"toc-item\"><li><span><a href=\"#Konfiguration\" data-toc-modified-id=\"Konfiguration-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Konfiguration</a></span></li><li><span><a href=\"#Durchführung\" data-toc-modified-id=\"Durchführung-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Durchführung</a></span></li></ul></li><li><span><a href=\"#Feature-Berechnung\" data-toc-modified-id=\"Feature-Berechnung-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Feature Berechnung</a></span></li></ul></li><li><span><a href=\"#Identifikation-von-Texten-mit-geteilter-Autorenschaft\" data-toc-modified-id=\"Identifikation-von-Texten-mit-geteilter-Autorenschaft-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Identifikation von Texten mit geteilter Autorenschaft</a></span><ul class=\"toc-item\"><li><span><a href=\"#Verwendete-Evaluations-Metrik\" data-toc-modified-id=\"Verwendete-Evaluations-Metrik-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Verwendete Evaluations-Metrik</a></span></li><li><span><a href=\"#Baseline\" data-toc-modified-id=\"Baseline-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Baseline</a></span></li><li><span><a href=\"#Ansatz-1:-Bi-direktionale-LSTM-Netze-basierend-auf-lexikalischen-und-syntaktischen-Merkmalen\" data-toc-modified-id=\"Ansatz-1:-Bi-direktionale-LSTM-Netze-basierend-auf-lexikalischen-und-syntaktischen-Merkmalen-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Ansatz 1: Bi-direktionale LSTM Netze basierend auf lexikalischen und syntaktischen Merkmalen</a></span><ul class=\"toc-item\"><li><span><a href=\"#Segmentierung-von-Texten\" data-toc-modified-id=\"Segmentierung-von-Texten-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>Segmentierung von Texten</a></span></li><li><span><a href=\"#Aufbau-des-Modells\" data-toc-modified-id=\"Aufbau-des-Modells-5.3.2\"><span class=\"toc-item-num\">5.3.2&nbsp;&nbsp;</span>Aufbau des Modells</a></span></li><li><span><a href=\"#Training-mit-dem-Book-Summary-2-Datensatz\" data-toc-modified-id=\"Training-mit-dem-Book-Summary-2-Datensatz-5.3.3\"><span class=\"toc-item-num\">5.3.3&nbsp;&nbsp;</span>Training mit dem Book Summary 2 Datensatz</a></span></li><li><span><a href=\"#Training-mit-dem-PAN-Datensatz\" data-toc-modified-id=\"Training-mit-dem-PAN-Datensatz-5.3.4\"><span class=\"toc-item-num\">5.3.4&nbsp;&nbsp;</span>Training mit dem PAN Datensatz</a></span></li><li><span><a href=\"#Evaluation-der-trainierten-Modelle\" data-toc-modified-id=\"Evaluation-der-trainierten-Modelle-5.3.5\"><span class=\"toc-item-num\">5.3.5&nbsp;&nbsp;</span>Evaluation der trainierten Modelle</a></span></li></ul></li><li><span><a href=\"#Ansatz-2:-Parallele-LSTM-Netze-zum-Vergleich-temporal-gegensätzlicher-Stilentwicklungen\" data-toc-modified-id=\"Ansatz-2:-Parallele-LSTM-Netze-zum-Vergleich-temporal-gegensätzlicher-Stilentwicklungen-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Ansatz 2: Parallele LSTM Netze zum Vergleich temporal gegensätzlicher Stilentwicklungen</a></span><ul class=\"toc-item\"><li><span><a href=\"#Segmentierung-von-Texten\" data-toc-modified-id=\"Segmentierung-von-Texten-5.4.1\"><span class=\"toc-item-num\">5.4.1&nbsp;&nbsp;</span>Segmentierung von Texten</a></span></li><li><span><a href=\"#Aufbau-des-Modells\" data-toc-modified-id=\"Aufbau-des-Modells-5.4.2\"><span class=\"toc-item-num\">5.4.2&nbsp;&nbsp;</span>Aufbau des Modells</a></span></li><li><span><a href=\"#Training-auf-dem-Book-Summary-2-Datensatz\" data-toc-modified-id=\"Training-auf-dem-Book-Summary-2-Datensatz-5.4.3\"><span class=\"toc-item-num\">5.4.3&nbsp;&nbsp;</span>Training auf dem Book Summary 2 Datensatz</a></span></li><li><span><a href=\"#Training-auf-dem-PAN-Datensatz\" data-toc-modified-id=\"Training-auf-dem-PAN-Datensatz-5.4.4\"><span class=\"toc-item-num\">5.4.4&nbsp;&nbsp;</span>Training auf dem PAN Datensatz</a></span></li><li><span><a href=\"#Evaluierung-der-trainierten-Modelle\" data-toc-modified-id=\"Evaluierung-der-trainierten-Modelle-5.4.5\"><span class=\"toc-item-num\">5.4.5&nbsp;&nbsp;</span>Evaluierung der trainierten Modelle</a></span></li></ul></li><li><span><a href=\"#Ansatz-3:-Worteinbettung\" data-toc-modified-id=\"Ansatz-3:-Worteinbettung-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Ansatz 3: Worteinbettung</a></span><ul class=\"toc-item\"><li><span><a href=\"#Laden-der-Datensätze\" data-toc-modified-id=\"Laden-der-Datensätze-5.5.1\"><span class=\"toc-item-num\">5.5.1&nbsp;&nbsp;</span>Laden der Datensätze</a></span></li><li><span><a href=\"#LSTM-auf-Basis-von-Worteinbettungen\" data-toc-modified-id=\"LSTM-auf-Basis-von-Worteinbettungen-5.5.2\"><span class=\"toc-item-num\">5.5.2&nbsp;&nbsp;</span>LSTM auf Basis von Worteinbettungen</a></span></li><li><span><a href=\"#Bidirektionales-LSTM-auf-Basis-von-Worteinbettungen\" data-toc-modified-id=\"Bidirektionales-LSTM-auf-Basis-von-Worteinbettungen-5.5.3\"><span class=\"toc-item-num\">5.5.3&nbsp;&nbsp;</span>Bidirektionales LSTM auf Basis von Worteinbettungen</a></span></li><li><span><a href=\"#1-dimensionales-CNN-auf-Baisis-von-Worteinbettungen\" data-toc-modified-id=\"1-dimensionales-CNN-auf-Baisis-von-Worteinbettungen-5.5.4\"><span class=\"toc-item-num\">5.5.4&nbsp;&nbsp;</span>1-dimensionales CNN auf Baisis von Worteinbettungen</a></span></li><li><span><a href=\"#CNN-in-Kombination-mit-LSTM-auf-Basis-von-Worteinbettungen\" data-toc-modified-id=\"CNN-in-Kombination-mit-LSTM-auf-Basis-von-Worteinbettungen-5.5.5\"><span class=\"toc-item-num\">5.5.5&nbsp;&nbsp;</span>CNN in Kombination mit LSTM auf Basis von Worteinbettungen</a></span></li><li><span><a href=\"#CNN-in-Kombination-mit-LSTM-auf-Basis-von-vortrainierten-Worteinbettungen\" data-toc-modified-id=\"CNN-in-Kombination-mit-LSTM-auf-Basis-von-vortrainierten-Worteinbettungen-5.5.6\"><span class=\"toc-item-num\">5.5.6&nbsp;&nbsp;</span>CNN in Kombination mit LSTM auf Basis von vortrainierten Worteinbettungen</a></span></li><li><span><a href=\"#CNN-in-Kombination-mit-LSTM-trainiert-auf-dem-PAN-Datensatz\" data-toc-modified-id=\"CNN-in-Kombination-mit-LSTM-trainiert-auf-dem-PAN-Datensatz-5.5.7\"><span class=\"toc-item-num\">5.5.7&nbsp;&nbsp;</span>CNN in Kombination mit LSTM trainiert auf dem PAN-Datensatz</a></span></li></ul></li></ul></li><li><span><a href=\"#Comparison\" data-toc-modified-id=\"Comparison-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Comparison</a></span></li><li><span><a href=\"#Fazit\" data-toc-modified-id=\"Fazit-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Fazit</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einführung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Zahl der verfügbaren Textdaten wächst exponentiell an und ein immer größerer Anteil der Bevölkerung nutzt die im Internet angebotenen Texte als primäre Informationsquelle. Die dort veröffentlichten Zeitungsartikel, Magazine, Bücher, Internetseiten und Posts in den Sozialen Medien bieten eine große Wissensbasis ([Montserrat Gomez Adorno, Rios, Posadas Durán, Sidorov und Sierra, 2018](http://www.cys.cic.ipn.mx/ojs/index.php/CyS/article/view/2882/2429) S.1). Sie haben einen starken Einfluss auf die öffentliche Meinung, sind jedoch auch einfach zu manipulieren. Spätestens seit den U.S. Präsidentschaftswahlen im Jahr 2016, in denen sogenannte \"Fake news\" über Twitter verbreitet wurde, sollte sich jeder diesem Problem bewusst sein.\n",
    "Die Frage nach der Authentizität der Texte ist daher stark in den Vordergrund gerückt worden ([Kestemont et al.](http://ceur-ws.org/Vol-2125/invited_paper_2.pdf) S.1f.). Zwar gibt es bereits viele veröffentlichte Arbeiten bezüglich der Zuordnung von Texten zu dem entsprechenden Verfasser, jedoch benötigen diese eine feste Menge an Autoren und müssen auf dieser trainiert werden. Zudem wäre es nicht möglich zu erkennen, ob lediglich eine einzelne Passage des Textes nachträglich manipuliert wurde, eine Entscheidung mit der selbst Menschen Probleme haben. Ein interessanter Ansatz und aktuelles Forschungsthema ist es, zu untersuchen, ob zwischen zwei Texten oder innerhalb eines Textes eine Änderung des Schreibstils vorliegt und anhand dieser Analyse zu entscheiden, ob der Text von demselben Autor stammen oder ob mehrere Autoren beteiligt waren. \n",
    "In dieser Seminararbeit wird versucht diese Problemstellung mithilfe verschiedener Methoden und Modelle aus der \"Natural language processing\" und \"Text Mining\" zu lösen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problemstellung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Identifikation von Texten mit geteilter Autorenschaft wird in der Literatur auch als Style Change Detektion (SCD) bezeichnet. Ziel ist es, Texte intrinsisch auf eine Änderung des Schreibstils zu untersuchen. Als Schreibstil bezeichnet man dabei die Art und Weise der Autoren bestimmte Inhalte auszudrücken. Da sich dieser von Autor zu Autor unterscheidet, kann von einer plötzlichen Stiländerung innerhalb eines Textes auf einen weiteren Autor und somit auf eine geteilte Autorenschaft geschlossen werden.\n",
    "Es handelt sich um ein binäres Klassifikationsproblem, das sich mithilfe verschiedener Verfahren des Maschinellen Lernens lösen lässt. Dafür wird in dieser Arbeit auf den CMU Book Summary Datensatz zurückgegriffen. Dieser umfasst über 16000 Zusammenfassungen von Büchern. Die Problemstellung untergliedert sich in zwei Teilaufgaben. \n",
    "\n",
    "Da es sich um überwachtes Lernen handelt, müssen zunächst gelabelte Daten künstlich generiert werden. Dazu sollen Texte aus dem gegeben Datensatz miteinander kombiniert werden. Die Herausforderung besteht darin, lediglich sich inhaltlich sehr ähnliche Texte zu vermischen. Somit wird sichergestellt, dass im weiteren Verlauf der Arbeit die stilistischen Merkmale relevant sind und nicht anhand von inhaltlichen Brüchen unterschieden werden kann. Des Weiteren kann die Schwierigkeit der Aufgabe über die Anzahl und die Positionen der Kombinationen innerhalb eines Textes erhöht werden.\n",
    "\n",
    "In dem Zweiten Teil der Arbeit geht es um die Identifikation dieser kombinierten Texte, die jetzt einer geteilten Autorenschaft unterliegen. Zuerst soll eine einfache Baseline geschaffen werden, um eine Referenz auf diesem Datensatz zu haben. Anschließend werden komplexere Modelle trainiert und die Ergebnisse verglichen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorgehen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Erzeugung der gelabelten Daten werden zunächst lediglich ähnliche Texte aneinandergehängt, sodass in jedem Text maximal ein Stilbruch und zwei Autoren vorkommen. Werden mit diesem Vorgehen gute Ergebnisse erzielt, so könnte die Schwierigkeit durch eine stärkere Vermischung erhöht werden. Die Ähnlichkeit der Text wird dabei über die im Datensatz enthaltene Genre-Information der zusammengefassten Bücher berechnet. \n",
    "Die Baseline besteht aus einer SVM, einem Random Forrest und einem LightGBM.\n",
    "Für die Klassifikation werden zwei unterschiedliche Ansätze ausprobiert und miteinander verglichen. Zum einen werden die Text in Fenster unterteilt und für jedes dieser Fenster konstruierte Merkmale extrahiert. Dabei werden lexikalische und syntaktische Merkmale berücksichtigt. Da dieser Ansatz jedoch die Struktur und die Grammatik der Texte vernachlässigt, wird noch der Ansatz verfolgt, mittels Worteinbettung den kompletten Text in ein Rekurrentes Neuronales Netz zu übergeben.\n",
    "Da sich bereits zu Beginn Zweifel gegenüber der Qualität des Booksummary-Datensatzes ergeben haben, werden die Ergebnisse anschließend zusätzlich auf einem bereits gelabelte Datensatz aus der PAN CLEF 2018 Challenge validiert, um die Generalisierbarkeit zu überprüfen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur im vorherigen Abschnitt beschriebenen Aufgabenstellung finden man in der Literatur nur wenig Veröffentlichungen. Einige aktuelle Arbeiten zur Style Change Detection findet man in der [PAN CLEF-2018 Challenge](http://ceur-ws.org/Vol-2125/invited_paper_2.pdf). Bei [PAN](https://pan.webis.de) handelt es sich um eine Plattform, auf der seit 2009 jährlich Aufgabenstellungen zu ausgewählten Themenbereichen und Datensätzen im Bereich der maschinellen Textverarbeitung veröffentlicht werden. Insgesamt gab es im Jahr 2018 im Hinblick auf die Detektion von Stilbrüchen fünf Abgaben. \n",
    "Den ersten Platz belegte entgegen dem aktuellen Trend zu Deep Learning Zlatkova et al. mit einer Genauigkeit von 0.893 auf dem vorgegebenen Testdatensatz. Dafür wurden Texte in mehrere sich überschneidende Fenster unterteilt und für diese jeweils vorgegebene Merkmale berechnete. Anschließend wurden diese an ein Ensemble-Learning-System übergeben, das auf SVM, einen Random Forest, AdaBoost, MLP und LightGBM beruht.\n",
    "\n",
    "Bereits 2017 hat PAN eine zur oben beschriebenen Problemstellung sehr ähnliche Aufgabe unter dem Titel [Style breach detection](http://ceur-ws.org/Vol-1866/invited_paper_3.pdf) veröffentlicht. Diese geht jedoch noch einen Schritt weiter und beschäftigt sich mit der Identifikation der genauen Positionen, an denen sich der Schreibstil ändert. Im Rahmen dieser Aufgabe wurden lediglich 3 Lösungen abgegeben. Zwar konnten alle die zufallsbasierte Baseline übertreffen, jedoch keine sonderlich guten Ergebnisse erzielen. \n",
    "\n",
    "Eine große Verwandtschaft zur Style Change Detection weist auch das Themengebiet der Plagiatserkennung auf. Ziel ist es hierbei, Stellen in Texten zu finden, in denen auf Inhalte aus fremden Arbeiten zurückgegriffen wird, ohne dass diese als solche gekennzeichnet werden. Es wird dabei zwischen dem extrinsischen und dem intrinsischen Ansatz unterschieden.\n",
    "Beim Erstgenannten wird auf ein Referenzdatensatz zurückgegriffen, in welchem nach Quellen für mögliche Plagiate durchsucht wird ([Stamatatos et al.](http://ceur-ws.org/Vol-1609/16090691.pdf) S. 3).\n",
    "Bei der zweiten Herangehensweise wird lediglich der zu untersuchende Text betrachtet. Im Vordergrund steht hierbei auch der persönliche Schreibstil des Autors. Es wird versucht mithilfe verschiedener Verfahren Stellen im Text zu identifizieren, in denen der Schreibstil signifikant von dem restlichen Text abweicht. ([Polydouri, Siolas und Stafylopatis, 2017](https://link.springer.com/content/pdf/10.1007%2F978-3-319-65172-9_9.pdf) S.1) \n",
    "Hierfür wurden zumeist unüberwachte Verfahren zur Ausreißererkennung verwendet. \n",
    "Grundannahme für diese Verfahren ist es, dass ein Großteil des Textes von ein und demselben Autor stammt. ([Kuznetsov, Motrenko, Kuznetsova, und Strijov](http://ceur-ws.org/Vol-1609/16090912.pdf) S.1)\n",
    "Für diese Arbeit ist besonders die intrinsische Plagiatserkennung von Bedeutung. Arbeiten zu diesem Themengebiet fanden auch im Rahmen der [PAN-Reihe](https://pan.webis.de/tasks.html) statt. In den Jahren 2009 bis 2011 gab es jeweils sowohl Aufgaben zur intrinsischen als auch zur extrinsischen Plagiatserkennung. 2016 wurde die Aufgabenstellung unter dem Begriff „Authorship diarization“ in einer abgewandelten Form wieder aufgenommen mit dem Ziel Textpassagen entsprechend ihren Autoren zu clustern ([Stamatatos et al.](http://ceur-ws.org/Vol-1609/16090691.pdf) S. 3). \n",
    "\n",
    "Ein weiteres etwas entfernteres Themengebiet ist die Authorship Attribution, also die Zuordnung anonymer Texte zu den jeweiligen Autoren, von denen sie verfasst wurden. Auch wenn sich diese Aufgabenstellung stark von den in dieser Arbeit verfolgten Ziele unterscheidet, so ist die Herangehensweise doch sehr ähnlich. Denn im Gegensatz zu einer inhaltsbasierten Klassifikation, wird auch hier die Ähnlichkeit der Texte mittels stilistischer Merkmale berechnet. Für die Identifikation einer geteilten Autorenschaft eines Textes kann dem zu folge auf dieselben Features zurückgegriffen werden.  Auch hierzu wurden im Rahmen der PAN-Serie mehrere Arbeiten veröffentlich. Zusätzlich gibt es viele Arbeiten die sich insbesondere mit der Wahl der richtigen Merkmale auseinandergesetzt haben. Dazu zählen beispielsweise die Arbeiten von [Stamatatos](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.440.1634&rep=rep1&type=pdf), von [Houvardas and Stamatatos](https://link.springer.com/content/pdf/10.1007%2F11861461_10.pdf) oder von [Sapkota, Bethard, Montes-y-Gomez, und Thamar Solorio](http://aclweb.org/anthology/N15-1010).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Durchführung einer Klassifikation mittels mathematischer Modelle, müssen die Texte zunächst in numerische Tensoren überführt werden. Ein wichtiger Bestandteil dieser Vektorisierung ist die Zerlegung der Texte in Tokens. Dabei werden die Texte in einzelne Buchtstaben oder einzelne Wörter aufgeteilt. Anschließend können entweder festgelegte Merkmale berechnet und an das Modell übergeben werden oder man wandelt die Token in Vektoren um und übergibt diese direkt an das Modell. Im Folgenden werden beide Ansätze kurz vorgestellt.   \n",
    "\n",
    "**Konstruierte Merkmale:**\n",
    "\n",
    "Für jeden Text werden dabei im Voraus festgelegte Merkmale berechnet, die die verschiedene Schreibstile der Autoren möglichst stark voneinander abgrenzen sollen. [Stamatatos](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.440.1634&rep=rep1&type=pdf) unterscheidet dabei zwischen lexikalischen, zeichenbasierten, syntaktischen, semantischen und anwendungsbezogenen Merkmalen. \n",
    " \n",
    "Beispiele für lexikalische Merkmale sind die durchschnittliche Wort-/ Satzlänge, die durchschnittliche Fehlerrate und der Wortschatz des Autors.\n",
    "Weitere verbreitete lexikalische Merkmale sind die Häufigkeiten der auftretenden Wörter und Wortkombinationen, den sogenannten N-Grammen. Dieser Ansatz ist auch unter dem Begriff „Bag of words“ bzw. „Bag of n-grams“ bekannt. Dabei lassen sich die betrachteten Wörter in Funktions- und Inhaltswörter unterteilen. Im Rahmen einer stilistischen Repräsentation der Texte spielen Funktionswörter eine wichtige Rolle. Hierbei handelt es sich um kurze und sehr häufig vorkommende Wörter, die für den Inhalt eines Satzes irrelevant sind und nur zur Verbindung der Inhaltswörter dienen. Während diese in inhaltsbasierten Textklassifikationen herausgefiltert werden, tragen sie viel zu einer stilistischen Abgrenzung verschiedener Autoren bei. \n",
    "\n",
    "Auch bei zeichenbasierten Merkmalen wird die Häufigkeit des Auftretens von einzelnen Zeichen und zeichenbasierter N-Gramme betrachtet. Das Auftreten von Buchstaben, Zahlen, Groß- und Kleinschreibweisen und Leerzeichen gibt Auskunft über den Schreibstil des Autors ([Stamatatos](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.440.1634&rep=rep1&type=pdf) S. 4 ff.).\n",
    "Diese eignen sich besonders gut zur Zuordnung der Texte zu ihren entsprechenden Autoren, wobei besonders jene zu guten Ergebnissen beitragen, die Wortanfänge/-enden oder Satzzeichen beinhalten ([Sapkota, Bethard, Montes-y-Gomez, und Thamar Solorio](http://aclweb.org/anthology/N15-1010), S.1 ff.). \n",
    "\n",
    "Des Weiteren gibt es syntaktische und semantische Merkmale, die jedoch stark von der entsprechenden Sprache abhängen. Ein Beispiel für ein semantische Merkmale sind N-Gramme auf Basis von Part-of-Speech-Tags. \n",
    "\n",
    "Bei allen N-Grammen stellt sich für die Merkmalsauswahl die Frage nach der richtigen Wahl des \"N\", welches die Anzahl der berücksichtigten Wörter/Zeichen festlegt.\n",
    "Generell gilt, je höher die Ordnung der N-Gramme, desto mehr Kontext wird betrachtet. Jedoch wird dadurch auch die Dimensionen des entstehenden Merkmalraums stark erhöht ([Stamatatos](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.440.1634&rep=rep1&type=pdf) S. 7). Verfahren wie Stemming oder Lemmatizing können genutzt werden, um die Dimensionen zu reduzieren.\n",
    "\n",
    "Die Betrachtung der Häufigkeiten ist relativ simpel und wird in vielen Arbeiten verwendet. Sie hat jedoch den Nachteil, dass die Tokens als Menge anstatt einer Sequenz wahrgenommen, wodurch jedoch die Reihenfolge, Grammatik und Struktur der Texte missachtet werden.\n",
    "\n",
    "\n",
    "\n",
    "**Gelernte Merkmale:**\n",
    "\n",
    "Im Gegensatz zu den selbst berechneten Merkmalen, können die Token mittels One-Hot-Encoding auch direkt in Vektoren umgewandelt werden. Der Vorteil dieses Vorgehens liegt darin, dass im Vergleich zum \"Bag of Words\"-Ansatz die Struktur des Textes erhalten bleibt. Diese Repräsentationsform führt jedoch zu sehr hohen Dimensionen, da in der Regel innerhalb eines Korpus oftmals zehntausende verschiedener Wörter vorkommen. Verfahren der Worteinbettung ordnen dagegen jedem Token einen dichtbesetzteren Vektor zu. Ziel dieser Verfahren ist es mithilfe der Vektoren auch die semantischen Abhängigkeiten der Wörter abzubilden, sodass Wörter mit einer ähnlichen Bedeutung auch ähnlich Vektoren erhalten. \n",
    "Die bekanntesten Verfahren sind der [Word2Vec](https://arxiv.org/pdf/1402.3722.pdf)- und der [GloVe](http://www.aclweb.org/anthology/D14-1162)-Ansatz. \n",
    "Deep-Learning-Verfahren, wie zum Bespiel LSTMs oder CNNs, können anhand dieser Vektoren Sequenzen von Wörtern oder Zeichen erlernen und mithilfe der identifizierten Muster Klassifizierungen durchführen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Vorbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laden eigener Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T14:08:34.423128Z",
     "start_time": "2019-02-07T14:08:34.418032Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import aatm_support\n",
    "from tensor_board_logger import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laden von externen Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T14:08:34.436181Z",
     "start_time": "2019-02-07T14:08:34.430294Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import LSTM, ConvLSTM2D, Activation, Dense, Dropout, Input, MaxPooling1D, concatenate, BatchNormalization, Bidirectional, Dot, Average, Lambda, Flatten\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from keras import regularizers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Globale Intialisierungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T14:08:34.444564Z",
     "start_time": "2019-02-07T14:08:34.438269Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "memory = Memory(location='./tmp', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verwendete Datensätze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusammen mit der Aufgabenstellung wurde der [CMU Book Summary Datensatz](http://www.cs.cmu.edu/~dbamman/booksummaries.html) vorgeschlagen. Teil der Aufgabenstellung war es aus diesem Datensatz einen für das Problem der SCD geeigneten gelabelten Datensatz zu erstellen, indem Texte des CMU Book Summary Datensatzes rekombiniert werden.\n",
    "\n",
    "Im folgenden wird der Datensatz kurz vorgestellt und begründet warum der CMU Book Summary Datensatz für die Aufgabenstellung nicht ideal ist. Nichtsdestotrotz wird in diesem Kapitel weiter vorgestellt wie gelabelte Daten für das SCD Problem konstruhiert wurden. Die zwei daraus resultierenden Datensätze, die im weiteren Verlauf verwendet wurden werden beschrieben.\n",
    "\n",
    "Motiviert durch die Vorbehalte gegenüber dem Datensatz wird außerdem ein alternativer Datensatz von der [PAN Style Change Detection @ CELF 2018](https://pan.webis.de/clef18/pan18-web/index.html) vorgestellt, der bei weiteren Arbeiten ebenfalls als Benchmark und zur methodischen Validierung herangezogen wurde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMU Book Summary Datensatz\n",
    "\n",
    "Der 2013 von David Bamman and Noah Smith veröffentliche [CMU Book Summary Datensatz](http://www.cs.cmu.edu/~dbamman/booksummaries.html) enthält 16.559 inhaltiche Zusammenfassungen von Büchern von Wikipedia sowie Metadaten über Autor, Titel, Publikationsatum und Genre des zusammengefassten Buches, sowie deren ID auf Wikipedia und Freebase (Metadaten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T13:13:53.718723Z",
     "start_time": "2019-02-02T13:13:53.464611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokumente insgesamt:\t 16559\n",
      "Jedes Dokument hat 7 Einträge.\n",
      "Index(['wiki_id', 'firebase_id', 'title', 'author', 'pub_date', 'genres',\n",
      "       'plot'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "bs_data = datasets.load_book_summary_raw()\n",
    "\n",
    "# Total entries\n",
    "print(\"Dokumente insgesamt:\\t\", bs_data.shape[0])\n",
    "print(\"Jedes Dokument hat %d Einträge.\" % (bs_data.shape[1]))\n",
    "print(bs_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T13:14:31.369281Z",
     "start_time": "2019-02-02T13:14:31.346998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einmalige Wikipedia IDs: 16559\n",
      "Einmalige Firebase IDs:\t 16559\n",
      "Einmalige Titles:\t 16277\n",
      "Einmalige Authors:\t 4715\n",
      "Einmalige Pub. Dates:\t 2640\n",
      "\n",
      "Einige Einträge fehlen:\n",
      "wiki_id           0\n",
      "firebase_id       0\n",
      "title             0\n",
      "author         2382\n",
      "pub_date       5610\n",
      "genres         3718\n",
      "plot              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Entries are unique books by ids...\n",
    "print(\"Einmalige Wikipedia IDs:\", bs_data.wiki_id.unique().size)\n",
    "print(\"Einmalige Firebase IDs:\\t\", bs_data.firebase_id.unique().size)\n",
    "# ...but not by title\n",
    "print(\"Einmalige Titles:\\t\", bs_data.title.unique().size)\n",
    "print(\"Einmalige Authors:\\t\", bs_data.author.unique().size)\n",
    "print(\"Einmalige Pub. Dates:\\t\", bs_data.pub_date.unique().size)\n",
    "\n",
    "print(\"\\nEinige Einträge fehlen:\")\n",
    "print(bs_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz wurde veröffentlicht im Zusammenhang mit Arbeiten zum Abgleich von Volltexten und Zusammenfassungen, sodass der Fokus auf Metadaten zu den zusammengefassten Büchern lag, nicht auf den Zusammenfassungen selbst. Es gilt hervorzuheben, dass die Informationen zur Autorenschaft sich auf das zusammengefasste Buch beziehen und nicht auf die Zusammenfassung selbst. Die im Datensatz enthaltenen Metainformationen sind im Kontext der intrinsischen Stilanalyse mit Ausnahme der Genre nicht von Bedeutung.\n",
    "\n",
    "Bei dem Versuch durch Kombination der Dokumente einen gelabelten Datensatz zu konstruieren muss aufgrund der fehlenden Metainformationen zu den Zusammenfassungen die Annahmen getroffen werden, dass jede Zusammenfassung von einem andere Autor stammt. Da die Zusammenfassungen von Wikipedia stammen impliziert dies jedoch zwei Risiken:\n",
    "\n",
    "1. Zusammenfassungen könnten vom selben Autor stammen.\n",
    "2. Zusammenfassungen könnten von mehreren Personen verfasst oder redigiert worden sein.\n",
    "\n",
    "Da es im Rahmen dieser Arbeit nicht möglich ist diese Risiken zu mitigieren (z.B. durch Ergänzen geigneter Metainformationen), wird stattdessen auf einen zusätzlichen Datensatz zurückgegriffen (siehe [Kapitel 3.3](#Alternativer-Datensatz-zur-Verifikation-der-verwendeten-Ansätze)). \n",
    "\n",
    "In Anwendungsscenarien der Authentizitätserkennung bei Texten ist es unwahrscheinlich, dass nicht authentische Textpassagen vollkommen andere Inhalte aufweisen als der restliche Text. Um einen möglichst realistischen Datensatz zu erhalten und eine Erkennung der Bruchstellen nach inhaltlichen Texteigenschaften zu vermeiden, sollen die Konstruktion gelabelter Texte deshalb nach Maßstäben ihrer inhaltlichen Kompatibilität stattfinden. Das gewälte Maß dazu wird auf den gegeben Genreinformationen basieren. Vorteilhaft ist an dieser Stelle, dass es sich um Zusammenfassungen und damit bereits um Abstrakte und in ihrer Art und Aufbau vermutlich ähnliche Texte handelt.\n",
    "\n",
    "Folgend wird also der Datensatz in Bezug auf die Genre-Informationen untersucht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T12:26:38.755526Z",
     "start_time": "2019-02-02T12:26:38.750493Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_genre_book_relations(data):\n",
    "    # Subset original data\n",
    "    temp = data.loc[:, ['wiki_id', 'genres']]\n",
    "    # drop rows without genres\n",
    "    temp = temp.dropna()\n",
    "    # extract `id: genre` pairs to lists\n",
    "    temp.genres = temp.genres.str.replace('[{}\"]', '', regex=True).str.split(', ')\n",
    "    # map each genre <=> book relation to a seperate row\n",
    "    genre_tags = []\n",
    "    for key, row in temp.iterrows():\n",
    "        book_id = row[0]\n",
    "        tags = pd.Series(row[1]).str.split(': ')\n",
    "        for genre_id, genre_name in tags:\n",
    "            genre_tags += [[book_id, genre_id, genre_name]]\n",
    "\n",
    "    genre_tags = pd.DataFrame(genre_tags)\n",
    "    genre_tags.columns = ['wiki_id', 'genre_id', 'genre_name']\n",
    "    \n",
    "    return genre_tags\n",
    "    \n",
    "def extract_genres(genre_tags):\n",
    "    # Extract unique genres\n",
    "    genres = genre_tags.groupby(['genre_id', 'genre_name']).agg('count')\n",
    "    genres.columns = ['count']\n",
    "    \n",
    "    print(\"Genre Data\")\n",
    "    print(genres.describe())\n",
    "    print(\"\\nNote that there are more unique ids than names ('Mystery' genre)\")\n",
    "    \n",
    "    return genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T12:26:44.213400Z",
     "start_time": "2019-02-02T12:26:39.526544Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre Data\n",
      "             count\n",
      "count   228.000000\n",
      "mean    131.596491\n",
      "std     545.391873\n",
      "min       1.000000\n",
      "25%       2.000000\n",
      "50%       6.500000\n",
      "75%      29.000000\n",
      "max    4747.000000\n",
      "\n",
      "Note that there are more unique ids than names ('Mystery' genre)\n",
      "\n",
      "Top 10 Genres\n",
      "                                  count\n",
      "genre_id  genre_name                   \n",
      "/m/02xlf  Fiction                  4747\n",
      "/m/014dfn Speculative fiction      4314\n",
      "/m/06n90  Science Fiction          2870\n",
      "/m/05hgj  Novel                    2463\n",
      "/m/01hmnh Fantasy                  2413\n",
      "/m/0dwly  Children's literature    2122\n",
      "/m/02n4kr Mystery                  1395\n",
      "/m/03mfnf Young adult literature    825\n",
      "/m/0c3351 Suspense                  765\n",
      "/m/0lsxr  Crime Fiction             753\n"
     ]
    }
   ],
   "source": [
    "genre_tags = extract_genre_book_relations(bs_data)\n",
    "genres = extract_genres(genre_tags)\n",
    "print(\"\\nTop 10 Genres\")\n",
    "print(genres.sort_values('count', ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T12:46:31.636275Z",
     "start_time": "2019-02-02T12:46:31.523342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         genre_name\n",
      "count  12841.000000\n",
      "mean       2.336578\n",
      "std        1.401971\n",
      "min        1.000000\n",
      "25%        1.000000\n",
      "50%        2.000000\n",
      "75%        3.000000\n",
      "max       11.000000\n"
     ]
    }
   ],
   "source": [
    "# count genres per book\n",
    "n_genres_per_book = genre_tags.loc[:,['wiki_id', 'genre_name']].groupby('wiki_id').count()\n",
    "# draw histogram\n",
    "n_genres_per_book.hist()\n",
    "plt.title(\"Verteilung der Anzahl von Genres pro Buch\")\n",
    "plt.ylabel(\"Anzahl Bücher mit x Genres\")\n",
    "plt.xlabel('Anzahl Genres')\n",
    "plt.show()\n",
    "print(n_genres_per_book.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T12:49:25.439748Z",
     "start_time": "2019-02-02T12:49:25.435840Z"
    }
   },
   "source": [
    "Es gibt 228 Genres nach ID, jedoch nur 227 eindeutige Genres nach Bezeichnung. Das Genre 'Mystery' wird unter zwei IDs geführt. Bereits unter den Top 10 Genres lässt sich gut erkennen, dass es sich bei vielen Genres auch um Sub-Genres handelt, z.B. 'Fiction' und 'Crime Fiction'. Durchschnittlich ist ein Genre 132 mal vergeben. 75% der Genres sind nur 29 mal oder weniger vertreten. Das häufigste Genre mit 4747 Dokumenten ist 'Fiction'. Im Durchschnitt werden jedem Buch 2,34 Genre zugeordnet. Es haben 50% aller Bücher 2 oder weniger, 75% haben 3 oder weniger Genre zugeordnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konstruktion von gelabelten Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kombinatorische Variablen\n",
    "\n",
    "Bei der Kombination von Texten gibt es mehrere Faktoren, die berücksichtigt und variiert werden können, um verschiedene Datensätze zu erstellen. Es liegt nahe, dass das Vorgehen bei der Erstellung des Datensatzes später Einfluss auf die Ergebnisse bei der Identifizierung der selben Texte hat.\n",
    "\n",
    "**Ähnlichkeit der Texte:**\n",
    "Durch Variation eines Schwellenwerts in Bezug auf die minimale Ähnlichkeit - gegeben eines geeigneten Ähnlichkeitmaßes - kann die Schwierigkeit der resultierenden Kombinationen beeinflusst werden kann. Die Bestimmung der geteilten Urheberschaft von Texten, die sich nach einem geeigneten Maß im Voraus ähnlicher sind, könnte schwieriger zu erkennen sein als bei einem kombinierten Text, bei dem Originaltexte im Vorfeld als weniger ähnlich eingestuft wurden.\n",
    "\n",
    "**Wiederverwendung von Texten:**\n",
    "Soll bei der Kombination von Texten mit oder ohne Zurücklegen kombiniert werden? Ein Text, der für die Kombination verwendet wurde, kann entweder für die Kombination mit zusätzlichen Texten wiederverwendet werden oder eben nicht. Dies kann ebenso für die Wiederverwendung als einzelner Text im resultierenden Datensatz variiert werden.\n",
    "\n",
    "**Verfahren zur Kombination:**\n",
    "Es gibt verschiedene Möglichkeiten, Texte zu kombinieren. Die triviale Variante ist zwei Texte aneinander zu hängen. Ein anderer Ansatz könnte darin bestehen, einzelne Texte in Absätze oder Sätze aufzuteilen und diese dann zu verschachteln oder zufällig zu mischen.\n",
    "\n",
    "**Anzahl der zu kombinierenden Texte:**\n",
    "Beliebig viele Texte können zu Texten gemeinsamer Autorenschaft mit unterschiedlichem Grad kombiniert werden, also bspw. 2, 3 oder mehr Autoren.\n",
    "\n",
    "**Anteil der kombinierten Texte am resultierenden Datensatz:**\n",
    "Soll ein ausgeglichener oder ein unausgeglichener Datensatz erstellt werden? Letzterer ist dabei wahrscheinlich realistischer da unter viele authentischen Dokumenten wenige unauthentische sein werden. Andererseits ist ein ausgeglichener Datensatz in den meisten Fälle besser um Algorithmen effizient und ohne Bias zu trainieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ähnlichkeitsmaß"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ähnlichkeit zu kombinierender Texte wird als primärer Faktor für Schwierigkeit und Qualität des resultierenden Datensatzes betrachtet. Die Autoren des Datensatz für die [2018 PAN Style Change Detection](http://ceur-ws.org/Vol-2125/invited_paper_2.pdf) haben dies bspw. dadurch sichergestellt, dass Fragen und Antworten aus dem technisch Forum Stack Overflow verwendet wurden, für Metainformationen zu den enthaltenen Themen und Subthemen verfügbar waren. Analog verwenden wir bei dem Book Summary Datensatz die vergebenen Genre und Subgenre.\n",
    "\n",
    "Dazu wird für jedes Dokument ein Vektor erstellt der binär die Zugehörigkeit zu jedem Genre kodiert (\"k-hot encoding\"). Jede Dimension des Vektorraums repräsentiert also die Zugehörigkeit zu einem Genre, die entweder mit 1 (\"zugehörig\") oder 0 (\"nicht zugehörig\") belegt wird. \n",
    "\n",
    "Da vor allem Texte mit hoher Ähnlichkeit von Interesse sind, wurden bei der Kodierung der Genres ausschließlich die Genres berücksichtigt, die mindestens zwei Texten zugeordnet werden. Dadurch reduziert sich die Dimension des Vektorraums von 228 auf 183."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:19:47.517394Z",
     "start_time": "2019-02-02T14:19:47.510092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract k-hot-encoding of genres\n",
    "@memory.cache\n",
    "def extract_genre_vectors(data):\n",
    "    # parse genre strings\n",
    "    result = data.genres.str.replace('[{}\"]', '', regex=True) \\\n",
    "                        .str.replace('/m/.+?: ', '', regex=True) \\\n",
    "                        .str.get_dummies(', ')\n",
    "    # Prefix and normalize genre columns\n",
    "    result.columns = ['genre_' + str(col) for col in result.columns.str.lower().str.replace('[^a-z]', '_')]\n",
    "    # Select genres that have been assigned at least twice.\n",
    "    # \n",
    "    # Assuming we use genres only to match text an additional dimensions \n",
    "    # that is never shared will only make a text more 'different' from \n",
    "    # all other text. No information gain in that.\n",
    "    # \n",
    "    # This reduces genres from 227 to 183. \n",
    "    result = result.loc[:, result.sum(axis=0) >= 2]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Ähnlichkeitsmaß für die berechneten Vektoren wird die Kosinus-Ähnlichkeit verwendet. Die Kosinus-Ähnlichkeit zeigt die Ähnlichkeit der Ausrichtung zweier Vektoren an, indem sie den Cosinus des Winkels zwischen diesen Vektoren misst. Die Größe der Vektoren ist nicht relevant. Die Kosinus-Ähnlichkeit ist 0 für orthogonale Vektoren, 1 für Vektoren gleicher Ausrichtung oder -1 für diametral entgegengesetzte Vektoren.\n",
    "\n",
    "$$ similarity: S_C(x,y) = cos(\\pmb x, \\pmb y) = \\frac {\\pmb x \\cdot \\pmb y}{||\\pmb x|| \\cdot ||\\pmb y||} $$\n",
    "\n",
    "Da jeder Text mit jedem anderen verglichen wird erhalten wir eine entsprechende Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T14:08:34.459374Z",
     "start_time": "2019-02-07T14:08:34.446435Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def calc_cosine_sim_matrix(genres):\n",
    "    # calculate cosine similarities\n",
    "    result = cosine_similarity(genres)\n",
    "    # override lower diagonal with nan to drop duplicates and self combination\n",
    "    result[np.tril_indices(result.shape[0])] = np.nan\n",
    "    # downcast precision to reduce memory footprint\n",
    "    result = pd.DataFrame(result).apply(pd.to_numeric, downcast='float')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Konstruktion von Datensätzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit den berechneten Ähnlichkeiten der Texte und unter berücksichtigung der weiteren Faktoren als Variablen wurden zwei Datensätze konstruiert. Implementiert wurde die einfache Kombination durch aneinanderhängen von zwei Texten mit und ohne Zurücklegen unter Berücksichtigung des erwünschten Anteils gemischter oder einfacher Texte im resultierenden Datensatz und eines Grenzwertes für die Ähnlichkeit der zu kombinierenden Texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T14:08:34.482836Z",
     "start_time": "2019-02-07T14:08:34.461554Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(\n",
    "    # the dataset \n",
    "    data,\n",
    "    # the similarity matrix\n",
    "    sim_matrix,\n",
    "    # the minimum similarity between the combined texts\n",
    "    sim_threshold = 0.5,\n",
    "    # flag to reuse texts\n",
    "    reuse_texts = False,\n",
    "    # target share of combined texts in the resulting dataset\n",
    "    target_share = 0.2,\n",
    "    # name of the columns containing the text\n",
    "    text_col = 'plot',\n",
    "    # number of texts to combine, only 2 is supported\n",
    "    comb_degree = 2,\n",
    "    # Method of combination, only 'append' is implemented\n",
    "    # combination = 'append'\n",
    "):  \n",
    "    # We focus on the combination of two texts only.\n",
    "    if comb_degree > 2:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # Total number of available texts\n",
    "    n_total = data.shape[0]\n",
    "    # Instantiate number of texts that will be combined\n",
    "    n_combine = 0\n",
    "    # Calculate number of combined texts\n",
    "    if (reuse_texts):\n",
    "        n_combine = (n_total / ( 1 / target_share - 1)) * comb_degree\n",
    "    else:\n",
    "        # Number of texts that will be combined\n",
    "        n_combine = n_total * comb_degree / (1/target_share + comb_degree - 1)\n",
    "    \n",
    "    # `n_combine` should be an integer value and dividable by `comb_degree` and\n",
    "    # we will interpret target_share as minimum.\n",
    "    n_combine = math.ceil(n_combine)\n",
    "    n_combine += (n_combine % comb_degree)\n",
    "    \n",
    "    # Instantiate number of resulting combined texts\n",
    "    n_combined = int(n_combine / comb_degree)\n",
    "    # Number of texts that will directly be taken into the in the final dataset without combination\n",
    "    if reuse_texts:\n",
    "        n_direct = n_total\n",
    "    else:\n",
    "        n_direct = n_total - n_combine\n",
    "    \n",
    "    # Number of resulting texts\n",
    "    n_result = n_direct + n_combined\n",
    "    actual_share = n_combined/n_result\n",
    "    \n",
    "    print('Total # of input texts: ', n_total)\n",
    "    print('# of texts to combine: ', n_combine)\n",
    "    print('# of resulting texts with shared authorship: ', n_combined)\n",
    "    print('# of resulting texts without shared authorship: ', n_direct)\n",
    "    print('Total # of resulting texts: ', n_result)\n",
    "    print('Actual share of texts with shared authorship: ', actual_share)\n",
    "    \n",
    "    # dropping nan\n",
    "    sim_df = sim_matrix.stack()\n",
    "    # drop combinations below threshold and return left viable choices\n",
    "    choices = sim_df[sim_df >= sim_threshold]\n",
    "    \n",
    "    to_combine = np.ndarray((n_combined), dtype=tuple)\n",
    "    if reuse_texts:\n",
    "        choices = choices.index.values\n",
    "        # random selection of viable indice combinations\n",
    "        to_combine = np.random.choice(choices, n_combined, replace=False)\n",
    "    else:\n",
    "        for i in range(to_combine.shape[0]):\n",
    "            # choose random tuple\n",
    "            choice = np.random.choice(choices.loc[choices.notna()].index.values)\n",
    "            to_combine[i] = choice\n",
    "            # drop all tuples including either choice\n",
    "            choices.loc[[choice[0], choice[1]]] = np.nan\n",
    "            choices.loc[:, [choice[0], choice[1]]] = np.nan\n",
    "\n",
    "    tc_values = list(sum(to_combine,()))\n",
    "    all_values = pd.Series(data.index.values)\n",
    "    if reuse_texts:\n",
    "        to_direct = all_values\n",
    "    else:\n",
    "        to_direct = all_values[~all_values.isin(tc_values)]\n",
    "    \n",
    "    # combine texts\n",
    "    combined = pd.DataFrame([[append_texts(data, ids, text_col), 1] for ids in to_combine])\n",
    "    direct = pd.DataFrame([[data[text_col][i], 0] for i in to_direct])\n",
    "    \n",
    "    result = pd.concat(\n",
    "        [combined, direct],\n",
    "        axis=0,\n",
    "        ignore_index=True, \n",
    "        copy=False\n",
    "    )\n",
    "    \n",
    "    result.columns = ['text', 'label']\n",
    "    \n",
    "    return result\n",
    "\n",
    "def append_texts(data, ids, text_col = 'plot'):\n",
    "    t = \"\"\n",
    "    for i in range(len(ids)):\n",
    "        t += data[text_col][ids[i]]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Book Summary 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der erste Datensatz _Book Summary 1_ verwendet jeden Text nur ein einziges Mal. Der Ähnlichkeitsschwellwert liegt bei 0,8 und der Datensatz ist ausgeglichen. Es gibt 5.520 Texte mit geteilter Autorenschaft und 5.519 Texte ohne geteilte Autorenschaft. Insgesamt enthält der Datensatz 11.039 Dokumente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T10:05:53.231781Z",
     "start_time": "2019-02-06T10:05:53.219966Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of input texts:  16559\n",
      "# of texts to combine:  11040\n",
      "# of resulting texts with shared authorship:  5520\n",
      "# of resulting texts without shared authorship:  5519\n",
      "Total # of resulting texts:  11039\n",
      "Actual share of texts with shared authorship:  0.5000452939577861\n",
      "Next available file: ./datasets/book_summary_1.csv\n"
     ]
    }
   ],
   "source": [
    "# THIS WAS USED TO CONSTRUCT THE DATASET, \n",
    "# WOULD HOWEVER PRODUCE A DIFFERENT DATASET WHEN RUN AGAIN\n",
    "sim_matrix = calc_cosine_sim_matrix(extract_genre_vectors(bs_data))\n",
    "book_summary_1 = build_dataset(\n",
    "    bs_data,\n",
    "    sim_matrix,\n",
    "    sim_threshold = 0.8,\n",
    "    target_share = 0.5\n",
    ")\n",
    "\n",
    "dataset.to_csv(aatm_support.next_file('./datasets/book_summary', '.csv'), encoding='utf-8', doublequote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T10:09:01.166347Z",
     "start_time": "2019-02-06T10:09:00.950992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11039 entries, 0 to 11038\n",
      "Data columns (total 2 columns):\n",
      "text     11039 non-null object\n",
      "label    11039 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 258.7+ KB\n"
     ]
    }
   ],
   "source": [
    "book_summary_1 = datasets.load_book_summary_1()\n",
    "book_summary_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Book Summary 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der zweite Datensatz _Book Summary 2_ legt Texte nach dem ziehen zurück, woraus ein entsprechend größerer Datensatz resultiert. Der Ähnlichkeitsschwellwert liegt bei 0,95 und der Datensatz ist ausgeglichen. Es gibt 14.794 Texte mit geteilter Autorenschaft und 14.794 Texte ohne geteilte Autorenschaft. Insgesamt enthält der Datensatz 29.588 Dokumente. Vor der Kombination wurden Außenseiter im Sinne von besonders langen und besonders kurzen Texten entfernt, wodurch der Ausgangsdatensatz auf 14.794 reduziert wurde. Alle diese Texte sind als nicht kombinierte Texte im resultierenden Datensatz enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of input texts:  14794\n",
      "# of texts to combine:  29588\n",
      "# of resulting texts with shared authorship:  14794\n",
      "# of resulting texts without shared authorship:  14794\n",
      "Total # of resulting texts:  29588\n",
      "Actual share of texts with shared authorship:  0.5\n",
      "Next available file: ./datasets/book_summary_2.csv\n"
     ]
    }
   ],
   "source": [
    "# THIS WAS USED TO CONSTRUCT THE DATASET, \n",
    "# WOULD HOWEVER PRODUCE A DIFFERENT DATASET WHEN RUN AGAIN\n",
    "\n",
    "# filter very short and very long texts\n",
    "plot_len = bs_data['plot'].str.len()\n",
    "bs_data_filtered = bs_data.loc[(plot_len - plot_len.mean() < 2 * plot_len.std()) & (plot_len >= 300)]\n",
    "bs_data_filtered.reset_index(inplace=True)\n",
    "\n",
    "# calculate similarity matrix\n",
    "sim_matrix = calc_cosine_sim_matrix(extract_genres(data))\n",
    "\n",
    "dataset = build_dataset(\n",
    "    data,\n",
    "    sim_matrix,\n",
    "    sim_threshold = 0.95,\n",
    "    target_share = 0.5,\n",
    "    reuse_texts = True\n",
    ")\n",
    "\n",
    "dataset.to_csv(aatm_support.next_file('./datasets/book_summary', '.csv'), encoding='utf-8', doublequote=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T10:09:42.295455Z",
     "start_time": "2019-02-06T10:09:41.764156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29588 entries, 0 to 29587\n",
      "Data columns (total 2 columns):\n",
      "text     29588 non-null object\n",
      "label    29588 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 693.5+ KB\n"
     ]
    }
   ],
   "source": [
    "book_summary_2 = datasets.load_book_summary_2()\n",
    "book_summary_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternativer Datensatz zur Verifikation der verwendeten Ansätze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgrund der Bedenken an der Tauglichkeit des CMU Book Summary Datensatzes für das SCD Problem (siehe [Kapitel 3.1](#CMU-Book-Summary-Datensatz)), wurde der Datensatz der [PAN Style Change Detection](http://ceur-ws.org/Vol-2125/invited_paper_2.pdf) Aufgabe als Alternativer Datensatz herangezogen. Der Datensatz wurde für ein im Rahmen der [CLEF Conference](http://clef2018.clef-initiative.eu) veranstaltetes \"evaluabtion lab\" herausgegeben. \n",
    "\n",
    "Er beinhaltet insgesamt 5.824 Dokumente, die aus Fragen und Antworten des [StackExchange](https://stackexchange.com) Forum-Netzwerks zusammengestellt wurden. Der Texte enthalten zwischen 300 und 1000 Token und wurden bereinigt um Texte die von anderen Autoren editiert wurden. Bei der Erstellung wurde auf eine ausgewogene Verteilung von Autoren, Themen und Subthemen, sowie Anzahl an Autorenwechseln und der Länge der Texte geachtet. Dies gilt sowohl bei Dokumenten von mehreren als auch bei Dokumenten von einem Autor. \n",
    "\n",
    "Insgesamt stellt der Datensatz damit ein wesentlich qualitativere Grundlage zur Entwicklung von Algorithmen zur Erkennung von Texten mit mehreren Autoren da. Mit rund 5.824 Dokumenten ist er jedoch vergleichweise klein, was grade für die Verarbeitung in tiefen Neuronalen Netzen Herausforderungen mit sich bringt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Repräsentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Auswahl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für diese Arbeit werden neben verschiedenen von Hand ausgewählten Merkmalen N-grams auf Wort, \n",
    "Zeichen und POS mit jeweils variablen Längen betrachtet. Für die Umsetzung wird dabei die Open-Source-Library [NLTK](http://www.nltk.org/) verwendet, da diese sehr modular aufgebaut und weit verbreitet ist.\n",
    "Da die Dimensionen des Merkmalraums abhängig von der Anzahl der Wörter innerhalb eines N-Grammes stark ansteigen, soll im Feature-Selektion-Schritt im Voraus über den vollständigen Korpus algorithmisch eine Auswahl getroffen, welche N-Gramme für eine Klassifikation hinsichtlich des Schreibstils relevant sind. \n",
    "\n",
    "Wie bereits in [Kapitel 2.5](#Theorie) beschrieben, werden zunächst die Textdaten in Tokens zerlegt. Bereits bei diesem Vorgang gibt es eine Vielzahl von Möglichkeiten, die zu unterschiedlichen Ergebnisse führen können und die Dimension des Merkmalraums stark beeinflussen. Um im späteren Verlauf der Arbeit etwas Spielraum zu haben, wird versucht diesen Vorgang möglichst flexibel zu gestalten. Beispielsweise kann über Parameter gesteuert werden, ob die Wörter in Originalform vorliegen oder mittels Stemming oder Lemmatizing auf den Wortstamm zurückgeführt werden sollen. Außerdem können ausgewählte Satzzeichen entfernt, Groß- und Kleinschreibung angepasst und Wörter, sowohl nach Länge als auch nach der Zugehörigkeit zu einem Korpus mit Funktionswörtern, gefiltert werden. \n",
    "\n",
    "Für die Erstellung der N-Gramme wird auf den [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) von sklearn zurückgegriffen, der für eine festgelegte Menge aller gewünschten N-Grams und den Tokens die N-Gramme und ihre Häufigkeiten innerhalb jedes Textes bestimmt. \n",
    "Dieser Vorgang wird für die Wort-, Zeichen- und die POS-basierten N-Gramme durchgeführt. Für die POS-Identifizierung wird auf den [POS-Tagger von NLTK](http://www.nltk.org/api/nltk.tag.html) zurückgegriffen. \n",
    "Innerhalb jeder dieser drei Kategorien wird für jedes unterschiedliche 'N' eine Selektion der Merkmale getroffen. \n",
    "\n",
    "Um einen Vergleich zu ermöglichen, müssen die Häufigkeiten skaliert werden. Dazu werden jeweils die Häufigkeiten der N-Gramme eines Textes ins Verhältnis zur Gesamtzahl aller Token des Textes gesetzt. Alternativ könnte zur Normalisierung auch der TFIDF-Ansatz verwendet werden. Dieser wird im folgenden jedoch nicht genutzt, da dieser die Gewichte der relevanten Funktionswörter auf null setzt.\n",
    "\n",
    "Die Relevanz der Features kann anschließend sowohl auf Basis der Häufigkeiten als auch der [Varianzen](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html#sklearn.feature_selection.VarianceThreshold) über alle Texte des Korpus hinweg bestimmt werden, wobei auch eine Kombination beider Filtermethoden möglich ist.  Hohe Häufigkeiten der N-Gramme lassen auf ein Funktionswort schließen, die als äußert aussagekräftig für den Schreibstil von Autoren gelten. \n",
    "Eine hohe Varianz dagegen deutet auf ein besonders diskriminatives Merkmal hin. Neben dem Filtern über relativen und absoluten Grenzwerten für die Anzahl der Features, könne auch Quantile angegeben werden, sodass ein gewisser Anteil der Gesamthäufigkeiten oder der Gesamtvarianz abgedeckt ist.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Konfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dieser Methode werden die Parameter festgelegt, die beschreiben wie gefiltert werden soll. Es kann nach Varianz eines Merkmals und nach der Häufigkeit über den gesamten Korpus hinweg gefiltert werden. Für jedes N-Gramm kann eine relative oder eine absolute Zahl an gewünschten Merkmalen angegeben werden. Zusätzlich können auch Quantile und Thresholds als Filterkriterium gewählt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T12:53:47.408828Z",
     "start_time": "2019-02-04T12:53:47.403022Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def set_filter_params(\n",
    "    var_word_n_grams  = (True, 'absolute', [5000, 500, 500]),\n",
    "    var_char_n_grams  = (True, 'absolute', [500, 500, 500, 500]),\n",
    "    var_pos_n_grams   = (True, 'absolute', [500, 500, 500]),\n",
    "    freq_word_n_grams = (True, 'absolute', [2000, 2000, 2000]),\n",
    "    freq_char_n_grams = (True, 'absolute', [2000, 2000, 2000, 2000]),\n",
    "    freq_pos_n_grams  = (True, 'absolute', [2000, 2000, 2000])):\n",
    "\n",
    "    return {\n",
    "        # Filter by variance: (flag, Type_of_filter, [thresholds for each n in\n",
    "        # word_n_grams])\n",
    "        'var_word_n_grams': var_word_n_grams,      \n",
    "        # Filter by variance: (flag, Type_of_filter, [thresholds for each n in\n",
    "        # char_n_grams])\n",
    "        'var_char_n_grams': var_char_n_grams,   \n",
    "        # Filter by variance: (flag, Type_of_filter, [thresholds for each n in\n",
    "        # pos_n_grams])\n",
    "        'var_pos_n_grams': var_pos_n_grams,       \n",
    "        # Use the most common features: (flag, Type_of_filter, [thresholds for each n\n",
    "        # in word_n_grams])\n",
    "        'freq_word_n_grams': freq_word_n_grams,\n",
    "        # Use the most common features: (flag, Type_of_filter, [thresholds for each n\n",
    "        # in char_n_grams])\n",
    "        'freq_char_n_grams': freq_char_n_grams,           \n",
    "        # Use the most common features: (flag, Type_of_filter, [thresholds for each n\n",
    "        # in pos_n_grams])\n",
    "        'freq_pos_n_grams': freq_pos_n_grams\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe dieser Methode können die Parameter festgelegt werden, die beschreiben welche Merkmale berücksichtigt werden sollen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T12:53:47.416049Z",
     "start_time": "2019-02-04T12:53:47.410593Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def set_features_to_calc(\n",
    "        char_n_grams= [1,2,3,4],        \n",
    "        word_n_grams = [1,2,3],                                          \n",
    "        pos_n_grams=[1,2,3],                      \n",
    "        avg_sent_len=True,                         \n",
    "        avg_word_len=True,                         \n",
    "        token_per_sent=True,                      \n",
    "        vocabulary_richness=True\n",
    "    ):\n",
    "\n",
    "    return{\n",
    "        # list with n for char_n_grams\n",
    "        'char_n_grams': char_n_grams,        \n",
    "        # list with n for word_n_grams\n",
    "        'word_n_grams': word_n_grams,                                          \n",
    "        # list with n for pos_n_grams\n",
    "        'pos_n_grams': pos_n_grams,                      \n",
    "        # flag if average sentence length should be calculated\n",
    "        'avg_sent_len': avg_sent_len,                         \n",
    "        # flag if average token length should be calculated\n",
    "        'avg_word_len': avg_word_len,                         \n",
    "        # flag if token per sentences should be calculated\n",
    "        'token_per_sent':token_per_sent,                      \n",
    "        # flag if vocabulary_richness should be calculated\n",
    "        'vocabulary_richness': vocabulary_richness             \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dieser Methode werden die Parameter für das Tokenisieren der Texte festgelegt. Dies wird für die Erstellung der Wort N-Gramme benötigt. Beispielsweise kann festgelegt werden, auf welcher Ebene tokenisiert und wie gefiltert wird, ob die Schreibweise vereinheitlicht werden soll oder ob die Wörter auf ihren Wortstamm zurückgeführt werden sollen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T12:53:47.432238Z",
     "start_time": "2019-02-04T12:53:47.417792Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def set_token_params_1 (\n",
    "    word_tokenizer = RegexpTokenizer(r'\\w+'),      \n",
    "    sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle'), \n",
    "    get_tokens = 'sentence',                                                    \n",
    "    word_strain = 'stem',\n",
    "    filter_length = ('long', 0),                                                \n",
    "    handle_stopwords = '',                                                      \n",
    "    get_sentences = False,                                                      \n",
    "    punctuation = \"[,;.!—]\",                                                   \n",
    "    lower_stop_words = set(stopwords.words('english')),                         \n",
    "    uncapitalized = True):    \n",
    "    \n",
    "    return {\n",
    "        # Word tokenizer\n",
    "        'word_tokenizer': word_tokenizer,\n",
    "        # Sentence tokenizer\n",
    "        'sent_tokenizer': sent_tokenizer,\n",
    "        # Group tokens: 'text'|'sentence'\n",
    "        'get_tokens': get_tokens,\n",
    "        # 'lemma'|'stem'\n",
    "        'word_strain': word_strain,\n",
    "        # Get tokens with length >= <int> or <= <int>: ('long',<int>)|('short',<int>)\n",
    "        'filter_length': filter_length,\n",
    "        # 'get'|'remove'\n",
    "        'handle_stopwords': handle_stopwords, \n",
    "        # Sentences tokens\n",
    "        'get_sentences': get_sentences,\n",
    "        # Remove punctuation\n",
    "        'punctuation': punctuation,\n",
    "        # Stopwords\n",
    "        'lower_stop_words': lower_stop_words,\n",
    "        # Original or uncapitalized stemms/lemmas\n",
    "        'uncapitalized': uncapitalized \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T12:53:47.437465Z",
     "start_time": "2019-02-04T12:53:47.434030Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# helper to load feaure sets later\n",
    "def load_feature_selection(num=None, base='.//Features//selected_features'):\n",
    "    if num:\n",
    "        path = f'{base}_{num}.txt'\n",
    "    else:\n",
    "        path = aatm_support.last_file(base)\n",
    "    \n",
    "    return pd.read_csv(\n",
    "        path,\n",
    "        sep = ',',\n",
    "        header = 0, \n",
    "        index_col = 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T12:53:47.448921Z",
     "start_time": "2019-02-04T12:53:47.439615Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def run_feature_selection(\n",
    "        serie_texts,\n",
    "        features_to_calc = set_features_to_calc(), \n",
    "        token_params_1 = set_token_params_1(),\n",
    "        filter_params = set_filter_params(\n",
    "            var_word_n_grams=(True, 'threshold', [0.001, 0.001, 0.001]),\n",
    "            var_char_n_grams=(True, 'threshold', [0.001, 0.001, 0.001, 0.001]),\n",
    "            var_pos_n_grams=(True, 'threshold', [0.01, 0.01, 0.01]),\n",
    "            freq_word_n_grams=(False,'',[ ]),\n",
    "            freq_char_n_grams=(False,'',[]),\n",
    "            freq_pos_n_grams=(False,'',[])\n",
    "        ),\n",
    "        cv_min_df = 0.1\n",
    "    ):\n",
    "\n",
    "    features = FEATURE_SELECTOR_v4.select_features(\n",
    "        serie_texts,                          \n",
    "        features_to_calc, \n",
    "        token_params_1,              \n",
    "        filter_params,\n",
    "        path_to_features = aatm_support.last_file('.//Features//selected_features'),\n",
    "        flag_extract_features = False,\n",
    "        cv_min_df = cv_min_df,         \n",
    "        normalization_type = ''\n",
    "    )\n",
    "    \n",
    "    with open(aatm_support.next_file('.//Features//selected_features'), 'w') as f:\n",
    "        json.dump(features, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T12:53:47.454196Z",
     "start_time": "2019-02-04T12:53:47.451023Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# helper to load feaure sets later\n",
    "def load_features(num=None, base='.//Features//calc_features'):\n",
    "    if num:\n",
    "        path = f'{base}_{num}.txt'\n",
    "    else:\n",
    "        path = aatm_support.last_file(base)\n",
    "    \n",
    "    return pd.read_csv(\n",
    "        path,\n",
    "        sep = ',',\n",
    "        header = 0, \n",
    "        index_col = 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Durchführung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird beispielhaft eine Selektion der N-Gramme ausgeführt. Es wird lediglich nach der Häufigkeit gefiltert, sodass zum Beispiel auf Wortebene nur die Kunktionswörter berücksichtigt werden. Für jede Kategorie sollen dabei 100 Merkmale zurückgegeben werden. Für die restlichen Parameter werden die Default-Werte verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T14:04:00.347097Z",
     "start_time": "2019-01-27T13:15:35.783002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last valid file: .//Features//selected_features_2.txt\n",
      "Next available file: .//Features//selected_features_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianluebke/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Persisting input arguments took 0.61s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# For constructed data\n",
    "run_feature_selection(\n",
    "    load_dataset('2').text, \n",
    "    filter_params = set_filter_params(\n",
    "        var_word_n_grams=(False, '', []),\n",
    "        var_char_n_grams=(False, '', []),\n",
    "        var_pos_n_grams=(False, '', []),\n",
    "        freq_word_n_grams=(True, 'absolute', [100, 100, 100]),\n",
    "        freq_char_n_grams=(True, 'absolute', [100, 100, 100, 100]),\n",
    "        freq_pos_n_grams=(True, 'absolute', [100, 100, 100])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Berechnung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Feature Berechnung werden die Ergebnisse der Feature Selektion aufgegriffen. Für jeden Text des Training- und Testdatensatzes werden die Häufigkeiten der ausgewählten N-Gramme bestimmt. Dazu werden dem CountVectorizer die ermittelten Merkmale als Dictionary mit den selektierten Merkmalen übergeben, sodass bei lediglich diese bei der Erzeugung der Häufigkeitsmatrix berücksichtigt werden. Zusätzlich werden auch die manuell selektierten Merkmale berechnet. Dazu gehören die die durchschnittliche Satzlänge, die durchschnittliche Anzahl an Zeichen pro Wort, die durchschnittliche Anzahl an Token pro Satz und die Größe des verwendeten Vokabulars. \n",
    "Im Folgenden wird dies beispielhaft für den Pan-Datensatz ausgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def run_feature_extraction(series, save=True, selected_features=None):\n",
    "    if selected_features == None:\n",
    "        path_to_features = aatm_support.last_file('.//Features//selected_features')\n",
    "    else:\n",
    "        path_to_features = f'./Features/{selected_features}.txt'\n",
    "    \n",
    "    extracted_features = FEATURE_SELECTOR_v4.select_features(\n",
    "        serie_texts=series,                          \n",
    "        features_to_calc = set_features_to_calc(), \n",
    "        token_params_1 = set_token_params_1(),\n",
    "        filter_params= set_filter_params(\n",
    "            (False,'',[]),(False,'',[]),(False,'',[]),(False,'',[]),(False,'',[]),(False,'',[])\n",
    "        ),\n",
    "        path_to_features = path_to_features,    \n",
    "        flag_extract_features= True,\n",
    "        cv_min_df = 0,                           \n",
    "        normalization_type= ''\n",
    "    )\n",
    "    \n",
    "    print(extracted_features.info())\n",
    "        \n",
    "    # Save the calculated features\n",
    "    if save:\n",
    "        extracted_features.to_csv(\n",
    "            path_or_buf = aatm_support.next_file('.//Features//calc_features'),\n",
    "            sep = ',', \n",
    "            header = True,\n",
    "            index = True\n",
    "        )\n",
    "    \n",
    "    return extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T10:43:28.349067Z",
     "start_time": "2019-02-04T10:40:31.510369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2980 entries, 0 to 2979\n",
      "Columns: 1108 entries, avg_sent_len to NNP NNP NNP\n",
      "dtypes: float64(1108)\n",
      "memory usage: 25.2 MB\n",
      "None\n",
      "Next available file: .//Features//calc_features_2.txt\n"
     ]
    }
   ],
   "source": [
    "data = load_pan_data('training')\n",
    "extracted_features = run_feature_extraction(data.text, selected_features='selected_features_pan_training_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifikation von Texten mit geteilter Autorenschaft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basierend auf einer reihe von Beobachtungen unter den Einreichungen der PAN 2018 SCD Aufgabe werden zwei Ansätze zur Lösung des SCD Problems verfolgt und verglichen. \n",
    "\n",
    "Die erste Beobachtung ist, dass der von [Schaetti](http://ceur-ws.org/Vol-2125/invited_paper_2.pdf) zur PAN SCD 2018 vorgestellte Ansatz eines Character-basierten Convolutional Neural Network seiner Einschätzung nach unter anderem aufgrund des relativ kleinen Datensatzes mit nur 62% Genauigkeit den letzten Platz unter den eingereichten Lösungen belegt. Um dieses Ergebnis zu erreichen musst Schaetti bereits den Datensatz durch erneute rekobination der gegebenen Probleme auf ca. 18.000 Probleme erweitern. Die Vermuting liegt also nahe, dass ein Netz das komplett eigenständig Features lernen soll die zur Diskriminierung zweier Autorenstile geeignet sind deutlich mehr Daten benötigt.\n",
    "\n",
    "Das parallele hierarchische Attention Network von [M. Hosseinia and A. Mukherjee](http://ceur-ws.org/Vol-2125/paper_91.pdf) erreichte hingegen mit 82% die zweitbeste Leistung. Sie gaben ihrem Neuronalen Netz als Eingabe Parse Tree Feature (PTF) Embeddings. Dies entspricht der Eingabe des Textes als deren kodierte Satzstruktur und vermeidet so direkt jeglichen Einfluss des Inhalts auf das Ergebnis. Ebenso wird dem Netz nicht die Featureextraktion selbst überlassen, sondern es wird auf das Erkennen von Mustern beschränkt.\n",
    "\n",
    "Die dritte Beobachtung ist das weitere erfolgreiche Lösungen ([Zlatkova et al.](https://www.researchgate.net/profile/Momchil_Hardalov/publication/327268227_Recursive_Style_Breach_Detection_with_Multifaceted_Ensemble_Learning/links/5b9e0907a6fdccd3cb5a848b/Recursive-Style-Breach-Detection-with-Multifaceted-Ensemble-Learning.pdf?_sg%5B0%5D=6JOrLDdgo2QX5BCW_eUPQnbsvkvXD0BRSVBSC951bkfz2nl6HanfYCwG7bLLe7LheXdlkGsCReYu_BATjqGFcA.sufIfxS0aZo12zvN0NE3HD8ZQZB0so2OZP9x3-aHbL6HY9nBNa55LgJi1lEsLIZiu_-55qwzV5-7DoxjUqaqDg&_sg%5B1%5D=qFhJKbYJH-nLdAAAG6UEaaU75xAEAfaiNIumEbSvr77bdIrbNtvCWnUDmNYpTQbLRG9XwmC1oC96cM5vSON591aV6laI8bcOF-OED7V7Kyew.sufIfxS0aZo12zvN0NE3HD8ZQZB0so2OZP9x3-aHbL6HY9nBNa55LgJi1lEsLIZiu_-55qwzV5-7DoxjUqaqDg&_iepl=), [Safin und Ogaltsov](http://ceur-ws.org/Vol-2125/paper_104.pdf)) sich gemeinhin auf vorselektierte lexikalische und syntaktische Features gestützt haben, damit jedoch ein Ensemble von Klassifkatoren trainiert haben.\n",
    "\n",
    "Im ersten Ansatz sollen weitere Möglichkeiten geprüft werden, vorab extrahierte Features als Eingabe für Neuronale Netze zu verwenden und so für die relativ kleinen Datenmengen zu kompensieren. Es werden statistischen und syntaktischen Features verwendet, um ein Neuronales Netz zu trainieren.\n",
    "\n",
    "Im zweiten Ansatz werden Word-Embbedings verwendet ein Neuronales Netz zu trainieren. **BEGRÜNDUNG**\n",
    "\n",
    "Zu Beginn werden verschiedene Standard-Algorithmen als Baseline für die Klassifizierung angewandt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verwendete Evaluations-Metrik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Bewertung der vorgestellten Modelle wird die Genauigkeit verwendet, also der Anteil der korrekt klassifizierten Beispielen an allen evaluierten Beispielen:\n",
    "\n",
    "$$ acc = \\frac {Anzahl\\ korrekt\\ klassifizierter\\ Beispiele}{Anzahl\\ aller\\ Beispiele} = \\frac {TP + TN}{TP + FP + TN + FN}  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Vergleich von späteren Ergebnissen werden eine [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) und eine [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) Implementierung von Sklearn, sowie der [LightGBM](https://lightgbm.readthedocs.io/en/latest/) Algorithmus von Microsoft verwendet. Sie werden jeweils über die gesamte Menge extrahierter Features für jeden Datensatz trainiert und evaluiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T12:59:27.344348Z",
     "start_time": "2019-02-04T12:59:27.340314Z"
    }
   },
   "outputs": [],
   "source": [
    "# Trains and scores three machines for a single dataset and saves the score to a result table\n",
    "def train_and_score(name, results, X_train, X_test, y_train, y_test):\n",
    "    # SVM training and score\n",
    "    svm_clf = SVC(gamma='auto')\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    results['SVM'][name] = svm_clf.score(X_test, y_test)\n",
    "\n",
    "    # SVM training and score\n",
    "    rf_clf = RandomForestClassifier(n_estimators=300)\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    results['RF'][name] = rf_clf.score(X_test, y_test)\n",
    "    \n",
    "    # SVM training and score\n",
    "    lgb_clf = lgb.LGBMClassifier(n_estimators=300)\n",
    "    lgb_clf.fit(X_train, y_train)\n",
    "    results['LightGBM'][name] = lgb_clf.score(X_test, y_test)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T15:54:03.755388Z",
     "start_time": "2019-02-04T15:39:14.800540Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     SVM        RF  LightGBM\n",
      "Book Summary 1  0.583333  0.740217  0.776087\n",
      "Book Summary 2  0.574557  0.728268  0.813438\n",
      "PAN             0.568365  0.682976  0.695710\n"
     ]
    }
   ],
   "source": [
    "# prepare results table\n",
    "results = pd.DataFrame(\n",
    "    np.zeros((3,3)), \n",
    "    index=['Book Summary 1', 'Book Summary 2', 'PAN'], \n",
    "    columns=['SVM', 'RF', 'LightGBM']\n",
    ")\n",
    "\n",
    "# Baseline for Book Summary 1\n",
    "train_and_score('Book Summary 1', results, *train_test_split(\n",
    "    datasets.load_extracted_features('bs_1'), \n",
    "    datasets.load_book_summary_1().label,\n",
    "    test_size=0.25\n",
    "))\n",
    "\n",
    "# Baseline for Book Summary 2\n",
    "train_and_score('Book Summary 2', results, *train_test_split(\n",
    "    datasets.load_extracted_features('bs_2'), \n",
    "    datasets.load_book_summary_2().label,\n",
    "    test_size=0.25\n",
    "))\n",
    "\n",
    "# Baseline for PAN\n",
    "train_and_score('PAN', results, \n",
    "    datasets.load_extracted_features('pan_training_1'), \n",
    "    datasets.load_extracted_features('pan_validation_1'),\n",
    "    datasets.load_pan_data('training').label,\n",
    "    datasets.load_pan_data('validation').label\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ansatz 1: Bi-direktionale LSTM Netze basierend auf lexikalischen und syntaktischen Merkmalen  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem ersten Ansatz verwenden wir ein Netz aus vier bi-dirktionalen LSTM Schichten (eines für jede Feature Gruppe) gefolgt von zwei vollständig verknüpften Schichten zur Klassifizierung. Die Zeitschritte der LSTM Schicht sind dabei jeweils eine Sequence des Textes, sodass deren temporale Abhängigkeit eine Veränderung der Merkmale im Laufe des Textes kodieren kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentierung von Texten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T16:01:11.640009Z",
     "start_time": "2019-02-04T16:01:11.635226Z"
    }
   },
   "source": [
    "Um zeitliche Veränderungen von Features zu erfassen werden diese jeweils über gleichlange Segmente des Textes berechnet. Die Anzahl der Segmente ist dabei immer gleich. Die Länge varriert also zwsichen Segmenten unterschiedlicher Dokumente nicht aber zwischen den Segmenten eines Dokumentes. Die auf jedem Segment berechneten Features werden durch die Länge der Segmente normiert, sodass diese über Dokumente hinweg vergleichbar sind**[VERWEIS FEATUREBERECHNUNG]**.\n",
    "\n",
    "Die Anzahl der verwendeten Segmente wurde auf vier festgesetzt. Die Wahl basiert auf der Anzahl der vorkommenden Autorenwechsel im PAN Datensatz. Sie macht aber auch Sinn für die Book Summary Datensätze, die zwar nur einen Wechsel haben, der durch Kombination unterschiedlich langer Texte prinzipiell jedoch auch im vorderen oder hinteren Teil des  Gesamttextes liegen kann. Eine höhere Zahl an Abschnitten würde zwar feinere Granularität erlauben aber auch das resultierende Netz ungleich komplexer machen. Die vier Abschnitte scheinen deshlab ein guter Kompromis. Weitere Experimente mit feingranularerer Segmentierung könnten bei der Identifizierung genauer Positionen von Stilbrüchen interessant werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T14:01:45.266542Z",
     "start_time": "2019-02-06T14:01:45.259558Z"
    }
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def split_to_windows(series, windows):\n",
    "    # split into characters\n",
    "    result = series.str.split()\n",
    "    # split char sequences into windows of equal length\n",
    "    result = pd.DataFrame(result.apply(np.array_split, indices_or_sections=windows).tolist())\n",
    "    # join characters per window \n",
    "    result = result.applymap(lambda s: \" \".join(s) )\n",
    "    return result\n",
    "\n",
    "@memory.cache\n",
    "def extract_features_for_windows(series, windows=4, save=True, selected_features=None):\n",
    "    # split into windows\n",
    "    result = split_to_windows(series, windows)\n",
    "    \n",
    "    # run feature extraction per window\n",
    "    columns = result.columns\n",
    "    for col in columns:\n",
    "        features = run_feature_extraction(result[col], False, selected_features=selected_features)\n",
    "        result = pd.concat([result, features], axis=1)\n",
    "        print(result.info())\n",
    "    \n",
    "    # drop text columns\n",
    "    result.drop(columns=columns, axis=1, inplace=True)\n",
    "\n",
    "    # Save the calculated features\n",
    "    if save:\n",
    "        result.to_csv(\n",
    "            path_or_buf = aatm_support.next_file('.//Features//calc_features_with_windows'),\n",
    "            sep = ',', \n",
    "            header = True,\n",
    "            index = True\n",
    "        )\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Helper to reshape the feature data loaded from file to fit one window per timestep\n",
    "def reshape_by_windows(data, windows = 4):\n",
    "    return data.values.reshape((data.shape[0], windows, int(data.shape[1] / windows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufbau des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell besteht im wesentlichen aus vier paralellen Netzen die je eine Feature-Gruppe (Lexikatlische Feature, Character-N-Grams, Word-N-Grams, PoS-N-Grams) als Input erhalten. \n",
    "\n",
    "Jedes der Netze verwendet über die Inputs zunächst eine Batch-Normalization Schicht nach [S. Ioffe und C. Szegedy (2015)](https://arxiv.org/pdf/1502.03167). Die Normalisierung hilft das Lernen bei starken Schwankungen der Verteilung der Inputparameter zu stabilisieren und zu beschleunigen. Vor allem bei den N-Grams sind solche Schwankungen zwischen einzelnen Beispielen zu erwaten.\n",
    "\n",
    "Auf die Normalisierung folgt jeweils ein bi-direktionales LSTM, wobei die Anzahl der Neuronen ggfs. je nach Feature-Gruppe variiert. Die LSTM-Schichten lernen dabei Muster in den Features und Abhängigkeiten dieser Muster zwsichen den einzelnen Textabschnitten. Die LSTM-Schichten verwenden jeweils einen Dropout, um einem Overfitting auf den relativ kleinen Datensätzen entgegenzuwirken. Ebenfalls zu diesem Zweck wird sowohl für die Kernel als auch für die  Verbindungen zwischen den temporalen Schritten des LSTM eine L2 oder _weight decay_ Regularisierung angewandt. Der λ-Parameter wurde dabei experimentell in den einzelnen Netzen optimiert. Als Aktivierungsfunktion der LSTM Netze wurden experimentell Exponential Linear Units (ELU) gewählt [\\[D. Clevert, T. Unterthiner, S. Hochreiter 2015\\]](https://arxiv.org/pdf/1511.07289).\n",
    "\n",
    "Die paralellen Netze werden anschließend wieder zusammengeführt, gefolgt von zwei vollständig vernetzte Schichten, die ebenfalls jeweils mit Dropout und L2 Regularisierung optimiert werden. Zuletzt wird eine einzelnes Neuron mit sigmoider Aktivierungsfunktion zur binären klassifikation verwendet. Als Fehlerfunktion wird die Binary Cross-Entropy verwendet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T14:42:04.670597Z",
     "start_time": "2019-02-06T14:28:25.063Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_multi_input_lstm_model(\n",
    "    input_dims,\n",
    "    settings,\n",
    "    windows = 4\n",
    "):\n",
    "    # We have four inputs. One for each type of feature: \n",
    "    # Lexical Features, Word N-Grams, Character N-Grams, POS N-Grams\n",
    "    lex_input = Input(shape=[windows, input_dims[0]], name='lex_input')   # 4 lexical features\n",
    "    word_input = Input(shape=[windows, input_dims[1]], name='word_input') # most freq. word (1,2,3)-grams\n",
    "    char_input = Input(shape=[windows, input_dims[2]], name='char_input') # most freq. char (1,2,3,4)-grams\n",
    "    pos_input = Input(shape=[windows, input_dims[3]], name='pos_input')   # most freq. pos (1,2,3)-grams\n",
    "    \n",
    "    lex_norm = BatchNormalization(axis=2)(lex_input) \n",
    "    word_norm = BatchNormalization(axis=2)(word_input)\n",
    "    char_norm = BatchNormalization(axis=2)(char_input)\n",
    "    pos_norm = BatchNormalization(axis=2)(pos_input) \n",
    "    \n",
    "    # A LSTM will transform the window sequence into a single vector,\n",
    "    # containing information about the entire sequence of windows\n",
    "    lex_output = Bidirectional(LSTM(\n",
    "        settings['lex.lstm.units'],\n",
    "        dropout=settings['lex.lstm.dropout'],\n",
    "        recurrent_regularizer=regularizers.l2(settings['lex.lstm.reg_recurrent']),\n",
    "        kernel_regularizer=regularizers.l2(settings['lex.lstm.reg_kernel']),\n",
    "        activation='elu'\n",
    "    ))(lex_norm)\n",
    "    word_output = Bidirectional(LSTM(\n",
    "        settings['word.lstm.units'], \n",
    "        dropout=settings['word.lstm.dropout'],\n",
    "        recurrent_regularizer=regularizers.l2(settings['word.lstm.reg_recurrent']),\n",
    "        kernel_regularizer=regularizers.l2(settings['word.lstm.reg_kernel']),\n",
    "        activation='elu'\n",
    "    ))(word_norm)\n",
    "    char_output = Bidirectional(LSTM(\n",
    "        settings['char.lstm.units'], \n",
    "        dropout=settings['char.lstm.dropout'],\n",
    "        recurrent_regularizer=regularizers.l2(settings['char.lstm.reg_recurrent']),\n",
    "        kernel_regularizer=regularizers.l2(settings['char.lstm.reg_kernel']),\n",
    "        activation='elu'\n",
    "    ))(char_norm)\n",
    "    pos_output = Bidirectional(LSTM(\n",
    "        settings['pos.lstm.units'],\n",
    "        dropout=settings['pos.lstm.dropout'],\n",
    "        recurrent_regularizer=regularizers.l2(settings['pos.lstm.reg_recurrent']),\n",
    "        kernel_regularizer=regularizers.l2(settings['pos.lstm.reg_kernel']),\n",
    "        activation='elu'\n",
    "    ))(pos_norm)\n",
    "    \n",
    "    # Next we join the LSTM outputs into a densely connected network\n",
    "    x = concatenate([lex_output, word_output, char_output, pos_output])\n",
    "    \n",
    "    x = Dense(\n",
    "        settings['dense.1.units'],\n",
    "        activation=settings['dense.1.acti'],\n",
    "        kernel_regularizer=regularizers.l2(settings['dense.1.reg_kernel'])\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(settings['dense.1.dropout'])(x)\n",
    "    x = Dense(\n",
    "        settings['dense.2.units'],\n",
    "        activation=settings['dense.2.acti'],\n",
    "        kernel_regularizer=regularizers.l2(settings['dense.2.reg_kernel'])\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(settings['dense.2.dropout'])(x)\n",
    "    \n",
    "    # And finally we add layer for the output\n",
    "    main_output = Dense(1, activation=settings['out.acti'], name='main_output')(x)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[\n",
    "            lex_input,\n",
    "            word_input,\n",
    "            char_input,\n",
    "            pos_input\n",
    "        ], \n",
    "        outputs=[\n",
    "            main_output\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=RMSprop(lr=settings['lr.initial']),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Helper to split window data into correct input shape for the network\n",
    "def get_inputs_for_model(data, input_dims, windows = 4):\n",
    "    # split for inputs\n",
    "    return [\n",
    "        data[:,:,0:input_dims[0]], \n",
    "        data[:,:,input_dims[0]:sum(input_dims[0:2])], \n",
    "        data[:,:,sum(input_dims[0:2]):sum(input_dims[0:3])], \n",
    "        data[:,:,sum(input_dims[0:3]):]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training mit dem Book Summary 2 Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Während die Struktur des Netzes erhalten bleibt, werden für die einzelnen Datensätze die Parameter angepasst. Die hier aufgezeigten Einstellungen entsprechen denen der vorgestellten Modelle. Um konsistente Ergebnisse zu produzieren, werden zur Evaluierung gespeicherte Modelle geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T15:33:31.097408Z",
     "start_time": "2019-02-06T15:11:59.403932Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = datasets.load_book_summary_2()\n",
    "features = datasets.load_extracted_features('with_windows_bs_2')\n",
    "# 821 cols per window\n",
    "# 0:4\n",
    "# 4:216 => 212\n",
    "# 216:589 => 373\n",
    "# 616: => 232\n",
    "input_dims = (4, 212, 373, 232)\n",
    "\n",
    "features = reshape_by_windows(features)\n",
    "\n",
    "# split into test and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, data.label, test_size=0.25, random_state=42)\n",
    "\n",
    "settings = {\n",
    "    'folder': aatm_support.next_file('./logs/4-lstms-merged/run', ''),\n",
    "    'lex.lstm.units': 16,\n",
    "    'lex.lstm.dropout': 0.1,\n",
    "    'lex.lstm.reg_recurrent': 0.01,\n",
    "    'lex.lstm.reg_kernel': 0.01,\n",
    "    'word.lstm.units': 64,\n",
    "    'word.lstm.dropout': 0.1,\n",
    "    'word.lstm.reg_recurrent': 0.01,\n",
    "    'word.lstm.reg_kernel': 0.01,\n",
    "    'char.lstm.units': 64,\n",
    "    'char.lstm.dropout': 0.1,\n",
    "    'char.lstm.reg_recurrent': 0.01,\n",
    "    'char.lstm.reg_kernel': 0.01,\n",
    "    'pos.lstm.units': 64,\n",
    "    'pos.lstm.dropout': 0.1,\n",
    "    'pos.lstm.reg_recurrent': 0.01,\n",
    "    'pos.lstm.reg_kernel': 0.01,\n",
    "    'dense.1.units': 64,\n",
    "    'dense.1.acti': 'elu',\n",
    "    'dense.1.reg_kernel': 0.2,\n",
    "    'dense.1.dropout': 0.3,\n",
    "    'dense.2.units': 32,\n",
    "    'dense.2.acti': 'elu',\n",
    "    'dense.2.reg_kernel': 0.2,\n",
    "    'dense.2.dropout': 0.2,\n",
    "    'out.acti': 'sigmoid',\n",
    "    'lr.initial': 0.001,\n",
    "    'epochs': 50,\n",
    "    'batch_size': 32,\n",
    "    'early_stop.monitor': 'val_loss',\n",
    "    'early_stop.min_delta': 0,\n",
    "    'early_stop.patience': 15\n",
    "}\n",
    "\n",
    "model = build_multi_input_lstm_model(input_dims, settings)\n",
    "\n",
    "model.fit(\n",
    "    get_inputs_for_model(X_train, input_dims),\n",
    "    y_train,\n",
    "    shuffle=True,\n",
    "    batch_size=settings['batch_size'],\n",
    "    epochs=settings['epochs'], \n",
    "    validation_data=(\n",
    "        get_inputs_for_model(X_test, input_dims), \n",
    "        y_test\n",
    "    ),\n",
    "    callbacks=[\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.3,\n",
    "            patience=5, \n",
    "            min_lr=0.0005\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor=settings['early_stop.monitor'], \n",
    "            min_delta=settings['early_stop.min_delta'],\n",
    "            patience=settings['early_stop.patience'],\n",
    "            restore_best_weights=True\n",
    "        ), \n",
    "        TensorBoardLogger(\n",
    "            log_dir=settings['folder'], \n",
    "            histogram_freq=0,\n",
    "            batch_size=settings['batch_size'], \n",
    "            write_graph=False,\n",
    "            settings_str_to_log=json.dumps(settings, ensure_ascii=False)\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zusammenfassung**\n",
    "\n",
    "Das folgende Modell wird für die Evaluierung und Präsentation verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T16:14:23.916799Z",
     "start_time": "2019-02-06T16:13:19.033234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "lex_input (InputLayer)          (None, 4, 4)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_input (InputLayer)         (None, 4, 212)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_input (InputLayer)         (None, 4, 373)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pos_input (InputLayer)          (None, 4, 232)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 4, 4)         16          lex_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 4, 212)       848         word_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 4, 373)       1492        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 232)       928         pos_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_25 (Bidirectional (None, 32)           2688        batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_26 (Bidirectional (None, 128)          141824      batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_27 (Bidirectional (None, 128)          224256      batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_28 (Bidirectional (None, 128)          152064      batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 416)          0           bidirectional_25[0][0]           \n",
      "                                                                 bidirectional_26[0][0]           \n",
      "                                                                 bidirectional_27[0][0]           \n",
      "                                                                 bidirectional_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           26688       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 64)           256         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 64)           0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 32)           2080        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 32)           128         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 32)           0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            33          dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 553,301\n",
      "Trainable params: 551,467\n",
      "Non-trainable params: 1,834\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "load_model('./models/4-lstms-merged/model_1.h5').summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lstm-merged-acc](./img/lstm-merged-acc.png)\n",
    "![lstm-merged-loss](./img/lstm-merged-loss.png)\n",
    "![lstm-merged-val-acc](./img/lstm-merged-val-acc.png)\n",
    "![lstm-merged-val-loss](./img/lstm-merged-val-loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training mit dem PAN Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Während die Struktur des Netzes erhalten bleibt, werden für die einzelnen Datensätze die Parameter angepasst. Die hier aufgezeigten Einstellungen entsprechen denen der vorgestellten Modelle. Um konsistente Ergebnisse zu produzieren, werden zur Evaluierung gespeicherte Modelle geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = datasets.load_pan_data('training')\n",
    "data_val = datasets.load_pan_data('validation')\n",
    "features_train = datasets.load_extracted_features('with_windows_pan_training_2')\n",
    "features_val = datasets.load_extracted_features('with_windows_pan_valiation_2')\n",
    "# 848 cols per window\n",
    "# lex: 0:4 => 4\n",
    "# word: 4:231 => 227\n",
    "# chars: 231:616 => 385\n",
    "# pos: 616: => 232\n",
    "input_dims = (4, 227, 385, 232)\n",
    "\n",
    "features_train = reshape_by_windows(features_train)\n",
    "features_val = reshape_by_windows(features_val)\n",
    "\n",
    "# split into test and training data\n",
    "X_train = features_train \n",
    "X_test = features_val\n",
    "y_train = data_train.label\n",
    "y_test = data_val.label\n",
    "\n",
    "settings = {\n",
    "    'folder': aatm_support.next_file('./logs/4-lstms-merged-pan/run', ''),\n",
    "    'lex.lstm.units': 16,\n",
    "    'lex.lstm.dropout': 0.5,\n",
    "    'lex.lstm.reg_recurrent': 0.3,\n",
    "    'lex.lstm.reg_kernel': 0.2,\n",
    "    'word.lstm.units': 64,\n",
    "    'word.lstm.dropout': 0.5,\n",
    "    'word.lstm.reg_recurrent': 0.3,\n",
    "    'word.lstm.reg_kernel': 0.2,\n",
    "    'char.lstm.units': 64,\n",
    "    'char.lstm.dropout': 0.5,\n",
    "    'char.lstm.reg_recurrent': 0.3,\n",
    "    'char.lstm.reg_kernel': 0.2,\n",
    "    'pos.lstm.units': 64,\n",
    "    'pos.lstm.dropout': 0.5,\n",
    "    'pos.lstm.reg_recurrent': 0.3,\n",
    "    'pos.lstm.reg_kernel': 0.2,\n",
    "    'dense.1.units': 128,\n",
    "    'dense.1.acti': 'elu',\n",
    "    'dense.1.reg_kernel': 0.3,\n",
    "    'dense.1.dropout': 0.5,\n",
    "    'dense.2.units': 64,\n",
    "    'dense.2.acti': 'elu',\n",
    "    'dense.2.reg_kernel': 0.3,\n",
    "    'dense.2.dropout': 0.5,\n",
    "    'out.acti': 'sigmoid',\n",
    "    'lr.initial': 0.005,\n",
    "    'epochs': 50,\n",
    "    'batch_size': 50,\n",
    "    'early_stop.monitor': 'val_loss',\n",
    "    'early_stop.min_delta': 0,\n",
    "    'early_stop.patience': 15\n",
    "}\n",
    "\n",
    "model = build_multi_input_lstm_model(input_dims, settings)\n",
    "\n",
    "model.fit(\n",
    "    get_inputs_for_model(X_train, input_dims),\n",
    "    y_train,\n",
    "    batch_size=settings['batch_size'],\n",
    "    shuffle=True,\n",
    "    epochs=settings['epochs'], \n",
    "    validation_data=(\n",
    "        get_inputs_for_model(X_test, input_dims),\n",
    "        y_test,\n",
    "    ),\n",
    "    callbacks=[\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5, \n",
    "            min_lr=0.0005\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor=settings['early_stop.monitor'], \n",
    "            min_delta=settings['early_stop.min_delta'],\n",
    "            patience=settings['early_stop.patience'],\n",
    "            restore_best_weights=True\n",
    "        ), \n",
    "        TensorBoardLogger(\n",
    "            log_dir=settings['folder'], \n",
    "            histogram_freq=0,\n",
    "            batch_size=settings['batch_size'], \n",
    "            write_graph=False,\n",
    "            settings_str_to_log=json.dumps(settings, ensure_ascii=False)\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zusammenfassung**\n",
    "\n",
    "Das folgende Modell wird für die Evaluierung und Präsentation verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T16:40:01.073255Z",
     "start_time": "2019-02-06T16:38:48.515449Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "lex_input (InputLayer)          (None, 4, 4)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_input (InputLayer)         (None, 4, 227)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_input (InputLayer)         (None, 4, 385)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pos_input (InputLayer)          (None, 4, 232)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 4, 4)         16          lex_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 4, 227)       908         word_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 4, 385)       1540        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 4, 232)       928         pos_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_81 (Bidirectional (None, 32)           2688        batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_82 (Bidirectional (None, 128)          149504      batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_83 (Bidirectional (None, 128)          230400      batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_84 (Bidirectional (None, 128)          152064      batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 416)          0           bidirectional_81[0][0]           \n",
      "                                                                 bidirectional_82[0][0]           \n",
      "                                                                 bidirectional_83[0][0]           \n",
      "                                                                 bidirectional_84[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 128)          53376       concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 128)          512         dense_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 128)          0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 64)           8256        dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 64)           256         dense_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 64)           0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            65          dropout_89[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 600,513\n",
      "Trainable params: 598,433\n",
      "Non-trainable params: 2,080\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "load_model('./models/4-lstms-merged-pan/model_1.h5').summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lstm-merged-pan-acc](./img/lstm-merged-pan-acc.png)\n",
    "![lstm-merged-pan-loss](./img/lstm-merged-pan-loss.png)\n",
    "![lstm-merged-pan-val-acc](./img/lstm-merged-pan-val-acc.png)\n",
    "![lstm-merged-pan-val-loss](./img/lstm-merged-pan-val-loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation der trainierten Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T16:08:53.452198Z",
     "start_time": "2019-02-06T16:08:53.448849Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evalulate_multi_input_lstm(model, data, features, input_dims):\n",
    "    result = model.evaluate(\n",
    "        get_inputs_for_model(reshape_by_windows(features), input_dims), \n",
    "        data.label\n",
    "    )\n",
    "\n",
    "    print('Loss: {:f}'.format(result[0]))\n",
    "    print('Accuracy: {:.2f}%'.format(result[1] * 100))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T16:13:18.758237Z",
     "start_time": "2019-02-06T16:08:53.551290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Summary 1\n",
      "11039/11039 [==============================] - 11s 1ms/step\n",
      "Loss: 0.532000\n",
      "Accuracy: 76.63%\n",
      "\n",
      "\n",
      "\n",
      "Book Summary 2\n",
      "7397/7397 [==============================] - 11s 1ms/step\n",
      "Loss: 0.499192\n",
      "Accuracy: 77.90%\n",
      "\n",
      "\n",
      "\n",
      "PAN\n",
      "1352/1352 [==============================] - 10s 7ms/step\n",
      "Loss: 1.039965\n",
      "Accuracy: 60.80%\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Book Summary 1')\n",
    "evalulate_multi_input_lstm(\n",
    "    load_model('./models/4-lstms-merged/model_1.h5'),\n",
    "    datasets.load_book_summary_1(),\n",
    "    datasets.load_extracted_features('with_windows_bs_1.2'),\n",
    "    input_dims = (4, 212, 373, 232)\n",
    ")\n",
    "print('Book Summary 2')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    datasets.load_extracted_features('with_windows_bs_2'), \n",
    "    datasets.load_book_summary_2(), \n",
    "    test_size=0.25,\n",
    "    random_state=42 # produces consistent result with training splits\n",
    ")\n",
    "\n",
    "evalulate_multi_input_lstm(\n",
    "    load_model('./models/4-lstms-merged/model_1.h5'),\n",
    "    y_test,\n",
    "    X_test,\n",
    "    input_dims = (4, 212, 373, 232)\n",
    ")\n",
    "print('PAN')\n",
    "evalulate_multi_input_lstm(\n",
    "    load_model('./models/4-lstms-merged-pan/model_1.h5'),\n",
    "    datasets.load_pan_data('test'),\n",
    "    datasets.load_extracted_features('with_windows_pan_test_2'),\n",
    "    input_dims = (4, 227, 385, 232)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ansatz 2: Parallele LSTM Netze zum Vergleich temporal gegensätzlicher Stilentwicklungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T18:52:46.152369Z",
     "start_time": "2019-02-04T18:52:46.148695Z"
    }
   },
   "source": [
    "Basierend auf [M. Hosseinia and A. Mukherjee (2018)](http://ceur-ws.org/Vol-2125/paper_91.pdf) werden im zweiten Ansatz zwei paralelle LSTM Netze verwendet. Die Textabschnitte werden jedoch in das eine vorwärts in das andere rückwärts eingespeißt. In den LSTMs werden dann Muster für jeden Abschnitt gelernt, auch in Abhängigkeit der vorherigen Zeitschritte. Die LSTM Netze geben jeweils einen Output pro Unit und Textabshnitt anstatt einem einzigen für den letzten Textabschnitt. Diese Sequenzen werden dann paarweise verglichen, sodass im zum Beispiel der erste Textabschnitt und die dort erkannten Muster oder stilistischen Eigenschaften mit denen im letzten Textabschnitt verglichen werden. Unterscheiden sich der Stil im Laufe der Abschnitte, sollten die resultierenden Sequenzen größere Unterschiede aufweisen, als bei einem konsistenten Text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentierung von Texten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T18:01:14.685338Z",
     "start_time": "2019-02-04T17:56:11.644Z"
    }
   },
   "source": [
    "Die Segmentierung entspricht der aus [Kapitel 5.3.1](#Segmentierung-von-Texten)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufbau des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell besteht aus zwei parallelen Netzenvon denen eines die Textabschnitte in richtiger und das zweite in umgekehrter Reihenfolge als Eingabe erhält. Beide Netze erhalten alle Feature aus allen feature-Gruppe als Eingabe.\n",
    "\n",
    "Jedes der Netze verwendet über die Inputs zunächst wieder eine Batch-Normalization Schicht. Auf die Normalisierung folgt jeweils eine LSTM Schicht. Im Unterschied zum ersten Ansatz kommt wird auch für die Verbindungen zwischen den temporalen Schritten des LSTM ein Dropout angewandt. Als Aktivierungsfunktion der LSTM Netze wurde ein Tangens hyperbolicus (tanh) gewählt. Beide LSTM-Schichten geben eine Sequenz für jeden Zeitschritt aus. Die zweite LSTM-Schicht (x2) geht die Zeitschritte rückwärts durch.\n",
    "\n",
    "Die parallelen Netze werden anschließend wieder zusammengeführt. Im Unterschied zum ersten Ansatz nicht durch Aneinanderhängen der Ausgaben sondern durch eine Kombination aus der paarweisen Kosinus-Ähnlichkeit und dem paarweisen Durchschnitt der Ausgabe. Es folgen ebenfalls zwei vollständig vernetzte Schichten eine einzelnes Neuron mit sigmoider Aktivierungsfunktion zur binären Klassifikation. Als Fehlerfunktion wird die Binary Cross-Entropy verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T15:09:56.325952Z",
     "start_time": "2019-02-07T15:09:56.248941Z"
    }
   },
   "outputs": [],
   "source": [
    "def getFaRLSTM(\n",
    "    n_features,\n",
    "    settings,\n",
    "    windows = 4\n",
    "):\n",
    "    # We have four inputs. One for each type of feature: \n",
    "    # Lexical Features, Word N-Grams, Character N-Grams, POS N-Grams\n",
    "    i = Input(shape=[windows, n_features], name='input')\n",
    "    \n",
    "    x = BatchNormalization(axis=2)(i)\n",
    "    \n",
    "    # A LSTM will transform the window sequence into a single vector,\n",
    "    # containing information about the entire sequence of windows\n",
    "    x1 = LSTM(\n",
    "        settings['forward.lstm.units'],\n",
    "        dropout=settings['forward.lstm.dropout'],\n",
    "        recurrent_dropout=settings['forward.lstm.dropout'],\n",
    "        recurrent_regularizer=regularizers.l2(settings['forward.lstm.reg_recurrent']),\n",
    "        kernel_regularizer=regularizers.l2(settings['forward.lstm.reg_kernel']),\n",
    "        return_sequences=True,\n",
    "        activation='elu'\n",
    "    )(x)\n",
    "    \n",
    "    x2 = LSTM(\n",
    "        settings['backward.lstm.units'],\n",
    "        dropout=settings['backward.lstm.dropout'],\n",
    "        recurrent_dropout=settings['backward.lstm.dropout'],\n",
    "        recurrent_regularizer=regularizers.l2(settings['backward.lstm.reg_recurrent']),\n",
    "        kernel_regularizer=regularizers.l2(settings['backward.lstm.reg_kernel']),\n",
    "        return_sequences=True,\n",
    "        activation='elu',\n",
    "        go_backwards=True\n",
    "    )(x)\n",
    "    \n",
    "    # Next we join the LSTM outputs into a densely connected network\n",
    "    dot = Dot(2, normalize=True)([x1, x2])\n",
    "    avg = Average()([x1,x2])\n",
    "    x = concatenate([dot, avg])\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(\n",
    "        settings['dense.1.units'],\n",
    "        activation=settings['dense.1.acti'],\n",
    "        kernel_regularizer=regularizers.l2(settings['dense.1.reg_kernel'])\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(settings['dense.1.dropout'])(x)\n",
    "    x = Dense(\n",
    "        settings['dense.2.units'],\n",
    "        activation=settings['dense.2.acti'],\n",
    "        kernel_regularizer=regularizers.l2(settings['dense.2.reg_kernel'])\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(settings['dense.2.dropout'])(x)\n",
    "    \n",
    "    # And finally we add a layer for the output\n",
    "    o = Dense(1, activation=settings['out.acti'], name='main_output')(x)\n",
    "    \n",
    "    model = Model(inputs=[i], outputs=[o])\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=RMSprop(lr=settings['lr.initial']),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training auf dem Book Summary 2 Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Während die Struktur des Netzes erhalten bleibt, werden für die einzelnen Datensätze die Parameter angepasst. Die hier aufgezeigten Einstellungen entsprechen denen der vorgestellten Modelle. Um konsistente Ergebnisse zu produzieren, werden zur Evaluierung gespeicherte Modelle geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_book_summary_2()\n",
    "features = datasets.load_extracted_features('with_windows_bs_2')\n",
    "\n",
    "features = reshape_by_windows(features)\n",
    "\n",
    "# split into test and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, data.label, test_size=0.2)\n",
    "\n",
    "settings = {\n",
    "    'folder': aatm_support.next_file('./logs/FaRLSTM-constructed-2/run', ''),\n",
    "    'forward.lstm.units': 32,\n",
    "    'forward.lstm.dropout': 0.2,\n",
    "    'forward.lstm.reg_recurrent': 0.055,\n",
    "    'forward.lstm.reg_kernel': 0.05,\n",
    "    'backward.lstm.units': 32,\n",
    "    'backward.lstm.dropout': 0.2,\n",
    "    'forward.lstm.reg_recurrent': 0.055,\n",
    "    'forward.lstm.reg_kernel': 0.05,\n",
    "    'dense.1.units': 16,\n",
    "    'dense.1.acti': 'elu',\n",
    "    'dense.1.reg_kernel': 0.1,\n",
    "    'dense.1.dropout': 0.2,\n",
    "    'dense.2.units': 8,\n",
    "    'dense.2.acti': 'relu',\n",
    "    'dense.2.reg_kernel': 0.1,\n",
    "    'dense.2.dropout': 0.2,\n",
    "    'out.acti': 'sigmoid',\n",
    "    'lr.initial': 0.002,\n",
    "    'epochs': 100,\n",
    "    'batch_size': 50,\n",
    "    'early_stop.monitor': 'val_loss',\n",
    "    'early_stop.min_delta': 0,\n",
    "    'early_stop.patience': 8\n",
    "}\n",
    "\n",
    "\n",
    "# Build the model\n",
    "n_features = features.shape[2]\n",
    "model = getFaRLSTM(n_features, settings)\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=settings['batch_size'],\n",
    "    shuffle=True,\n",
    "    epochs=settings['epochs'], \n",
    "    validation_data=(\n",
    "        X_test,\n",
    "        y_test,\n",
    "    ),\n",
    "    callbacks=[\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=2, \n",
    "            min_lr=0.0005\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor=settings['early_stop.monitor'], \n",
    "            min_delta=settings['early_stop.min_delta'],\n",
    "            patience=settings['early_stop.patience'],\n",
    "            restore_best_weights=True\n",
    "        ), \n",
    "        TensorBoardLogger(\n",
    "            log_dir=settings['folder'], \n",
    "            histogram_freq=0,\n",
    "            batch_size=settings['batch_size'], \n",
    "            write_graph=False,\n",
    "            settings_str_to_log=json.dumps(settings, ensure_ascii=False)\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zusammenfassung**\n",
    "\n",
    "Das folgende Modell wird für die Evaluierung und Präsentation verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T16:47:08.403561Z",
     "start_time": "2019-02-06T16:46:06.068072Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 4, 821)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 4, 821)       3284        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_63 (LSTM)                  (None, 4, 32)        109312      batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_64 (LSTM)                  (None, 4, 32)        109312      batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_25 (Dot)                    (None, 4, 4)         0           lstm_63[0][0]                    \n",
      "                                                                 lstm_64[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_10 (Average)            (None, 4, 32)        0           lstm_63[0][0]                    \n",
      "                                                                 lstm_64[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 4, 36)        0           dot_25[0][0]                     \n",
      "                                                                 average_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 144)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 16)           2320        flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 16)           64          dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 16)           0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 8)            136         dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8)            32          dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 8)            0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            9           dropout_44[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 224,469\n",
      "Trainable params: 222,779\n",
      "Non-trainable params: 1,690\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "load_model('./models/FaRLSTM-constructed-2/model_0.h5').summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![farlstm-acc](./img/farlstm-acc.png)\n",
    "![farlstm-loss](./img/farlstm-loss.png)\n",
    "![farlstm-val-acc](./img/farlstm-val-acc.png)\n",
    "![farlstm-val-loss](./img/farlstm-val-loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training auf dem PAN Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Während die Struktur des Netzes erhalten bleibt, werden für die einzelnen Datensätze die Parameter angepasst. Die hier aufgezeigten Einstellungen entsprechen denen der vorgestellten Modelle. Um konsistente Ergebnisse zu produzieren, werden zur Evaluierung gespeicherte Modelle geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T17:31:43.641840Z",
     "start_time": "2019-02-07T17:24:55.015677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next available file: ./logs/FaRLSTM/run_33\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 4, 848)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 4, 848)       3392        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_61 (LSTM)                  (None, 4, 8)         27424       batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_62 (LSTM)                  (None, 4, 8)         27424       batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_17 (Dot)                    (None, 4, 4)         0           lstm_61[0][0]                    \n",
      "                                                                 lstm_62[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_17 (Average)            (None, 4, 8)         0           lstm_61[0][0]                    \n",
      "                                                                 lstm_62[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 4, 12)        0           dot_17[0][0]                     \n",
      "                                                                 average_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 48)           0           concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 16)           784         flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 16)           64          dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 16)           0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 8)            136         dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 8)            32          dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 8)            0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            9           dropout_48[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 59,265\n",
      "Trainable params: 57,521\n",
      "Non-trainable params: 1,744\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Fold  0\n",
      "Train on 3576 samples, validate on 896 samples\n",
      "Epoch 1/100\n",
      "3576/3576 [==============================] - 25s 7ms/step - loss: 10.2550 - acc: 0.5081 - val_loss: 2.3520 - val_acc: 0.4955\n",
      "Epoch 2/100\n",
      "3576/3576 [==============================] - 3s 921us/step - loss: 1.5260 - acc: 0.5364 - val_loss: 1.1095 - val_acc: 0.5714\n",
      "Epoch 3/100\n",
      "3576/3576 [==============================] - 3s 906us/step - loss: 0.9909 - acc: 0.5305 - val_loss: 0.8992 - val_acc: 0.5770\n",
      "Epoch 4/100\n",
      "3576/3576 [==============================] - 3s 937us/step - loss: 0.8671 - acc: 0.5534 - val_loss: 0.8184 - val_acc: 0.6071\n",
      "Epoch 5/100\n",
      "3576/3576 [==============================] - 4s 994us/step - loss: 0.8181 - acc: 0.6074 - val_loss: 0.8023 - val_acc: 0.6116\n",
      "Epoch 6/100\n",
      "3576/3576 [==============================] - 4s 1ms/step - loss: 0.8007 - acc: 0.6021 - val_loss: 0.7669 - val_acc: 0.6462\n",
      "Epoch 7/100\n",
      "3576/3576 [==============================] - 4s 999us/step - loss: 0.7833 - acc: 0.6253 - val_loss: 0.7852 - val_acc: 0.6183\n",
      "Epoch 8/100\n",
      "3576/3576 [==============================] - 4s 1ms/step - loss: 0.7719 - acc: 0.6225 - val_loss: 0.7947 - val_acc: 0.6071\n",
      "Epoch 9/100\n",
      "3576/3576 [==============================] - 3s 948us/step - loss: 0.7680 - acc: 0.6250 - val_loss: 0.7840 - val_acc: 0.5882\n",
      "Epoch 10/100\n",
      "3576/3576 [==============================] - 4s 980us/step - loss: 0.7591 - acc: 0.6278 - val_loss: 0.7523 - val_acc: 0.6071\n",
      "Epoch 11/100\n",
      "3576/3576 [==============================] - 4s 995us/step - loss: 0.7476 - acc: 0.6337 - val_loss: 0.7399 - val_acc: 0.6350\n",
      "Epoch 12/100\n",
      "3576/3576 [==============================] - 4s 1ms/step - loss: 0.7491 - acc: 0.6242 - val_loss: 0.7471 - val_acc: 0.6295\n",
      "Epoch 13/100\n",
      "3576/3576 [==============================] - 3s 977us/step - loss: 0.7508 - acc: 0.6261 - val_loss: 0.7394 - val_acc: 0.6049\n",
      "Epoch 14/100\n",
      "3576/3576 [==============================] - 4s 1ms/step - loss: 0.7413 - acc: 0.6376 - val_loss: 0.7326 - val_acc: 0.6272\n",
      "Epoch 15/100\n",
      "3576/3576 [==============================] - 4s 1ms/step - loss: 0.7486 - acc: 0.6272 - val_loss: 0.7547 - val_acc: 0.6105\n",
      "Epoch 16/100\n",
      "3576/3576 [==============================] - 4s 1ms/step - loss: 0.7414 - acc: 0.6353 - val_loss: 0.7269 - val_acc: 0.6362\n",
      "Epoch 17/100\n",
      "3576/3576 [==============================] - 4s 1ms/step - loss: 0.7342 - acc: 0.6351 - val_loss: 0.7521 - val_acc: 0.6161\n",
      "Epoch 18/100\n",
      "3576/3576 [==============================] - 4s 1ms/step - loss: 0.7462 - acc: 0.6323 - val_loss: 0.7276 - val_acc: 0.6406\n",
      "Epoch 19/100\n",
      "3576/3576 [==============================] - 4s 991us/step - loss: 0.7398 - acc: 0.6317 - val_loss: 0.7208 - val_acc: 0.6228\n",
      "Epoch 20/100\n",
      "3576/3576 [==============================] - 4s 1ms/step - loss: 0.7439 - acc: 0.6236 - val_loss: 0.7390 - val_acc: 0.6150\n",
      "Epoch 21/100\n",
      "3576/3576 [==============================] - 4s 1ms/step - loss: 0.7426 - acc: 0.6446 - val_loss: 0.7678 - val_acc: 0.6016\n",
      "Epoch 22/100\n",
      "3576/3576 [==============================] - 4s 1ms/step - loss: 0.7419 - acc: 0.6423 - val_loss: 0.7414 - val_acc: 0.6295\n",
      "Epoch 23/100\n",
      "3576/3576 [==============================] - 4s 1ms/step - loss: 0.7334 - acc: 0.6331 - val_loss: 0.7447 - val_acc: 0.6283\n",
      "Epoch 24/100\n",
      "3576/3576 [==============================] - 4s 1ms/step - loss: 0.7289 - acc: 0.6351 - val_loss: 0.7238 - val_acc: 0.6317\n",
      "\n",
      "Fold  1\n",
      "Train on 3578 samples, validate on 894 samples\n",
      "Epoch 1/100\n",
      "3578/3578 [==============================] - 3s 951us/step - loss: 0.7313 - acc: 0.6397 - val_loss: 0.7275 - val_acc: 0.6309\n",
      "Epoch 2/100\n",
      "3578/3578 [==============================] - 3s 970us/step - loss: 0.7282 - acc: 0.6462 - val_loss: 0.7469 - val_acc: 0.6130\n",
      "Epoch 3/100\n",
      "3578/3578 [==============================] - 4s 999us/step - loss: 0.7292 - acc: 0.6473 - val_loss: 0.7427 - val_acc: 0.6230\n",
      "Epoch 4/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7363 - acc: 0.6428 - val_loss: 0.7574 - val_acc: 0.6063\n",
      "Epoch 5/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7270 - acc: 0.6465 - val_loss: 0.7435 - val_acc: 0.6432\n",
      "Epoch 6/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7356 - acc: 0.6543 - val_loss: 0.7481 - val_acc: 0.6174\n",
      "\n",
      "Fold  2\n",
      "Train on 3578 samples, validate on 894 samples\n",
      "Epoch 1/100\n",
      "3578/3578 [==============================] - 3s 943us/step - loss: 0.7404 - acc: 0.6286 - val_loss: 0.7259 - val_acc: 0.6655\n",
      "Epoch 2/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7334 - acc: 0.6392 - val_loss: 0.7542 - val_acc: 0.6409\n",
      "Epoch 3/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7358 - acc: 0.6599 - val_loss: 0.7075 - val_acc: 0.6544\n",
      "Epoch 4/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7417 - acc: 0.6442 - val_loss: 0.7003 - val_acc: 0.6779\n",
      "Epoch 5/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7401 - acc: 0.6439 - val_loss: 0.6942 - val_acc: 0.6465\n",
      "Epoch 6/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7353 - acc: 0.6448 - val_loss: 0.7093 - val_acc: 0.6812\n",
      "Epoch 7/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7377 - acc: 0.6490 - val_loss: 0.7116 - val_acc: 0.6812\n",
      "Epoch 8/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7369 - acc: 0.6434 - val_loss: 0.7239 - val_acc: 0.6398\n",
      "Epoch 9/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7228 - acc: 0.6395 - val_loss: 0.7285 - val_acc: 0.6521\n",
      "Epoch 10/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7285 - acc: 0.6465 - val_loss: 0.7130 - val_acc: 0.6443\n",
      "\n",
      "Fold  3\n",
      "Train on 3578 samples, validate on 894 samples\n",
      "Epoch 1/100\n",
      "3578/3578 [==============================] - 4s 996us/step - loss: 0.7341 - acc: 0.6358 - val_loss: 0.7081 - val_acc: 0.6790\n",
      "Epoch 2/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7310 - acc: 0.6400 - val_loss: 0.7132 - val_acc: 0.6745\n",
      "Epoch 3/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7307 - acc: 0.6442 - val_loss: 0.7053 - val_acc: 0.6555\n",
      "Epoch 4/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7286 - acc: 0.6414 - val_loss: 0.7119 - val_acc: 0.6499\n",
      "Epoch 5/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7332 - acc: 0.6420 - val_loss: 0.7248 - val_acc: 0.6286\n",
      "Epoch 6/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7312 - acc: 0.6411 - val_loss: 0.7080 - val_acc: 0.6398\n",
      "Epoch 7/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7341 - acc: 0.6523 - val_loss: 0.7010 - val_acc: 0.6566\n",
      "Epoch 8/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7301 - acc: 0.6465 - val_loss: 0.7002 - val_acc: 0.6723\n",
      "Epoch 9/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7323 - acc: 0.6498 - val_loss: 0.6891 - val_acc: 0.6678\n",
      "Epoch 10/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7342 - acc: 0.6481 - val_loss: 0.7061 - val_acc: 0.6711\n",
      "Epoch 11/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7327 - acc: 0.6442 - val_loss: 0.7018 - val_acc: 0.6723\n",
      "Epoch 12/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7305 - acc: 0.6540 - val_loss: 0.7518 - val_acc: 0.6264\n",
      "Epoch 13/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7251 - acc: 0.6596 - val_loss: 0.7275 - val_acc: 0.6421\n",
      "Epoch 14/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7364 - acc: 0.6481 - val_loss: 0.7359 - val_acc: 0.6432\n",
      "\n",
      "Fold  4\n",
      "Train on 3578 samples, validate on 894 samples\n",
      "Epoch 1/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7290 - acc: 0.6420 - val_loss: 0.7114 - val_acc: 0.6342\n",
      "Epoch 2/100\n",
      "3578/3578 [==============================] - 3s 941us/step - loss: 0.7222 - acc: 0.6568 - val_loss: 0.7140 - val_acc: 0.6398\n",
      "Epoch 3/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7241 - acc: 0.6532 - val_loss: 0.7243 - val_acc: 0.6398\n",
      "Epoch 4/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7240 - acc: 0.6484 - val_loss: 0.7210 - val_acc: 0.6600\n",
      "Epoch 5/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7262 - acc: 0.6537 - val_loss: 0.7049 - val_acc: 0.6398\n",
      "Epoch 6/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7194 - acc: 0.6439 - val_loss: 0.7323 - val_acc: 0.6197\n",
      "Epoch 7/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7243 - acc: 0.6554 - val_loss: 0.7272 - val_acc: 0.6409\n",
      "Epoch 8/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7212 - acc: 0.6481 - val_loss: 0.7385 - val_acc: 0.6208\n",
      "Epoch 9/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7184 - acc: 0.6562 - val_loss: 0.7194 - val_acc: 0.6622\n",
      "Epoch 10/100\n",
      "3578/3578 [==============================] - 4s 1ms/step - loss: 0.7246 - acc: 0.6546 - val_loss: 0.7357 - val_acc: 0.6376\n"
     ]
    }
   ],
   "source": [
    "# data_train = datasets.load_pan_data('training')\n",
    "data_val = datasets.load_pan_data('validation')\n",
    "features_train = datasets.load_extracted_features('with_windows_pan_training_2')\n",
    "features_val = datasets.load_extracted_features('with_windows_pan_validation_2')\n",
    "\n",
    "features_train = reshape_by_windows(features_train)\n",
    "features_val = reshape_by_windows(features_val)\n",
    "\n",
    "# combine training and validation set for cross validation\n",
    "# evaluation uses test dataset\n",
    "X_train = np.concatenate((features_train, features_val))\n",
    "y_train = np.concatenate((data_train.label,data_val.label))\n",
    "\n",
    "settings = {\n",
    "    'folds': 5,\n",
    "    'folder': aatm_support.next_file('./logs/FaRLSTM/run', ''),\n",
    "    'forward.lstm.units': 8,\n",
    "    'forward.lstm.dropout': 0.2,\n",
    "    'forward.lstm.reg_recurrent': 0.4,\n",
    "    'forward.lstm.reg_kernel': 0.4,\n",
    "    'backward.lstm.units': 8,\n",
    "    'backward.lstm.dropout': 0.2,\n",
    "    'backward.lstm.reg_recurrent': 0.4,\n",
    "    'backward.lstm.reg_kernel': 0.4,\n",
    "    'dense.1.units': 16,\n",
    "    'dense.1.acti': 'elu',\n",
    "    'dense.1.reg_kernel': 0.1,\n",
    "    'dense.1.dropout': 0.3,\n",
    "    'dense.2.units': 8,\n",
    "    'dense.2.acti': 'elu',\n",
    "    'dense.2.reg_kernel': 0.1,\n",
    "    'dense.2.dropout': 0.3,\n",
    "    'out.acti': 'sigmoid',\n",
    "    'lr.initial': 0.001,\n",
    "    'epochs': 100,\n",
    "    'batch_size': 16,\n",
    "    'early_stop.monitor': 'val_loss',\n",
    "    'early_stop.min_delta': 0,\n",
    "    'early_stop.patience': 5\n",
    "}\n",
    "\n",
    "\n",
    "# Build the model\n",
    "n_features = features_train.shape[2]\n",
    "model = getFaRLSTM(n_features, settings)\n",
    "\n",
    "folds = list(StratifiedKFold(n_splits=settings['folds'], shuffle=True).split(X_train, y_train))\n",
    "\n",
    "# train for each fold\n",
    "for j, (train_idx, test_idx) in enumerate(folds):\n",
    "    print('\\nFold ', j)\n",
    "    X_train_cv = X_train[train_idx]\n",
    "    y_train_cv = y_train[train_idx]\n",
    "    X_test_cv = X_train[test_idx]\n",
    "    y_test_cv = y_train[test_idx]\n",
    "\n",
    "    model.fit(\n",
    "        X_train_cv,\n",
    "        y_train_cv,\n",
    "        batch_size=settings['batch_size'],\n",
    "        shuffle=True,\n",
    "        epochs=settings['epochs'], \n",
    "        validation_data=(\n",
    "            X_test_cv,\n",
    "            y_test_cv,\n",
    "        ),\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor=settings['early_stop.monitor'], \n",
    "                min_delta=settings['early_stop.min_delta'],\n",
    "                patience=settings['early_stop.patience'],\n",
    "                restore_best_weights=(j + 1 == settings['folds'])\n",
    "            ), \n",
    "            TensorBoardLogger(\n",
    "                log_dir=settings['folder'], \n",
    "                histogram_freq=0,\n",
    "                batch_size=settings['batch_size'], \n",
    "                write_graph=False,\n",
    "                settings_str_to_log=json.dumps(settings, ensure_ascii=False)\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zusammenfassung**\n",
    "\n",
    "Das folgende Modell wird für die Evaluierung und Präsentation verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T17:40:21.441437Z",
     "start_time": "2019-02-07T17:38:51.268843Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 4, 848)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 4, 848)       3392        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_61 (LSTM)                  (None, 4, 8)         27424       batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_62 (LSTM)                  (None, 4, 8)         27424       batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_17 (Dot)                    (None, 4, 4)         0           lstm_61[0][0]                    \n",
      "                                                                 lstm_62[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_17 (Average)            (None, 4, 8)         0           lstm_61[0][0]                    \n",
      "                                                                 lstm_62[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 4, 12)        0           dot_17[0][0]                     \n",
      "                                                                 average_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 48)           0           concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 16)           784         flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 16)           64          dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 16)           0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 8)            136         dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 8)            32          dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 8)            0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            9           dropout_48[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 59,265\n",
      "Trainable params: 57,521\n",
      "Non-trainable params: 1,744\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "load_model('./models/FaRLSTM/model_8.h5').summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![farlstm-pan-acc](./img/farlstm-pan-acc.png)\n",
    "![farlstm-pan-loss](./img/farlstm-pan-loss.png)\n",
    "![farlstm-pan-val-acc](./img/farlstm-pan-val-acc.png)\n",
    "![farlstm-pan-val-loss](./img/farlstm-pan-val-loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T18:01:14.690067Z",
     "start_time": "2019-02-04T17:58:23.520Z"
    }
   },
   "source": [
    "#### Evaluierung der trainierten Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T13:52:04.288360Z",
     "start_time": "2019-02-07T13:52:04.279429Z"
    }
   },
   "outputs": [],
   "source": [
    "def evalulate_farlstm(model, data, features):\n",
    "    result = model.evaluate(\n",
    "        reshape_by_windows(features), \n",
    "        data.label\n",
    "    )\n",
    "\n",
    "    print('Loss: {:f}'.format(result[0]))\n",
    "    print('Accuracy: {:.2f}%'.format(result[1] * 100))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T17:48:19.494177Z",
     "start_time": "2019-02-07T17:42:15.600845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Summary 1\n",
      "11039/11039 [==============================] - 19s 2ms/step\n",
      "Loss: 0.599818\n",
      "Accuracy: 75.52%\n",
      "\n",
      "\n",
      "\n",
      "Book Summary 2\n",
      "7397/7397 [==============================] - 17s 2ms/step\n",
      "Loss: 0.511149\n",
      "Accuracy: 80.57%\n",
      "\n",
      "\n",
      "\n",
      "PAN\n",
      "1352/1352 [==============================] - 15s 11ms/step\n",
      "Loss: 0.712533\n",
      "Accuracy: 64.64%\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Book Summary 1')\n",
    "evalulate_farlstm(\n",
    "    load_model('./models/FaRLSTM-constructed-2/model_0.h5'),\n",
    "    datasets.load_book_summary_1(),\n",
    "    datasets.load_extracted_features('with_windows_bs_1.2')\n",
    ")\n",
    "print('Book Summary 2')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    datasets.load_extracted_features('with_windows_bs_2'), \n",
    "    datasets.load_book_summary_2(), \n",
    "    test_size=0.25,\n",
    "    random_state=42 # produces consistent result with training splits\n",
    ")\n",
    "\n",
    "evalulate_farlstm(\n",
    "    load_model('./models/FaRLSTM-constructed-2/model_0.h5'),\n",
    "    y_test,\n",
    "    X_test\n",
    ")\n",
    "print('PAN')\n",
    "evalulate_farlstm(\n",
    "    load_model('./models/FaRLSTM/model_8.h5'),\n",
    "    datasets.load_pan_data('test'),\n",
    "    datasets.load_extracted_features('with_windows_pan_test_2')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ansatz 3: Worteinbettung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bis jetzt wurden die Merkmale immer zuerst festgelegt, berechnet und anschließend in das Modell gegeben. Diese beinhalteten neben konstruierten Merkmalen, wie zum Beispiel die die durchschnittliche Satzlänge, N-Gramme auf Basis von Wörtern, Zeichen und PoS-Tags. Dabei geht jedoch die Struktur des Textes verloren. Im folgenden Abschnitt werden die Modelle auf Worteinbettungen trainiert wie sie in [Kapitel 2.5](#Theorie) beschrieben werden. Dabei wird eine Kombination zwischen einem CNN und einem LSTM verwendet. Weitere Modelle befinden sich im Anhang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:11:02.005489Z",
     "start_time": "2019-02-01T14:11:02.001938Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Diese Methode dient dazu die Texte in die gewünschte Form zu bringen, sodass diese anschließend in ein Modell mit einem führenden Embedding-Layer übergeben werden können. Hierfür wird jeder Texte in ein Array mit Integern überführt, wobei jeder Integer-Wert für ein ganz bestimmtes Wort steht. \n",
    "Für die weiteren Schritte müssen die Längen der Arrays angeglichen werden. Hierfür wird eine gewünschte Länge vorgegeben. Texte die eine geringere Länge aufweisen werden mittels Padding ergänzt, wobei das Array entweder zu Beginn oder am Ende mit 0-Werten ergänzt werden. Texte, die hingegen zu lang waren, werden gekürzt, indem Wörter weggelassen werden. Als Ergebnis erhält man einen Integermatrix mit m Zeilen und n Spalten, wobei m der Anzahl der Texte und n der festgelegten Länge.\n",
    "Anschließend wird das Datenset in Trainings- und Testdaten unterteilt.\"\"\"\n",
    "\n",
    "def prepare_data(tokenizer, serie_texts, labels, max_len=1000, test_size=0.33, random_state=42, max_words=10000):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        tokenizer,\n",
    "        serie_texts: pd.Series with documents, \n",
    "        labels: pd.Series with labels,\n",
    "        max_len: Length of the array per text after padding,\n",
    "        test_size: Size of the test set,\n",
    "        random_state: Random_state\n",
    "        random_state: random_state\n",
    "        max_words: The k most frequent words\n",
    "    Output: Test and train data\n",
    "    Method: Tokenizing, Indexing, Padding and splitting into test and train data\n",
    "    \"\"\"\n",
    "\n",
    "    #Tokenizing and Indexing\n",
    "    sequences = tok.texts_to_sequences(serie_texts)\n",
    "    #Padding to make sure that all the texts has the same lenght\n",
    "    sequences_matrix = sequence.pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "    # Split the dataset into test and training data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(sequences_matrix, labels, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:11:05.426948Z",
     "start_time": "2019-02-01T14:11:05.422031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Draw the accuracy and the loss for the training as well as the validation data\n",
    "def draw_history(history):\n",
    "    \n",
    "    # Accuracies\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.subplot(211)\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    acc_values = acc\n",
    "    val_acc_values = val_acc\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'g', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laden der Datensätze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Booksummary**\n",
    "\n",
    "Die Daten des Booksummaries-Korpus werden geladen und entsprechend aufbereitet. Dazu gehört die Tokenisierung, das Padding und die Aufteilung in Test- und Trainingsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:11:23.666093Z",
     "start_time": "2019-02-01T14:11:22.723160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29588"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the data\n",
    "path_data='.//datasets//constructed_2.csv'\n",
    "\n",
    "# Load the data\n",
    "df_texts=pd.read_csv(path_data,sep=',',header=0, index_col=0)\n",
    "\n",
    "# Documents\n",
    "serie_texts=df_texts.text\n",
    "serie_texts.size\n",
    "\n",
    "# Labels\n",
    "labels=df_texts.label\n",
    "labels.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:11:24.572681Z",
     "start_time": "2019-02-01T14:11:24.570172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Length for padding\n",
    "max_len=1000\n",
    "# Size of the test set\n",
    "test_size=0.33\n",
    "# The most n frequent words\n",
    "max_words=10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:11:38.225181Z",
     "start_time": "2019-02-01T14:11:25.244690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train Tokenizer\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(serie_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:11:50.055865Z",
     "start_time": "2019-02-01T14:11:38.239829Z"
    }
   },
   "outputs": [],
   "source": [
    "# Booksummaries_data as word embeddings\n",
    "X_train, X_test, y_train, y_test = prepare_data(tok,serie_texts=serie_texts,max_len=max_len, labels=df_texts.label,test_size=test_size,max_words=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PAN-Daten**\n",
    "\n",
    "Die Daten des Pan-Korpus werden geladen und entsprechend aufbereitet. Dazu gehört die Tokenisierung, das Padding. Dieser Datensatz bereits in Test-, Trainings- und Validierungsdaten unterteilt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:11:55.367673Z",
     "start_time": "2019-02-01T14:11:52.627957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Dokument m: 2980\n",
      "Anzahl Token n: 1000\n"
     ]
    }
   ],
   "source": [
    "# Pan2018 training data\n",
    "pan_data=datasets.load_pan_data(name = 'training')\n",
    "pan_text=pan_data.text\n",
    "pan_label=pan_data.label\n",
    "\n",
    "#Tokenizing and Indexing\n",
    "pan_text = tok.texts_to_sequences(pan_text)\n",
    "#Padding\n",
    "pan_text = sequence.pad_sequences(pan_text, maxlen=max_len)\n",
    "# Size\n",
    "print(\"Anzahl Dokument m:\",pan_text.shape[0])\n",
    "print(\"Anzahl Token n:\",pan_text.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:12:38.837403Z",
     "start_time": "2019-02-01T14:12:37.552917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Dokument m: 1492\n",
      "Anzahl Token n: 1000\n"
     ]
    }
   ],
   "source": [
    "#Pan2018 validation data\n",
    "val_data = datasets.load_pan_data('validation')\n",
    "val_text=val_data.text\n",
    "val_label=val_data.label\n",
    "\n",
    "#Tokenizing and Indexing\n",
    "val_text = tok.texts_to_sequences(val_text)\n",
    "#Padding\n",
    "val_text = sequence.pad_sequences(val_text, maxlen=max_len)\n",
    "# Size\n",
    "print(\"Anzahl Dokument m:\",val_text.shape[0])\n",
    "print(\"Anzahl Token n:\",val_text.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Dokument m: 1352\n",
      "Anzahl Token n: 1000\n"
     ]
    }
   ],
   "source": [
    "#Pan2018 test data\n",
    "test_data = datasets.load_pan_data('test')\n",
    "test_text=test_data.text\n",
    "test_label=test_data.label\n",
    "\n",
    "#Tokenizing and Indexing\n",
    "test_text = tok.texts_to_sequences(test_text)\n",
    "#Padding\n",
    "test_text = sequence.pad_sequences(test_text, maxlen=max_len)\n",
    "# Size\n",
    "print(\"Anzahl Dokument m:\",test_text.shape[0])\n",
    "print(\"Anzahl Token n:\",test_text.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Dokument m: 4472\n",
      "Anzahl Token n: 1000\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the training and the validiation data to increase the number of training data\n",
    "pan_text=np.concatenate([pan_text,val_text]) \n",
    "pan_label=np.concatenate([pan_label,val_label])\n",
    "print(\"Anzahl Dokument m:\",pan_text.shape[0])\n",
    "print(\"Anzahl Token n:\",pan_text.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN in Kombination mit LSTM auf Basis von Worteinbettungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell besteht aus einem Embedding-, einer Convolutional-, einer LSTM-, sowie einer Dense-Schicht.\n",
    "Als Input wird eine Matrix übergeben, deren Dimensionen der Anzahl der Texte und der Anzahl der Token pro Text entsprechen. Letztere ist mittels Padding auf 1000 normiert worden. Jeder Wert der Matrix entspricht einem Integer-Wert, der wiederum für ein bestimmtes Wort repräsentiert. Die Embedding-Schicht dient dazu, diese Integer-Werte in Vektoren der Dimension 100 umzuwandeln. Welches Wort letztendlich durch welchen Vektor repräsentiert wird, wird wie bei den anderen Schichten im Laufe des Trainings durch das Anpassen der Gewichte mittels Backpropagation optimiert, sodass der Fehler minimiert wird. Alternative Ansätze zur Berechnung der Vektoren sind die Word2Vec-, sowie die GloVe-Methode. Im Gegensatz zu den bisherigen Ansätzen werden die Texte als Ganzes in das Neuronale Netz übergeben.\n",
    "\n",
    "Die Idee eine Faltung der Vektoren durchzuführen, bevor diese an ein LSTM übergeben werden, wird in der Arbeit [\"A C-LSTM Neural Network for Text Classification\"](https://arxiv.org/pdf/1511.08630.pdf) aus dem Jahr 2015 genauer beschrieben. Es sollen die Stärken beider Modelle kombiniert werden. Das CNN ist in der Lage lokale Korrelation durch Anpassung der Gewichte der Filter zu erlernen. Diese werden auf dem gesamten Text gleich angewendet, sodass Parameter eingespart werden können. Durch den Sliding-Window-Ansatz der Filter werden sozusagen N-Gramme aus den Texten extrahiert und durch die Faltung werde diese abstrahiert. Das LSTM ist in der Lage diese abstrahierten Merkmale als Sequenzen zu betrachten und die Änderung der gelernten Merkmale über einen Zeitverlauf betrachten. Zwischen dem CNN und dem LSTM ist eine Max-Pooling-Schicht zwischengeschaltet, die die Dimensionen reduziert.\n",
    "Das Output des LSTMs wird anschließend an eine Dense-Schicht übergeben, bevor die eigentliche Klassifikation durchgeführt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T14:20:08.780427Z",
     "start_time": "2019-02-01T14:20:08.773685Z"
    }
   },
   "outputs": [],
   "source": [
    "def cnn_lstm_model(input_dim, settings):\n",
    "    inputs = Input(name='inputs',shape=[input_dim])\n",
    "    layer =  Embedding(max_words,settings['embedding.units'],input_length=input_dim)(inputs)\n",
    "    \n",
    "    layer = Conv1D(settings['cnn.1.units'], settings['cnn.1.len'], activation=settings['cnn.1.acti'])(layer)\n",
    "    layer = MaxPooling1D(settings['pooling.1.len'])(layer)\n",
    "    \n",
    "    layer = LSTM(settings['lstm.1.units'],dropout=settings['lstm.1.dropout'])(layer)\n",
    "    layer = Dropout(settings['lstm.1.dropout'])(layer)\n",
    "    \n",
    "    layer = Dense(\n",
    "        settings['dense.1.units'], \n",
    "        activation=settings['dense.1.acti'],\n",
    "        kernel_regularizer=regularizers.l2(settings['kernel.regularizer'])\n",
    "    )(layer)\n",
    "    layer = Dense(\n",
    "        settings['dense.1.units'],\n",
    "        activation=settings['dense.1.acti'],\n",
    "        kernel_regularizer=regularizers.l2(settings['kernel.regularizer'])\n",
    "    )(layer)\n",
    "    layer = Dropout(settings['dense.1.dropout'])(layer)\n",
    "    \n",
    "    output = Dense(1, activation=settings['out.acti'], name='main_output')(layer)\n",
    "    \n",
    "    model = Model(inputs, output)\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=RMSprop(lr=settings['lr.initial']),\n",
    "        loss={\n",
    "            'main_output': 'binary_crossentropy',\n",
    "        },\n",
    "        loss_weights={\n",
    "            'main_output': 1., \n",
    "        },\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Vektoren werden in der zweiten Schicht mittels eines eindimensionalen Filters gefaltet. Die Länge des Filters beträgt dabei neun Wörter. Ähnlich wie bei den N-Grammen wird dabei sehr granular vorgegangen, indem der Stride bei eins belassen wird. Es wird kein Padding durchgeführt, wodurch bereits hier eine geringe Dimensionsreduktion stattfindet. Das Output der Faltung entspricht einer abstrahierten Version von N-Grammen der Länge neun. Insgesamt kommen 32 Filter zum Einsatz. Durch das anschließende Max-Pooling der Länge fünf und einem Stride von eins wird die Dimension stark reduziert. Die gelernten Merkmale werden anschließend an eine LSTM-Schicht mit 32 Einheiten übergeben.\n",
    "Um Overfitting zu vermeiden, kommen desweitern Dropout-Schichten, sowie Regularisierungen zum Einsatz. Durch ersteres wird verhindert, dass Neuronen während des Trainings zu starke Abhängigkeiten entwickeln. Mittels Regularisierungen wird hohen Gewichten entgegengewirkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T01:36:49.549030Z",
     "start_time": "2019-02-01T23:39:11.631794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next available file: ./logs/word_embeddings/run_36\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 1000, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 992, 32)           28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 198, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,037,969\n",
      "Trainable params: 1,037,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 19823 samples, validate on 9765 samples\n",
      "Epoch 1/200\n",
      "19823/19823 [==============================] - 364s 18ms/step - loss: 0.9788 - acc: 0.5424 - val_loss: 0.8906 - val_acc: 0.6750\n",
      "Epoch 2/200\n",
      "19823/19823 [==============================] - 320s 16ms/step - loss: 0.7975 - acc: 0.6876 - val_loss: 0.7287 - val_acc: 0.6960\n",
      "Epoch 3/200\n",
      "19823/19823 [==============================] - 332s 17ms/step - loss: 0.6771 - acc: 0.7289 - val_loss: 0.6145 - val_acc: 0.7584\n",
      "Epoch 4/200\n",
      "19823/19823 [==============================] - 341s 17ms/step - loss: 0.5970 - acc: 0.7639 - val_loss: 0.5439 - val_acc: 0.7900\n",
      "Epoch 5/200\n",
      "19823/19823 [==============================] - 312s 16ms/step - loss: 0.5311 - acc: 0.7973 - val_loss: 0.5030 - val_acc: 0.8014\n",
      "Epoch 6/200\n",
      "19823/19823 [==============================] - 304s 15ms/step - loss: 0.4816 - acc: 0.8209 - val_loss: 0.4792 - val_acc: 0.8077\n",
      "Epoch 7/200\n",
      "19823/19823 [==============================] - 308s 16ms/step - loss: 0.4449 - acc: 0.8373 - val_loss: 0.4716 - val_acc: 0.8044\n",
      "Epoch 8/200\n",
      "19823/19823 [==============================] - 331s 17ms/step - loss: 0.4129 - acc: 0.8533 - val_loss: 0.4519 - val_acc: 0.8163\n",
      "Epoch 9/200\n",
      "19823/19823 [==============================] - 326s 16ms/step - loss: 0.3899 - acc: 0.8600 - val_loss: 0.4559 - val_acc: 0.8159\n",
      "Epoch 10/200\n",
      "19823/19823 [==============================] - 325s 16ms/step - loss: 0.3695 - acc: 0.8704 - val_loss: 0.4454 - val_acc: 0.8172\n",
      "Epoch 11/200\n",
      "19823/19823 [==============================] - 327s 16ms/step - loss: 0.3529 - acc: 0.8780 - val_loss: 0.4611 - val_acc: 0.8104\n",
      "Epoch 12/200\n",
      "19823/19823 [==============================] - 326s 16ms/step - loss: 0.3371 - acc: 0.8849 - val_loss: 0.4693 - val_acc: 0.8129\n",
      "Epoch 13/200\n",
      "19823/19823 [==============================] - 326s 16ms/step - loss: 0.3281 - acc: 0.8897 - val_loss: 0.4566 - val_acc: 0.8134\n",
      "Epoch 14/200\n",
      "19823/19823 [==============================] - 330s 17ms/step - loss: 0.3165 - acc: 0.8929 - val_loss: 0.4681 - val_acc: 0.8121\n",
      "Epoch 15/200\n",
      "19823/19823 [==============================] - 331s 17ms/step - loss: 0.3017 - acc: 0.9007 - val_loss: 0.4764 - val_acc: 0.8128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "settings = {\n",
    "    'folder': aatm_support.next_file('./logs/word_embeddings/run', ''),\n",
    "    'embedding.units': embedding_dim,\n",
    "    'cnn.1.units': 32,\n",
    "    'cnn.1.len': 9,\n",
    "    'cnn.1.acti': 'relu',\n",
    "    'pooling.1.len': 5,\n",
    "    'lstm.1.units': 32,\n",
    "    'lstm.1.dropout': 0.2,\n",
    "    'dense.1.units': 16,\n",
    "    'dense.1.acti': 'relu',\n",
    "    'dense.1.dropout': 0.2,\n",
    "    'out.acti': 'sigmoid',\n",
    "    'lr.initial': 0.0001,\n",
    "    'epochs': 200,\n",
    "    'batch_size': 32,\n",
    "    'early_stop.monitor': 'val_loss',\n",
    "    'early_stop.min_delta': 0.001,\n",
    "    'early_stop.patience': 5,\n",
    "    'kernel.regularizer': 0.01\n",
    "}\n",
    "\n",
    "model = cnn_lstm_model(input_dim=X_train.shape[1], settings=settings)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    [\n",
    "        y_train, \n",
    "    ],\n",
    "    batch_size=settings['batch_size'],\n",
    "    epochs=settings['epochs'], \n",
    "    validation_data=(\n",
    "        X_test, \n",
    "        [\n",
    "            y_test, \n",
    "        ],\n",
    "    ),\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor=settings['early_stop.monitor'], \n",
    "            min_delta=settings['early_stop.min_delta'],\n",
    "            patience=settings['early_stop.patience']\n",
    "        ), \n",
    "        TensorBoardLogger(\n",
    "            log_dir=settings['folder'], \n",
    "            histogram_freq=0,\n",
    "            batch_size=settings['batch_size'], \n",
    "            write_graph=False,\n",
    "            settings_str_to_log=json.dumps(settings, ensure_ascii=False)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "draw_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T01:36:50.655481Z",
     "start_time": "2019-02-02T01:36:49.551902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next available file: ./models/Embedded_models/embedded_cnn_lstm/model_1.h5\n"
     ]
    }
   ],
   "source": [
    "# Run this to save a model after training\n",
    "model.save(aatm_support.next_file('./models/Embedded_models/embedded_cnn_lstm/model', '.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T01:36:57.506696Z",
     "start_time": "2019-02-02T01:36:50.657615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 53.55%\n"
     ]
    }
   ],
   "source": [
    "# Test model on pan2018 data\n",
    "scores = model.evaluate(val_text, val_label, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN in Kombination mit LSTM auf Basis von vortrainierten Worteinbettungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da das Erlernen der Worteinbettungen die Anzahl der Parameter extrem erhöht und nur eine geringe Anzahl an Trainingsdaten vorliegt, wird im Folgenden versucht bereits vortrainierte Gewichte zu nutzen. Diese basieren auf dem [GloVe-Ansatz](https://nlp.stanford.edu/projects/glove/) und wurden auf Wikipedia und Gigaword 5 erlernt. Diese repräsentieren 400000 Wörter. Die Dimensionen der Vektoren betragen wie bereits beim vorherigen Ansatz 100. Zuerst müssen diese jedoch in die richtige Form gebracht werden, sodass sie an die Embedding-Schicht übergeben werden können. Diese Schicht wird dann für das spätere Training eingefroren, sodass sich die Gewichte nicht mehr anpassen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T09:21:34.880383Z",
     "start_time": "2019-02-02T09:21:24.836735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Get Glove weights\n",
    "glove_dir = './/glove.6B'\n",
    "\n",
    "embeddings_index = {}\n",
    "# Read the data and split word and weights\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'),'r', encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T09:27:34.010653Z",
     "start_time": "2019-02-02T09:27:19.133461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n",
       "         0.82779998,  0.27061999],\n",
       "       [-0.18970001,  0.050024  ,  0.19084001, ..., -0.39804   ,\n",
       "         0.47646999, -0.15983   ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.50269002,  0.056798  ,  0.21261001, ...,  0.085045  ,\n",
       "         0.60573   , -0.73576999],\n",
       "       [ 0.70137   , -0.51065999,  0.16745   , ...,  0.57358998,\n",
       "        -0.15755001, -0.23511   ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build embedding matrix\n",
    "embedding_dim = 100\n",
    "word_index=tok.word_index\n",
    "# Matrix with the needed Dimensions\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die restlichen Parameter wurden bei den selben Werten belassen, sodass eine Vergleichbarkeit mit dem vorherigen Modell gegeben ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T12:01:23.900335Z",
     "start_time": "2019-02-02T09:45:29.965731Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next available file: ./logs/word_embeddings/run_34\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 1000, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 992, 32)           28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 198, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,037,969\n",
      "Trainable params: 1,037,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 19823 samples, validate on 9765 samples\n",
      "Epoch 1/200\n",
      "19823/19823 [==============================] - 285s 14ms/step - loss: 0.9959 - acc: 0.5021 - val_loss: 0.9326 - val_acc: 0.5183\n",
      "Epoch 2/200\n",
      "19823/19823 [==============================] - 287s 14ms/step - loss: 0.8816 - acc: 0.5087 - val_loss: 0.8348 - val_acc: 0.5062\n",
      "Epoch 3/200\n",
      "19823/19823 [==============================] - 290s 15ms/step - loss: 0.8006 - acc: 0.4993 - val_loss: 0.7696 - val_acc: 0.5253\n",
      "Epoch 4/200\n",
      "19823/19823 [==============================] - 266s 13ms/step - loss: 0.7480 - acc: 0.5149 - val_loss: 0.7287 - val_acc: 0.5884\n",
      "Epoch 5/200\n",
      "19823/19823 [==============================] - 258s 13ms/step - loss: 0.7185 - acc: 0.5424 - val_loss: 0.7045 - val_acc: 0.6435\n",
      "Epoch 6/200\n",
      "19823/19823 [==============================] - 259s 13ms/step - loss: 0.6971 - acc: 0.6017 - val_loss: 0.6642 - val_acc: 0.6853\n",
      "Epoch 7/200\n",
      "19823/19823 [==============================] - 259s 13ms/step - loss: 0.6604 - acc: 0.6626 - val_loss: 0.6417 - val_acc: 0.6777\n",
      "Epoch 8/200\n",
      "19823/19823 [==============================] - 259s 13ms/step - loss: 0.6296 - acc: 0.6844 - val_loss: 0.6148 - val_acc: 0.6913\n",
      "Epoch 9/200\n",
      "19823/19823 [==============================] - 258s 13ms/step - loss: 0.6132 - acc: 0.6955 - val_loss: 0.6071 - val_acc: 0.6893\n",
      "Epoch 10/200\n",
      "19823/19823 [==============================] - 259s 13ms/step - loss: 0.6004 - acc: 0.7083 - val_loss: 0.5950 - val_acc: 0.7036\n",
      "Epoch 11/200\n",
      "19823/19823 [==============================] - 258s 13ms/step - loss: 0.5873 - acc: 0.7181 - val_loss: 0.5913 - val_acc: 0.7041\n",
      "Epoch 12/200\n",
      "19823/19823 [==============================] - 258s 13ms/step - loss: 0.5822 - acc: 0.7206 - val_loss: 0.6059 - val_acc: 0.6916\n",
      "Epoch 13/200\n",
      "19823/19823 [==============================] - 258s 13ms/step - loss: 0.5760 - acc: 0.7292 - val_loss: 0.5848 - val_acc: 0.7126\n",
      "Epoch 14/200\n",
      "19823/19823 [==============================] - 259s 13ms/step - loss: 0.5680 - acc: 0.7312 - val_loss: 0.5524 - val_acc: 0.7319\n",
      "Epoch 15/200\n",
      "19823/19823 [==============================] - 258s 13ms/step - loss: 0.5598 - acc: 0.7349 - val_loss: 0.5381 - val_acc: 0.7422\n",
      "Epoch 16/200\n",
      "19823/19823 [==============================] - 298s 15ms/step - loss: 0.5514 - acc: 0.7404 - val_loss: 0.5640 - val_acc: 0.7262\n",
      "Epoch 17/200\n",
      "19823/19823 [==============================] - 269s 14ms/step - loss: 0.5480 - acc: 0.7461 - val_loss: 0.5229 - val_acc: 0.7604\n",
      "Epoch 18/200\n",
      "19823/19823 [==============================] - 263s 13ms/step - loss: 0.5349 - acc: 0.7575 - val_loss: 0.5352 - val_acc: 0.7509\n",
      "Epoch 19/200\n",
      "19823/19823 [==============================] - 262s 13ms/step - loss: 0.5305 - acc: 0.7575 - val_loss: 0.5017 - val_acc: 0.7760\n",
      "Epoch 20/200\n",
      "19823/19823 [==============================] - 270s 14ms/step - loss: 0.5238 - acc: 0.7592 - val_loss: 0.5429 - val_acc: 0.7437\n",
      "Epoch 21/200\n",
      "19823/19823 [==============================] - 260s 13ms/step - loss: 0.5161 - acc: 0.7661 - val_loss: 0.5091 - val_acc: 0.7719\n",
      "Epoch 22/200\n",
      "19823/19823 [==============================] - 276s 14ms/step - loss: 0.5043 - acc: 0.7767 - val_loss: 0.5186 - val_acc: 0.7606\n",
      "Epoch 23/200\n",
      "19823/19823 [==============================] - 267s 13ms/step - loss: 0.4980 - acc: 0.7816 - val_loss: 0.4802 - val_acc: 0.7873\n",
      "Epoch 24/200\n",
      "19823/19823 [==============================] - 271s 14ms/step - loss: 0.4939 - acc: 0.7806 - val_loss: 0.5489 - val_acc: 0.7447\n",
      "Epoch 25/200\n",
      "19823/19823 [==============================] - 280s 14ms/step - loss: 0.4834 - acc: 0.7904 - val_loss: 0.5114 - val_acc: 0.7732\n",
      "Epoch 26/200\n",
      "19823/19823 [==============================] - 296s 15ms/step - loss: 0.4824 - acc: 0.7922 - val_loss: 0.4675 - val_acc: 0.7947\n",
      "Epoch 27/200\n",
      "19823/19823 [==============================] - 281s 14ms/step - loss: 0.4741 - acc: 0.7963 - val_loss: 0.4803 - val_acc: 0.7860\n",
      "Epoch 28/200\n",
      "19823/19823 [==============================] - 287s 14ms/step - loss: 0.4664 - acc: 0.8001 - val_loss: 0.4576 - val_acc: 0.7948\n",
      "Epoch 29/200\n",
      "19823/19823 [==============================] - 293s 15ms/step - loss: 0.4581 - acc: 0.8049 - val_loss: 0.4651 - val_acc: 0.7867\n",
      "Epoch 30/200\n",
      "19823/19823 [==============================] - 298s 15ms/step - loss: 0.4519 - acc: 0.8089 - val_loss: 0.4518 - val_acc: 0.7987\n",
      "Epoch 31/200\n",
      "19823/19823 [==============================] - 275s 14ms/step - loss: 0.4435 - acc: 0.8141 - val_loss: 0.5064 - val_acc: 0.7730\n",
      "Epoch 32/200\n",
      "19823/19823 [==============================] - 271s 14ms/step - loss: 0.4376 - acc: 0.8191 - val_loss: 0.4504 - val_acc: 0.8039\n",
      "Epoch 33/200\n",
      "19823/19823 [==============================] - 272s 14ms/step - loss: 0.4334 - acc: 0.8216 - val_loss: 0.4448 - val_acc: 0.8120\n",
      "Epoch 34/200\n",
      "19823/19823 [==============================] - 276s 14ms/step - loss: 0.4239 - acc: 0.8261 - val_loss: 0.4418 - val_acc: 0.8092\n",
      "Epoch 35/200\n",
      "19823/19823 [==============================] - 271s 14ms/step - loss: 0.4185 - acc: 0.8295 - val_loss: 0.4590 - val_acc: 0.7997\n",
      "Epoch 36/200\n",
      "19823/19823 [==============================] - 274s 14ms/step - loss: 0.4105 - acc: 0.8347 - val_loss: 0.4515 - val_acc: 0.8024\n",
      "Epoch 37/200\n",
      "19823/19823 [==============================] - 272s 14ms/step - loss: 0.4047 - acc: 0.8402 - val_loss: 0.4323 - val_acc: 0.8162\n",
      "Epoch 38/200\n",
      "19823/19823 [==============================] - 282s 14ms/step - loss: 0.3971 - acc: 0.8430 - val_loss: 0.4365 - val_acc: 0.8137\n",
      "Epoch 39/200\n",
      "19823/19823 [==============================] - 297s 15ms/step - loss: 0.3869 - acc: 0.8490 - val_loss: 0.4458 - val_acc: 0.8050\n",
      "Epoch 40/200\n",
      "19823/19823 [==============================] - 293s 15ms/step - loss: 0.3858 - acc: 0.8477 - val_loss: 0.4273 - val_acc: 0.8203\n",
      "Epoch 41/200\n",
      "19823/19823 [==============================] - 295s 15ms/step - loss: 0.3774 - acc: 0.8535 - val_loss: 0.5277 - val_acc: 0.7680\n",
      "Epoch 42/200\n",
      "19823/19823 [==============================] - 315s 16ms/step - loss: 0.3707 - acc: 0.8565 - val_loss: 0.4823 - val_acc: 0.7959\n",
      "Epoch 43/200\n",
      "19823/19823 [==============================] - 288s 15ms/step - loss: 0.3685 - acc: 0.8580 - val_loss: 0.4230 - val_acc: 0.8204\n",
      "Epoch 44/200\n",
      "19823/19823 [==============================] - 297s 15ms/step - loss: 0.3619 - acc: 0.8596 - val_loss: 0.4269 - val_acc: 0.8248\n",
      "Epoch 45/200\n",
      "19823/19823 [==============================] - 292s 15ms/step - loss: 0.3522 - acc: 0.8680 - val_loss: 0.4337 - val_acc: 0.8196\n",
      "Epoch 46/200\n",
      "19823/19823 [==============================] - 263s 13ms/step - loss: 0.3492 - acc: 0.8661 - val_loss: 0.4219 - val_acc: 0.8261\n",
      "Epoch 47/200\n",
      "19823/19823 [==============================] - 334s 17ms/step - loss: 0.3415 - acc: 0.8717 - val_loss: 0.4342 - val_acc: 0.8226\n",
      "Epoch 48/200\n",
      "19823/19823 [==============================] - 290s 15ms/step - loss: 0.3410 - acc: 0.8717 - val_loss: 0.4457 - val_acc: 0.8179\n",
      "Epoch 49/200\n",
      "19823/19823 [==============================] - 286s 14ms/step - loss: 0.3389 - acc: 0.8730 - val_loss: 0.4318 - val_acc: 0.8237\n",
      "Epoch 50/200\n",
      "19823/19823 [==============================] - 286s 14ms/step - loss: 0.3246 - acc: 0.8803 - val_loss: 0.4449 - val_acc: 0.8164\n",
      "Epoch 51/200\n",
      "19823/19823 [==============================] - 303s 15ms/step - loss: 0.3206 - acc: 0.8831 - val_loss: 0.4251 - val_acc: 0.8271\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "settings = {\n",
    "    'folder': aatm_support.next_file('./logs/word_embeddings/run', ''),\n",
    "    'embedding.units': embedding_dim,\n",
    "    'cnn.1.units': 32,\n",
    "    'cnn.1.len': 9,\n",
    "    'cnn.1.acti': 'relu',\n",
    "    'pooling.1.len': 5,\n",
    "    'lstm.1.units': 32,\n",
    "    'lstm.1.dropout': 0.2,\n",
    "    'dense.1.units': 16,\n",
    "    'dense.1.acti': 'relu',\n",
    "    'dense.1.dropout': 0.2,\n",
    "    'out.acti': 'sigmoid',\n",
    "    'lr.initial': 0.0001,\n",
    "    'epochs': 200,\n",
    "    'batch_size': 32,\n",
    "    'early_stop.monitor': 'val_loss',\n",
    "    'early_stop.min_delta': 0.001,\n",
    "    'early_stop.patience': 5,\n",
    "    'kernel.regularizer': 0.01\n",
    "}\n",
    "\n",
    "model = cnn_lstm_model(input_dim=X_train.shape[1], settings=settings)\n",
    "\n",
    "#Freeze layer\n",
    "model.layers[1].set_weights([embedding_matrix])\n",
    "model.layers[1].trainable=False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=RMSprop(lr=settings['lr.initial']),\n",
    "    loss={\n",
    "        'main_output': 'binary_crossentropy',\n",
    "    },\n",
    "    loss_weights={\n",
    "        'main_output': 1., \n",
    "    },\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    [\n",
    "        y_train, \n",
    "    ],\n",
    "    batch_size=settings['batch_size'],\n",
    "    epochs=settings['epochs'], \n",
    "    validation_data=(\n",
    "        X_test, \n",
    "        [\n",
    "            y_test, \n",
    "        ],\n",
    "    ),\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor=settings['early_stop.monitor'], \n",
    "            min_delta=settings['early_stop.min_delta'],\n",
    "            patience=settings['early_stop.patience']\n",
    "        ), \n",
    "        TensorBoardLogger(\n",
    "            log_dir=settings['folder'], \n",
    "            histogram_freq=0,\n",
    "            batch_size=settings['batch_size'], \n",
    "            write_graph=False,\n",
    "            settings_str_to_log=json.dumps(settings, ensure_ascii=False)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "draw_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T12:18:19.570385Z",
     "start_time": "2019-02-02T12:18:17.323813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next available file: ./models/Embedded_models/pretrained_embedded_cnn_lstm/model_1.h5\n"
     ]
    }
   ],
   "source": [
    "# Run this to save a model after training\n",
    "model.save(aatm_support.next_file('./models/Embedded_models/pretrained_embedded_cnn_lstm/model', '.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T12:23:50.090190Z",
     "start_time": "2019-02-02T12:23:44.014956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 54.69%\n"
     ]
    }
   ],
   "source": [
    "# Test model on pan2018 data\n",
    "scores = model.evaluate(val_text, val_label, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit bereits vortrainierten Gewichten konnte keine aussagekräftige Verbesserung erzielt werden. Auch mit 300-dimensionalen Vektoren war dies nicht möglich. Ein weiterer Ansatz wäre das Word2Vec- oder den GloVe-Modell speziell auf dem Booksummary Datensatz zu trainieren. Dies war in der vorliegenden Arbeit aus zeitlichen Gründen jedoch nicht mehr möglich."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN in Kombination mit LSTM trainiert auf dem PAN-Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zwar konnten mit den vorherigen Ansätzen Modelle trainiert werden, die auf dem Booksummary-Datensatz eine Genauigkeit von über 80% erreichen, jedoch können diese nicht auf den PAN-Datensatz übertragen werden. Dort erreichen sie lediglich knapp über 50%. Daher wird das CNN-LSTM-Modell hier mit leicht angepassten Parametern auf dem PAN-Datensatz trainiert. Statt einer Filterlänge von 9 wird eine Länge von 32 verwendet. Dadurch kann auf dem PAN-Datensatz immerhin eine Genauigkeit von knapp 65% erzielt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next available file: ./logs/word_embeddings/run_25\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 1000, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 969, 32)           102432    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 193, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,111,569\n",
      "Trainable params: 1,111,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4472 samples, validate on 1352 samples\n",
      "Epoch 1/200\n",
      "4472/4472 [==============================] - 169s 38ms/step - loss: 1.0479 - acc: 0.4946 - val_loss: 1.0284 - val_acc: 0.5074\n",
      "Epoch 2/200\n",
      "4472/4472 [==============================] - 166s 37ms/step - loss: 1.0103 - acc: 0.5065 - val_loss: 0.9926 - val_acc: 0.5059\n",
      "Epoch 3/200\n",
      "4472/4472 [==============================] - 178s 40ms/step - loss: 0.9761 - acc: 0.4886 - val_loss: 0.9594 - val_acc: 0.5000\n",
      "Epoch 4/200\n",
      "4472/4472 [==============================] - 161s 36ms/step - loss: 0.9440 - acc: 0.5051 - val_loss: 0.9288 - val_acc: 0.5007\n",
      "Epoch 5/200\n",
      "4472/4472 [==============================] - 171s 38ms/step - loss: 0.9147 - acc: 0.4984 - val_loss: 0.9005 - val_acc: 0.5030\n",
      "Epoch 6/200\n",
      "4472/4472 [==============================] - 166s 37ms/step - loss: 0.8873 - acc: 0.5101 - val_loss: 0.8746 - val_acc: 0.5007\n",
      "Epoch 7/200\n",
      "4472/4472 [==============================] - 163s 37ms/step - loss: 0.8627 - acc: 0.5083 - val_loss: 0.8511 - val_acc: 0.5044\n",
      "Epoch 8/200\n",
      "4472/4472 [==============================] - 165s 37ms/step - loss: 0.8403 - acc: 0.5114 - val_loss: 0.8298 - val_acc: 0.5074\n",
      "Epoch 9/200\n",
      "4472/4472 [==============================] - 160s 36ms/step - loss: 0.8197 - acc: 0.5186 - val_loss: 0.8104 - val_acc: 0.4970\n",
      "Epoch 10/200\n",
      "4472/4472 [==============================] - 161s 36ms/step - loss: 0.8015 - acc: 0.5174 - val_loss: 0.7931 - val_acc: 0.5000\n",
      "Epoch 11/200\n",
      "4472/4472 [==============================] - 161s 36ms/step - loss: 0.7852 - acc: 0.5161 - val_loss: 0.7776 - val_acc: 0.5007\n",
      "Epoch 12/200\n",
      "4472/4472 [==============================] - 163s 36ms/step - loss: 0.7703 - acc: 0.5239 - val_loss: 0.7638 - val_acc: 0.5000\n",
      "Epoch 13/200\n",
      "4472/4472 [==============================] - 170s 38ms/step - loss: 0.7573 - acc: 0.5275 - val_loss: 0.7516 - val_acc: 0.5059\n",
      "Epoch 14/200\n",
      "4472/4472 [==============================] - 164s 37ms/step - loss: 0.7458 - acc: 0.5255 - val_loss: 0.7411 - val_acc: 0.5067\n",
      "Epoch 15/200\n",
      "4472/4472 [==============================] - 156s 35ms/step - loss: 0.7358 - acc: 0.5546 - val_loss: 0.7320 - val_acc: 0.5126\n",
      "Epoch 16/200\n",
      "4472/4472 [==============================] - 158s 35ms/step - loss: 0.7271 - acc: 0.5671 - val_loss: 0.7243 - val_acc: 0.5340\n",
      "Epoch 17/200\n",
      "4472/4472 [==============================] - 164s 37ms/step - loss: 0.7192 - acc: 0.5832 - val_loss: 0.7178 - val_acc: 0.5274\n",
      "Epoch 18/200\n",
      "4472/4472 [==============================] - 161s 36ms/step - loss: 0.7120 - acc: 0.6058 - val_loss: 0.7124 - val_acc: 0.5237\n",
      "Epoch 19/200\n",
      "4472/4472 [==============================] - 160s 36ms/step - loss: 0.7030 - acc: 0.6297 - val_loss: 0.7050 - val_acc: 0.5407\n",
      "Epoch 20/200\n",
      "4472/4472 [==============================] - 165s 37ms/step - loss: 0.6864 - acc: 0.6715 - val_loss: 0.6907 - val_acc: 0.6280\n",
      "Epoch 21/200\n",
      "4472/4472 [==============================] - 170s 38ms/step - loss: 0.6654 - acc: 0.7153 - val_loss: 0.6791 - val_acc: 0.6391\n",
      "Epoch 22/200\n",
      "4472/4472 [==============================] - 177s 40ms/step - loss: 0.6417 - acc: 0.7475 - val_loss: 0.6689 - val_acc: 0.6487\n",
      "Epoch 23/200\n",
      "4472/4472 [==============================] - 171s 38ms/step - loss: 0.6166 - acc: 0.7661 - val_loss: 0.6657 - val_acc: 0.6546\n",
      "Epoch 24/200\n",
      "4472/4472 [==============================] - 172s 38ms/step - loss: 0.5927 - acc: 0.7840 - val_loss: 0.6630 - val_acc: 0.6435\n",
      "Epoch 25/200\n",
      "4472/4472 [==============================] - 172s 39ms/step - loss: 0.5628 - acc: 0.8108 - val_loss: 0.6733 - val_acc: 0.6287\n",
      "Epoch 26/200\n",
      "4472/4472 [==============================] - 177s 40ms/step - loss: 0.5357 - acc: 0.8216 - val_loss: 0.6772 - val_acc: 0.6391\n",
      "Epoch 27/200\n",
      "4472/4472 [==============================] - 169s 38ms/step - loss: 0.5158 - acc: 0.8372 - val_loss: 0.6736 - val_acc: 0.6487\n",
      "Epoch 28/200\n",
      "4472/4472 [==============================] - 177s 40ms/step - loss: 0.4974 - acc: 0.8468 - val_loss: 0.7105 - val_acc: 0.6346\n",
      "Epoch 29/200\n",
      "4472/4472 [==============================] - 171s 38ms/step - loss: 0.4738 - acc: 0.8551 - val_loss: 0.6856 - val_acc: 0.6280\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "settings = {\n",
    "    'folder': aatm_support.next_file('./logs/word_embeddings/run', ''),\n",
    "    'embedding.units': 100,\n",
    "    'cnn.1.units': 32,\n",
    "    'cnn.1.len': 32,\n",
    "    'cnn.1.acti': 'relu',\n",
    "    'pooling.1.len': 5,\n",
    "    'lstm.1.units': 32,\n",
    "    'lstm.1.dropout': 0.4,\n",
    "    'dense.1.units': 16,\n",
    "    'dense.1.acti': 'relu',\n",
    "    'dense.1.dropout': 0.4,\n",
    "    'out.acti': 'sigmoid',\n",
    "    'lr.initial': 0.0001,\n",
    "    'epochs': 200,\n",
    "    'batch_size': 32,\n",
    "    'early_stop.monitor': 'val_loss',\n",
    "    'early_stop.min_delta': 0.001,\n",
    "    'early_stop.patience': 5,\n",
    "    'kernel.regularizer': 0.01\n",
    "}\n",
    "\n",
    "model = cnn_lstm_model(input_dim=pan_text.shape[1], settings=settings)\n",
    "\n",
    "history = model.fit(\n",
    "    pan_text,\n",
    "    [\n",
    "        pan_label, \n",
    "    ],\n",
    "    batch_size=settings['batch_size'],\n",
    "    epochs=settings['epochs'], \n",
    "    validation_data=(\n",
    "        test_text, \n",
    "        [\n",
    "            test_label, \n",
    "        ],\n",
    "    ),\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor=settings['early_stop.monitor'], \n",
    "            min_delta=settings['early_stop.min_delta'],\n",
    "            patience=settings['early_stop.patience']\n",
    "        ), \n",
    "        TensorBoardLogger(\n",
    "            log_dir=settings['folder'], \n",
    "            histogram_freq=0,\n",
    "            batch_size=settings['batch_size'], \n",
    "            write_graph=False,\n",
    "            settings_str_to_log=json.dumps(settings, ensure_ascii=False)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "draw_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next available file: ./models/Embedded_models/pan_embedding_cnn_lstm/model_1.h5\n"
     ]
    }
   ],
   "source": [
    "# Run this to save a model after training\n",
    "model.save(aatm_support.next_file('./models/Embedded_models/pan_embedding_cnn_lstm/model', '.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wurden neben den drei Modellen der Baseline drei eigene Modelle vorgestellt auf jeweils zwei Datesätzen (Book Summary 2 & PAN) trainiert und auf je drei Datensätzen (Book Summary 1, 2 & PAN) evaluiert.\n",
    "\n",
    "**Genauigkeit der Modelle auf den Datzensätzen in Prozent (%)**\n",
    "\n",
    "| Datensatz      | SVM | RF  | LightGBM | A1) LSTM pro Feature Gruppe | A2) Parallele LSTM    | A3) CNN + LSTM |\n",
    "|----------------|-----|-----|----------|-------------------------|-------------------|------------|\n",
    "| Book Summary 1 | 58% | 74% | **78%**  | 77%*                    | 76%*              | -          |\n",
    "| Book Summary 2 | 57% | 73% | **81%**  | 78%                     | **81%**           | **81%**    |\n",
    "| PAN            | 57% | 68% | **70%**  | 61%                     | 65%               | 65%        |\n",
    "\n",
    "_\\*Die Ergebnisse wurden für den Book Summary 1 Datensatz mit den jeweils auf Book Summary 2 trainierten Modellen erreicht_\n",
    "\n",
    "Für alle drei Datensätze sind die Ergebnisse des nicht optimierten LightGBM führend. Für den Book Summary 2 Datensatz konnten mit dem zweiten Ansatz der parallelen LSTM die Textabschnitte vorwärts und rückwärts als Eingabe bekommen haben und mit der Kombination aus CNN und LSTM Schichten zumindest ebenso gute Ergebnisse erreicht werden. Auf dem PAN Datensatz sind alle vorgestellten Ansätze jedoch mit maximal 65% Genauigkeit noch weit hinter dem LightGBM mit 70%.\n",
    "\n",
    "Innerhalb der Book Summary Datensätze sind die Ergebnisse mit nur geringem Unterschied von 1% bei Ansatz 1 und 5% bei Ansatz 2 gut übertragbar. Versuche auf dem Book Summary Datensatz trainierte Modelle auf den PAN Datensatz zu übertragen oder umgekehrt sind aufgrund der gewählten extrahierten Features nur mit Book Summary 1 möglich gewesen und ohne Ausnahme mit einer Genauigkeit rund um 50% alle fehlgeschlagen.\n",
    "\n",
    "Während die Ansätze 1 und 2 ebenso gute Ergebnisse wie Ansatz 3 erzielt haben, ließ sich nicht bestätigen, dass durch die vorab extrahierten Features eine bessere Performance auf den relativ kleinen Datensätzen erreicht werden kann. Durch das ausbleibende Trainieren der Embedding-Schichten, sind jedoch die Trainingszeiten für Ansatz 1 und 2 wesentliche kürzer. Während sich Ansatz 1 und Ansatz 2 in rund 6 bzw. 10 Minuten durchgelaufen sind, hat Ansatz 3 knapp über 2 Stunden benötigt.\n",
    "\n",
    "Im Vergleich zu den bei der PAN Style Change Detection Aufgabe 2018 eingereichten Modellen hätten unsere Ansätze 2 und 3 mit 65% Genauigkeit den 4. Platz belegt. Das nächst bessere Modell wäre jedoch mit 80% ([Safin und Ogaltsov](http://ceur-ws.org/Vol-2125/paper_104.pdf)) wesentlich besser gewesen, während die folgenden Modelle mit 64% ([Khan](http://ceur-ws.org/Vol-2125/paper_170.pdf)) und 62% ([Schaetti](http://ceur-ws.org/Vol-2125/invited_paper_2.pdf)) nah bei einander liegen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Comparison_models.PNG](attachment:Comparison_models.PNG) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Abb. **tbd xx** ist abschließend der Vergleich der verschiedenen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusammenfassend lässt sich feststellen, dass es prinzipiell gelungen ist mit einer Genauigkeit von über 80% gute Ergebnisse auf dem Booksummary-Datensatz zu erreichen. Die Ergebnisse sind jedoch nicht ohne Vorbehalt im hinblicka uf das Ziel der Identifizierung von Texten mit geteilter Autornschaft, da die zugrundliegenden Daten von Wikipedia stammen und so eine mehrfache Autorenschaft auch bei den negativ gelabelten Texten nicht ausgeschlossen werden kann. Dies wirft die Frage auf, ob tatsächlich der Stil der Autoren erkannt und Veränderungen dessen zu den Ergebnissen führen oder andere Eigenschaften (wie z.B. starke inhaltliche Unterschiede) ausschlaggebend sind. Im Vergleich haben die selben Modelle mit 65% Genauigkeit auf dem besser aufbereiteten PAN Datensatz schlechtere Ergenisse erzielt. \n",
    "\n",
    "Im Vergleich der Modelle und ihrer Trainingslaufzeiten lässt sich abschließend feststellen, dass die Extraktion von definierten Features als Input für Neuronale Netze lediglich einen zeitlichen Vorteil beim Trainieren von tiefen Neuronalen Netzen bringt, keine Verbesserung der Ergebnisse. Während die Architektur in Ansatz 3 auf der Lernen von Word-N-Grams ausgerichtet ist, bleibt es eine interessante Frage für weitere Experimente, ob andere vor alle lexikalische Featuers wie bspw. die durchschnittliche Satzlänge in einem solchen Netz codiert werden können und zur Klassifizierung beitragen. \n",
    "\n",
    "Desweiteren ist aufgefallen, dass alle drei Ansätze stark von einem Bias durch die Trainingsdaten betroffen sind. Zum einen war der Einsatz verschiedenster Techniken zur Vermeidung von Overfitting auf den Trainingsdaten nötig, um die Netze auf relativ kleinen datenmenge zu trainieren. Zum anderen ist auch die Übertragbarkeit der trainierten Modelle zwischen den Datensätzen nicht gegeben. Auch die einbezogene verwandte Forschung spricht dafür, dass die Generalisierbarkeit von Modellen im Bereich der Style Change Detection noch weitreichender Verbesserung bedarf. Ein Beispiel für Bemühungen in diese Richtung ist die PAN Aufgabe zur [Cross-domain Authorship Attribution](https://pan.webis.de/clef18/pan18-web/author-identification.html), die parallell zur Style Change Detection ausgeschrieben wurde. \n",
    "\n",
    "Sowohl im Sinne der Generalisierbarkeit als auch, um potentiale tieferer Neuronaler Netze in diesem Bereich zu erfroschen, besteht der Bedarf an umfangreicheren Datensätzen für diese Forschungsfrage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Inhaltsverzeichnis",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "562px",
    "left": "1567px",
    "right": "4px",
    "top": "114px",
    "width": "349px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
